{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e71ff86",
   "metadata": {},
   "source": [
    "# Bibliography Categorization: 'BibCat'\n",
    "## Tutorial: Estimating performance of classifiers in bibcat.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3ab7e4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d234a479",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction.\n",
    "\n",
    "In this tutorial, we will use bibcat to estimate the performance of classifiers on sets of texts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f050727",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86289680",
   "metadata": {},
   "source": [
    "## User Workflow: Training a machine learning (ML) model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af236d7a",
   "metadata": {},
   "source": [
    "The `Performance` class contains user-friendly methods for estimating the performance of given classifiers and outputting that performance as, e.g., confusion matrices.  We overview how this method can be run in the code blocks below.\n",
    "\n",
    "For this tutorial, we assume that the user has already run the trainML tutorial, and so has generated and saved a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fdea077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import external packages\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "sys.path.append(\"./../main/\")\n",
    "#\n",
    "#Import bibcat packages\n",
    "import bibcat_classes as bibcat\n",
    "import bibcat_config as config\n",
    "import bibcat_constants as preset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9e0a06e-61fc-438a-b642-3669910f9b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set some global variables\n",
    "seed_test = 10 #Random seed for shuffling text dataset\n",
    "do_shuffle = True #Whether or not to shuffle the text dataset\n",
    "max_tests = 100 #Number of text entries to test the performance for; None for all tests available\n",
    "is_text_processed = True #We are using preprocessed text for this tutorial (previously generated by trainML in a test set directory)\n",
    "mode_modif = None #We are using preprocessed data in this tutorial, so we do not need a processing mode at all\n",
    "buffer = 0\n",
    "#\n",
    "#Prepare some Keyword objects\n",
    "kobj_hubble = bibcat.Keyword(\n",
    "                keywords=[\"Hubble\", \"Hubble Telescope\",\n",
    "                          \"Hubble Space Telescope\"],\n",
    "                acronyms=[\"hst\", \"ht\"])\n",
    "all_kobjs = [kobj_hubble]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "710913d3-0a11-4cda-8971-1b845d542fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch filepaths for model and data\n",
    "name_model = config.name_model\n",
    "filepath_json = config.path_json\n",
    "dir_model = os.path.join(config.dir_allmodels, name_model)\n",
    "#\n",
    "#Set some directories\n",
    "dir_info = dir_model\n",
    "dir_test = os.path.join(dir_model, \"dir_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0188dbd8-388d-4f8e-95e9-ebede99435c2",
   "metadata": {},
   "source": [
    "Let's build a set of classifiers for which we'd like to test the performance.  We'll then feed each of those classifiers into an instance of the Operator class to handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "116fd35a-994f-452c-87dc-233733ab8749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "#Create a list of classifiers\n",
    "#This can be modified to use whatever classifiers you'd like.\n",
    "#Load a previously trained ML model\n",
    "filepath_model = os.path.join(dir_model, (name_model+\".npy\"))\n",
    "fileloc_ML = os.path.join(dir_model, (preset.tfoutput_prefix+name_model))\n",
    "classifier_ML = bibcat.Classifier_ML(filepath_model=filepath_model, fileloc_ML=fileloc_ML, do_verbose=True)\n",
    "#\n",
    "\n",
    "#Load a rule-based classifier\n",
    "classifier_rules = bibcat.Classifier_Rules()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e4a36a1-e8cc-4576-8aab-904f61813988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance of Operator successfully initialized!\n",
      "Keyword objects:\n",
      "0: Keyword Object:\n",
      "Name: Hubble\n",
      "Keywords: ['Hubble Space Telescope', 'Hubble Telescope', 'Hubble']\n",
      "Acronyms: ['hst', 'ht']\n",
      "\n",
      "Instance of Operator successfully initialized!\n",
      "Keyword objects:\n",
      "0: Keyword Object:\n",
      "Name: Hubble\n",
      "Keywords: ['Hubble Space Telescope', 'Hubble Telescope', 'Hubble']\n",
      "Acronyms: ['hst', 'ht']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load models into instances of the Operator class\n",
    "operator_1 = bibcat.Operator(classifier=classifier_ML, mode=mode_modif, keyword_objs=all_kobjs,\n",
    "                            name=\"Operator_1\", do_verbose=True, load_check_truematch=True, do_verbose_deep=False)\n",
    "operator_2 = bibcat.Operator(classifier=classifier_rules,\n",
    "                            name=\"Operator_2\", mode=mode_modif, keyword_objs=all_kobjs, do_verbose=True, do_verbose_deep=False)\n",
    "list_operators = [operator_1, operator_2] #Feel free to add more/less operators here.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82951251-fc59-4e33-a978-bc8fa16915dd",
   "metadata": {},
   "source": [
    "Now, let's fetch some text for our classifiers to classify. For this tutorial, we'll load previously processed texts from the directory containing the test set for the ML classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8075c1f-bc7b-422e-89cc-82fac058bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load information for the processed text\n",
    "dict_allinfo = np.load(os.path.join(dir_info, \"dict_textinfo.npy\"), allow_pickle=True).item()\n",
    "\n",
    "#Prepare filepaths for each text\n",
    "list_filenames = [item for item in os.listdir(dir_test) if item.endswith(\".txt\")]\n",
    "\n",
    "#Shuffle the tests, if so requested\n",
    "if do_shuffle:\n",
    "    np.random.seed(seed_test)\n",
    "    np.random.shuffle(list_filenames)\n",
    "#\n",
    "\n",
    "#Truncate the number of tests, if so requested\n",
    "if (max_tests is not None):\n",
    "    list_filenames = list_filenames[0:max_tests]\n",
    "#\n",
    "\n",
    "dict_texts = {}\n",
    "#Process the tests into a dictionary of texts\n",
    "for ii in range(0, len(list_filenames)):\n",
    "    curr_filename = list_filenames[ii]\n",
    "    curr_fileroot = re.sub(\"\\.txt$\", \"\", curr_filename) #Remove extension\n",
    "    curr_info = dict_allinfo[curr_fileroot]\n",
    "\n",
    "    #Load the text from this file\n",
    "    with open(os.path.join(dir_test, curr_filename), 'r') as openfile:\n",
    "        curr_text = openfile.read()\n",
    "    #\n",
    "    \n",
    "    #Store info for this current text entry\n",
    "    curr_dict = {\"text\":curr_text, \"mission\":curr_info[\"mission\"], \"forest\":curr_info[\"forest\"],\n",
    "                \"class\":curr_info[\"class\"], \"id\":curr_info[\"id\"]}\n",
    "    dict_texts[str(ii)] = curr_dict\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eacfa22-ba0d-48e2-b878-e6e665b61e3b",
   "metadata": {},
   "source": [
    "Next, let's prepare some additional information for each of these classifiers.  We'll need to set, for example, the uncertainty thresholds for accepting or rejecting each classifier's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52317109-f682-4555-a6fe-187424b69116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set parameters for each operator and its internal classifier\n",
    "#Global parameters\n",
    "do_verify_truematch = True\n",
    "do_raise_innererror = False\n",
    "\n",
    "#For operator 1\n",
    "mapper_1 = None #Mapper to mask classifications; None if no masking\n",
    "dict_texts_1 = dict_texts #Dictionary of texts to classify\n",
    "threshold_1 = 0.70 #Uncertainty threshold for this classifier\n",
    "\n",
    "#For operator 2\n",
    "mapper_2 = None #Mapper to mask classifications; None if no masking\n",
    "dict_texts_2 = dict_texts #Dictionary of texts to classify\n",
    "threshold_2 = 0.70 #Uncertainty threshold for this classifier\n",
    "\n",
    "#Gather parameters into lists\n",
    "list_mappers = [mapper_1, mapper_2]\n",
    "list_thresholds = [threshold_1, threshold_2]\n",
    "list_dict_texts = [dict_texts_1, dict_texts_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc781e0-10f6-4eee-a431-23727b1ef0e2",
   "metadata": {},
   "source": [
    "Now, let's evaluate the performance of these classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09831c4e-c557-4f2d-87fe-134a12329bd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'do_verbose' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Create an instance of the Performance class\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m performer \u001b[38;5;241m=\u001b[39m \u001b[43mbibcat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPerformance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/STScI_Fellowship/Functional/Library/BibTracking/repo_stsci/bibcat/docs/./../main/bibcat_classes.py:6413\u001b[0m, in \u001b[0;36mPerformance.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6411\u001b[0m \u001b[38;5;66;03m#Initialize storage\u001b[39;00m\n\u001b[1;32m   6412\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 6413\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_info(\u001b[43mdo_verbose\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_verbose\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6414\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_info(do_verbose_deep, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_verbose_deep\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6415\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   6416\u001b[0m \n\u001b[1;32m   6417\u001b[0m \u001b[38;5;66;03m#Exit the method\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'do_verbose' is not defined"
     ]
    }
   ],
   "source": [
    "#Create an instance of the Performance class\n",
    "performer = bibcat.Performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73bc293-bb66-4d66-bb0e-6643a1e15ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the pipeline for a basic evaluation of model performance\n",
    "performer.evaluate_performance_basic(operators=list_operators, dicts_texts=list_dict_texts, mappers=list_mappers,\n",
    "                                     thresholds=list_thresholds, is_text_processed=is_text_processed,\n",
    "                                     do_verify_truematch=do_verify_truematch, do_raise_innererror=do_raise_innererror,\n",
    "                                     do_save_evaluation=True, do_save_misclassif=True, filepath_output=filepath_output,\n",
    "                                     fileroot_evaluation=fileroot_evaluation, fileroot_misclassif=fileroot_misclassif,\n",
    "                                     print_freq=25, do_verbose=True, do_verbose_deep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3ceb74-7087-4256-8044-59f4cb97db51",
   "metadata": {},
   "source": [
    "And with that, you should have new confusion matrices summarizing the basic performance for these classifiers saved in your requested directory!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee10749-9dc1-4460-a34c-18ecb413f450",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
