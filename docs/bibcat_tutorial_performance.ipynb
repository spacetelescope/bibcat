{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e71ff86",
   "metadata": {},
   "source": [
    "# Bibliography Categorization: 'BibCat'\n",
    "## Tutorial: Estimating performance of classifiers in bibcat.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3ab7e4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d234a479",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction.\n",
    "\n",
    "In this tutorial, we will use bibcat to estimate the performance of classifiers on sets of texts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f050727",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86289680",
   "metadata": {},
   "source": [
    "## User Workflow: Training a machine learning (ML) model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af236d7a",
   "metadata": {},
   "source": [
    "The `Performance` class contains user-friendly methods for estimating the performance of given classifiers and outputting that performance as, e.g., confusion matrices.  We overview how this method can be run in the code blocks below.\n",
    "\n",
    "For this tutorial, we assume that the user has already run the trainML tutorial, and so has generated and saved a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fdea077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import external packages\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "272dbb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: /Users/jamila.pegues/Documents/STScI_Fellowship/Functional/Library/BibTracking/repo_stsci/bibcat/docs\n",
      "Source directory: /Users/jamila.pegues/Documents/STScI_Fellowship/Functional/Library/BibTracking/repo_stsci/bibcat/src\n"
     ]
    }
   ],
   "source": [
    "# Set up for fetching necessary bibcat modules for the tutorial\n",
    "# Check work directories: src/ is where all source python scripts are available. \n",
    "current_dir= os.path.dirname(os.path.abspath('__file__'))\n",
    "_parent = os.path.dirname(current_dir)\n",
    "src_dir = os.path.join(_parent, \"src\")\n",
    "\n",
    "print(f'Current Directory: {current_dir}')\n",
    "print(f'Source directory: {src_dir}')\n",
    "\n",
    "# move to the ../src/ directory to import necessary modules. \n",
    "os.chdir(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d040df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root directory =/Users/jamila.pegues/Documents/STScI_Fellowship/Functional/Library/BibTracking/repo_stsci/bibcat/src, parent directory=/Users/jamila.pegues/Documents/STScI_Fellowship/Functional/Library/BibTracking/repo_stsci/bibcat\n",
      "/Users/jamila.pegues/Documents/STScI_Fellowship/Functional/Library/BibTracking/repo_stsci/bibcat/src/models folder already exists.\n",
      "/Users/jamila.pegues/Documents/STScI_Fellowship/Functional/Library/BibTracking/repo_stsci/bibcat/output folder already exists.\n"
     ]
    }
   ],
   "source": [
    "#Import bibcat packages\n",
    "import bibcat_classes as bibcat\n",
    "import bibcat_config as config\n",
    "import bibcat_parameters as params #Temporary file until contents moved elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef0edceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set parameters for each operator and its internal classifier\n",
    "#Global parameters\n",
    "do_verify_truematch = True #A very important parameter - discuss with J.P. first!!!  Set it to either True or False.\n",
    "do_raise_innererror = False #If True, will stop if exception encountered; if False, will print error and continue\n",
    "list_threshold_arrays = [np.linspace(0.5, 0.95, 20)]*2 #For uncertainty test\n",
    "class_mapper = params.map_papertypes #Mapper for class types; None for no mapper\n",
    "\n",
    "#For operator 1\n",
    "mapper_1 = class_mapper #Mapper to mask classifications; None if no masking\n",
    "threshold_1 = 0.70 #Uncertainty threshold for this classifier\n",
    "buffer_1 = 0\n",
    "\n",
    "#For operator 2\n",
    "mapper_2 = class_mapper #Mapper to mask classifications; None if no masking\n",
    "threshold_2 = 0.70 #Uncertainty threshold for this classifier\n",
    "buffer_2 = 0\n",
    "\n",
    "#Gather parameters into lists\n",
    "list_mappers = [mapper_1, mapper_2]\n",
    "list_thresholds = [threshold_1, threshold_2]\n",
    "list_buffers = [buffer_1, buffer_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9e0a06e-61fc-438a-b642-3669910f9b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set some overarching global variables\n",
    "seed_test = 10 #Random seed for shuffling text dataset\n",
    "np.random.seed(seed_test)\n",
    "do_shuffle = True #Whether or not to shuffle the text dataset\n",
    "do_real_testdata = True #If True, will use real papers to test performance; if False, will use fake texts below\n",
    "#\n",
    "max_tests = 10 #0 #Number of text entries to test the performance for; None for all tests available\n",
    "mode_modif = \"skim_trim_anon\" #None #We are using preprocessed data in this tutorial, so we do not need a processing mode at all\n",
    "#\n",
    "#Prepare some Keyword objects\n",
    "all_kobjs = params.all_kobjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "710913d3-0a11-4cda-8971-1b845d542fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch filepaths for model and data\n",
    "name_model = config.name_model\n",
    "filepath_json = config.path_json\n",
    "output_path = config.PATH_OUTPUT\n",
    "dir_model = os.path.join(config.dir_allmodels, name_model)\n",
    "#\n",
    "#Set directories for storing performance output\n",
    "filepath_output = output_path #Where to store the performance output, such as the confusion matrices\n",
    "#\n",
    "#Set directories for fetching text\n",
    "dir_info = dir_model\n",
    "folder_test = config.folders_TVT[\"test\"]\n",
    "dir_test = os.path.join(dir_model, folder_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0188dbd8-388d-4f8e-95e9-ebede99435c2",
   "metadata": {},
   "source": [
    "Let's build a set of classifiers for which we'd like to test the performance.  We'll then feed each of those classifiers into an instance of the Operator class to handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "116fd35a-994f-452c-87dc-233733ab8749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:using Lamb optimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "#Create a list of classifiers\n",
    "#This can be modified to use whatever classifiers you'd like.\n",
    "#Load a previously trained ML model\n",
    "filepath_model = os.path.join(dir_model, (name_model+\".npy\"))\n",
    "fileloc_ML = os.path.join(dir_model, (config.tfoutput_prefix+name_model))\n",
    "classifier_ML = bibcat.Classifier_ML(filepath_model=filepath_model, fileloc_ML=fileloc_ML, do_verbose=True)\n",
    "#\n",
    "\n",
    "#Load a rule-based classifier\n",
    "classifier_rules = bibcat.Classifier_Rules()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e4a36a1-e8cc-4576-8aab-904f61813988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance of Operator successfully initialized!\n",
      "Keyword objects:\n",
      "0: Keyword Object:\n",
      "Name: Hubble\n",
      "Keywords: ['Hubble Space Telescope', 'Hubble Telescope', 'Hubble']\n",
      "Acronyms: ['HST', 'HT']\n",
      "\n",
      "1: Keyword Object:\n",
      "Name: Webb Telescope\n",
      "Keywords: ['James Webb Space Telescope', 'Webb Space Telescope', 'James Webb Telescope', 'Webb Telescope']\n",
      "Acronyms: ['JWST', 'JST', 'JT']\n",
      "\n",
      "2: Keyword Object:\n",
      "Name: Transiting Exoplanet Survey Satellite\n",
      "Keywords: ['Transiting Exoplanet Survey Satellite']\n",
      "Acronyms: ['TESS']\n",
      "\n",
      "3: Keyword Object:\n",
      "Name: Kepler\n",
      "Keywords: ['Kepler']\n",
      "Acronyms: []\n",
      "\n",
      "4: Keyword Object:\n",
      "Name: Pan-STARRS\n",
      "Keywords: ['Panoramic Survey Telescope and Rapid Response System', 'Pan-STARRS1', 'Pan-STARRS']\n",
      "Acronyms: ['PanSTARRS1', 'PanSTARRS', 'PS1']\n",
      "\n",
      "5: Keyword Object:\n",
      "Name: Galaxy Evolution Explorer\n",
      "Keywords: ['Galaxy Evolution Explorer']\n",
      "Acronyms: ['GALEX']\n",
      "\n",
      "6: Keyword Object:\n",
      "Name: K2\n",
      "Keywords: ['K2']\n",
      "Acronyms: []\n",
      "\n",
      "7: Keyword Object:\n",
      "Name: Hubble Legacy Archive\n",
      "Keywords: ['Hubble Legacy Archive']\n",
      "Acronyms: ['HLA']\n",
      "\n",
      "Instance of Operator successfully initialized!\n",
      "Keyword objects:\n",
      "0: Keyword Object:\n",
      "Name: Hubble\n",
      "Keywords: ['Hubble Space Telescope', 'Hubble Telescope', 'Hubble']\n",
      "Acronyms: ['HST', 'HT']\n",
      "\n",
      "1: Keyword Object:\n",
      "Name: Webb Telescope\n",
      "Keywords: ['James Webb Space Telescope', 'Webb Space Telescope', 'James Webb Telescope', 'Webb Telescope']\n",
      "Acronyms: ['JWST', 'JST', 'JT']\n",
      "\n",
      "2: Keyword Object:\n",
      "Name: Transiting Exoplanet Survey Satellite\n",
      "Keywords: ['Transiting Exoplanet Survey Satellite']\n",
      "Acronyms: ['TESS']\n",
      "\n",
      "3: Keyword Object:\n",
      "Name: Kepler\n",
      "Keywords: ['Kepler']\n",
      "Acronyms: []\n",
      "\n",
      "4: Keyword Object:\n",
      "Name: Pan-STARRS\n",
      "Keywords: ['Panoramic Survey Telescope and Rapid Response System', 'Pan-STARRS1', 'Pan-STARRS']\n",
      "Acronyms: ['PanSTARRS1', 'PanSTARRS', 'PS1']\n",
      "\n",
      "5: Keyword Object:\n",
      "Name: Galaxy Evolution Explorer\n",
      "Keywords: ['Galaxy Evolution Explorer']\n",
      "Acronyms: ['GALEX']\n",
      "\n",
      "6: Keyword Object:\n",
      "Name: K2\n",
      "Keywords: ['K2']\n",
      "Acronyms: []\n",
      "\n",
      "7: Keyword Object:\n",
      "Name: Hubble Legacy Archive\n",
      "Keywords: ['Hubble Legacy Archive']\n",
      "Acronyms: ['HLA']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load models into instances of the Operator class\n",
    "operator_1 = bibcat.Operator(classifier=classifier_ML, mode=mode_modif, keyword_objs=all_kobjs,\n",
    "                            name=\"Operator_ML\", do_verbose=True, load_check_truematch=True, do_verbose_deep=False)\n",
    "operator_2 = bibcat.Operator(classifier=classifier_rules,\n",
    "                            name=\"Operator_RB\", mode=mode_modif, keyword_objs=all_kobjs,\n",
    "                            do_verbose=True, do_verbose_deep=False)\n",
    "list_operators = [operator_1, operator_2] #Feel free to add more/less operators here.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82951251-fc59-4e33-a978-bc8fa16915dd",
   "metadata": {},
   "source": [
    "Now, let's fetch some text for our classifiers to classify. For this tutorial, we'll load previously processed texts from the directory containing the test set for the ML classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8075c1f-bc7b-422e-89cc-82fac058bb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts in text set: 10\n",
      "\n",
      "Entry 59:\n",
      "ID: 59\n",
      "Bibcode: 2021Icar..35313406G\n",
      "Missions: {'Hubble': {'mission': 'Hubble', 'class': 'MENTION'}, 'Webb Telescope': {'mission': 'Webb Telescope', 'class': 'z_notmatch'}, 'Transiting Exoplanet Survey Satellite': {'mission': 'Transiting Exoplanet Survey Satellite', 'class': 'z_notmatch'}, 'Kepler': {'mission': 'Kepler', 'class': 'z_notmatch'}, 'Pan-STARRS': {'mission': 'Pan-STARRS', 'class': 'z_notmatch'}, 'Galaxy Evolution Explorer': {'mission': 'Galaxy Evolution Explorer', 'class': 'z_notmatch'}, 'K2': {'mission': 'K2', 'class': 'z_notmatch'}, 'Hubble Legacy Archive': {'mission': 'Hubble Legacy Archive', 'class': 'z_notmatch'}}\n",
      "Start of text:\n",
      "1 Introduction The state of a planetary atmosphere can be described by the interdependence of the temperature, pressure and density as a function of the altitude. The knowledge of the vertical temperature profiles is essential for an understanding of the dynamical, thermodynamical, and chemical processes occurring in the atmosphere. In addition, suspended aerosols such as dust and water ice, which are very variable in the Martian atmosphere, strongly affect the radiative transfer, with significa\n",
      "-\n",
      "\n",
      "Entry 968:\n",
      "ID: 968\n",
      "Bibcode: 2021MNRAS.500.2440M\n",
      "Missions: {'Hubble': {'mission': 'Hubble', 'class': 'z_notmatch'}, 'Webb Telescope': {'mission': 'Webb Telescope', 'class': 'z_notmatch'}, 'Transiting Exoplanet Survey Satellite': {'mission': 'Transiting Exoplanet Survey Satellite', 'class': 'z_notmatch'}, 'Kepler': {'mission': 'Kepler', 'class': 'z_notmatch'}, 'Pan-STARRS': {'mission': 'Pan-STARRS', 'class': 'SCIENCE'}, 'Galaxy Evolution Explorer': {'mission': 'Galaxy Evolution Explorer', 'class': 'z_notmatch'}, 'K2': {'mission': 'K2', 'class': 'z_notmatch'}, 'Hubble Legacy Archive': {'mission': 'Hubble Legacy Archive', 'class': 'z_notmatch'}}\n",
      "Start of text:\n",
      "1 INTRODUCTION Herbig–Haro (HH) objects represent shocked excitation zones where supersonic flows from young stellar objects (YSOs) collide with the interstellar medium and form small cloudlets with pure emission spectra including permitted and low-excitation forbidden emission lines ([O i ], [S ii ] etc.). They have long been recognized as a sign of high and recent activity of star formation in molecular clouds. The discovery of new HH objects is important for several reasons. First, HH objects\n",
      "-\n",
      "\n",
      "Entry 1709:\n",
      "ID: 1709\n",
      "Bibcode: 2020PASP..132l5002S\n",
      "Missions: {'Hubble': {'mission': 'Hubble', 'class': 'z_notmatch'}, 'Webb Telescope': {'mission': 'Webb Telescope', 'class': 'z_notmatch'}, 'Transiting Exoplanet Survey Satellite': {'mission': 'Transiting Exoplanet Survey Satellite', 'class': 'z_notmatch'}, 'Kepler': {'mission': 'Kepler', 'class': 'MENTION'}, 'Pan-STARRS': {'mission': 'Pan-STARRS', 'class': 'z_notmatch'}, 'Galaxy Evolution Explorer': {'mission': 'Galaxy Evolution Explorer', 'class': 'z_notmatch'}, 'K2': {'mission': 'K2', 'class': 'z_notmatch'}, 'Hubble Legacy Archive': {'mission': 'Hubble Legacy Archive', 'class': 'z_notmatch'}}\n",
      "Start of text:\n",
      "1. Introduction Lick Observatory (LO) was established during the decade of the 1880s. The observatory was made possible by the scientific philanthropy of James Lick, under circumstances that have been well chronicled by Wright ( 1987 ) and Osterbrock et al. ( 1988 ). The first telescope to be mounted in a dome atop Mount Hamilton was a 12 in Clark refractor, which was used for observation of a transit of Mercury in 1881 November (Neubauer 1950 ), a mere two weeks after the Earp brothers and Doc \n",
      "-\n",
      "\n",
      "Entry 152:\n",
      "ID: 152\n",
      "Bibcode: 2021MNRAS.500.4578M\n",
      "Missions: {'Hubble': {'mission': 'Hubble', 'class': 'z_notmatch'}, 'Webb Telescope': {'mission': 'Webb Telescope', 'class': 'MENTION'}, 'Transiting Exoplanet Survey Satellite': {'mission': 'Transiting Exoplanet Survey Satellite', 'class': 'z_notmatch'}, 'Kepler': {'mission': 'Kepler', 'class': 'z_notmatch'}, 'Pan-STARRS': {'mission': 'Pan-STARRS', 'class': 'z_notmatch'}, 'Galaxy Evolution Explorer': {'mission': 'Galaxy Evolution Explorer', 'class': 'z_notmatch'}, 'K2': {'mission': 'K2', 'class': 'z_notmatch'}, 'Hubble Legacy Archive': {'mission': 'Hubble Legacy Archive', 'class': 'z_notmatch'}}\n",
      "Start of text:\n",
      "1 INTRODUCTION The answer to how multiple stellar populations (MSPs) form within globular clusters (GCs) has evaded astronomers for several decades. Since the suggestion that MSP may be responsible for the cyanogen bimodality in 47 Tucanae (47 Tuc) by Norris Freeman ( 1979 ), a wealth of photometric (e.g. Sbordone et al. 2011 ; Piotto et al. 2015 ; Milone et al. 2017 ; Lagioia et al. 2019 ; Lee Sneden 2020 ) and spectroscopic (e.g. Barbuy et al. 2009 ; Carretta et al. 2009a ; Kamann et al. 2018 \n",
      "-\n",
      "\n",
      "Entry 1606:\n",
      "ID: 1606\n",
      "Bibcode: 2020PSJ.....1...44N\n",
      "Missions: {'Hubble': {'mission': 'Hubble', 'class': 'SCIENCE'}, 'Webb Telescope': {'mission': 'Webb Telescope', 'class': 'z_notmatch'}, 'Transiting Exoplanet Survey Satellite': {'mission': 'Transiting Exoplanet Survey Satellite', 'class': 'z_notmatch'}, 'Kepler': {'mission': 'Kepler', 'class': 'z_notmatch'}, 'Pan-STARRS': {'mission': 'Pan-STARRS', 'class': 'z_notmatch'}, 'Galaxy Evolution Explorer': {'mission': 'Galaxy Evolution Explorer', 'class': 'z_notmatch'}, 'K2': {'mission': 'K2', 'class': 'z_notmatch'}, 'Hubble Legacy Archive': {'mission': 'Hubble Legacy Archive', 'class': 'z_notmatch'}}\n",
      "Start of text:\n",
      "1. Introduction Starting in 2018, the first deep satellite search of the Trojan asteroids that are targets of NASA’s Lucy mission (Levison et al. 2017 ) was conducted using the Hubble Space Telescope (HST; Noll et al. 2018 ). Deep searches with high contrast are required to detect small satellites and observations with HST are uniquely well suited for this purpose. Here we report the discovery of a previously unknown satellite of the Lucy target Eurybates, a d = 63.9 ± 0.3 km body (Grav et al. 2\n",
      "-\n",
      "\n",
      "Entry 2376:\n",
      "ID: 2376\n",
      "Bibcode: 2021MNRAS.500.1038L\n",
      "Missions: {'Hubble': {'mission': 'Hubble', 'class': 'SCIENCE'}, 'Webb Telescope': {'mission': 'Webb Telescope', 'class': 'z_notmatch'}, 'Transiting Exoplanet Survey Satellite': {'mission': 'Transiting Exoplanet Survey Satellite', 'class': 'z_notmatch'}, 'Kepler': {'mission': 'Kepler', 'class': 'z_notmatch'}, 'Pan-STARRS': {'mission': 'Pan-STARRS', 'class': 'z_notmatch'}, 'Galaxy Evolution Explorer': {'mission': 'Galaxy Evolution Explorer', 'class': 'z_notmatch'}, 'K2': {'mission': 'K2', 'class': 'z_notmatch'}, 'Hubble Legacy Archive': {'mission': 'Hubble Legacy Archive', 'class': 'z_notmatch'}}\n",
      "Start of text:\n",
      "1 INTRODUCTION The origin of the circumgalactic medium (CGM) is a product of two critical processes in galaxy evolution: gas inflow from the intergalactic medium (IGM) and gas outflow from the galaxy. Continuous gas inflow is required to sustain the star formation activity observed throughout cosmic time, while galactic outflows are necessary to explain the low observed star formation efficiency (Dekel et al. 2009 ; Silk Mamon 2012 ). However, the CGM is a complex and dynamic environment because\n",
      "-\n",
      "\n",
      "Entry 268:\n",
      "ID: 268\n",
      "Bibcode: 2021MNRAS.500.1087B\n",
      "Missions: {'Hubble': {'mission': 'Hubble', 'class': 'z_notmatch'}, 'Webb Telescope': {'mission': 'Webb Telescope', 'class': 'z_notmatch'}, 'Transiting Exoplanet Survey Satellite': {'mission': 'Transiting Exoplanet Survey Satellite', 'class': 'z_notmatch'}, 'Kepler': {'mission': 'Kepler', 'class': 'z_notmatch'}, 'Pan-STARRS': {'mission': 'Pan-STARRS', 'class': 'z_notmatch'}, 'Galaxy Evolution Explorer': {'mission': 'Galaxy Evolution Explorer', 'class': 'MENTION'}, 'K2': {'mission': 'K2', 'class': 'z_notmatch'}, 'Hubble Legacy Archive': {'mission': 'Hubble Legacy Archive', 'class': 'z_notmatch'}}\n",
      "Start of text:\n",
      "1 INTRODUCTION The origin of ultrahigh energy cosmic rays (UHECRs) is one of the long-standing unsolved problems of physics. It is generally believed that the sources of UHECRCs can identify through observations of anisotropy in the arrival direction of UHECRs. The Pierre Auger collaboration reported that arrival directions of the 13 events above 55 EeV energies of a total of 69 events in the whole sky are consistent with the sky location of a circular window of radius 18 ○ centred on nearest ac\n",
      "-\n",
      "\n",
      "Entry 1245:\n",
      "ID: 1245\n",
      "Bibcode: 2020P&SS..19105030F\n",
      "Missions: {'Hubble': {'mission': 'Hubble', 'class': 'z_notmatch'}, 'Webb Telescope': {'mission': 'Webb Telescope', 'class': 'z_notmatch'}, 'Transiting Exoplanet Survey Satellite': {'mission': 'Transiting Exoplanet Survey Satellite', 'class': 'z_notmatch'}, 'Kepler': {'mission': 'Kepler', 'class': 'z_notmatch'}, 'Pan-STARRS': {'mission': 'Pan-STARRS', 'class': 'z_notmatch'}, 'Galaxy Evolution Explorer': {'mission': 'Galaxy Evolution Explorer', 'class': 'z_notmatch'}, 'K2': {'mission': 'K2', 'class': 'z_notmatch'}, 'Hubble Legacy Archive': {'mission': 'Hubble Legacy Archive', 'class': 'z_notmatch'}}\n",
      "Start of text:\n",
      "1 Introduction: why explore Ice Giant Systems? 1.1 Motivations The early 21st century has provided unprecedented leaps in our exploration of the Gas Giant systems, via the completion of the Galileo and Cassini orbital missions at Jupiter and Saturn; NASA/Junos ongoing exploration of Jupiters deep interior, atmosphere, and magnetic field; ESAs development of the JUICE mission (Jupiter Icy Moons Explorer) and NASAs Europa Clipper to explore the Galilean satellites. The past decade has also provide\n",
      "-\n",
      "\n",
      "Entry 603:\n",
      "ID: 603\n",
      "Bibcode: 2020SPIE11422E..0QS\n",
      "Missions: {'Hubble': {'mission': 'Hubble', 'class': 'z_notmatch'}, 'Webb Telescope': {'mission': 'Webb Telescope', 'class': 'MENTION'}, 'Transiting Exoplanet Survey Satellite': {'mission': 'Transiting Exoplanet Survey Satellite', 'class': 'z_notmatch'}, 'Kepler': {'mission': 'Kepler', 'class': 'z_notmatch'}, 'Pan-STARRS': {'mission': 'Pan-STARRS', 'class': 'z_notmatch'}, 'Galaxy Evolution Explorer': {'mission': 'Galaxy Evolution Explorer', 'class': 'z_notmatch'}, 'K2': {'mission': 'K2', 'class': 'z_notmatch'}, 'Hubble Legacy Archive': {'mission': 'Hubble Legacy Archive', 'class': 'z_notmatch'}}\n",
      "Start of text:\n",
      "Hardening a notional missile warning satellite telescope against jamming and damage by ground, airborne, and space-based lasers John R. Solin* SOLINCO, PO Box 3937, San Jose, CA, USA 95150-3937 ABSTRACT Methods are proposed for hardening a missile warning satellite against jamming and damage from unlimited running time 1-MW airborne, 1-MJ ground-based, and space-based lasers. The unhardened telescope design is based on a model of a missile warning satellite telescope developed by the American Ph\n",
      "-\n",
      "\n",
      "Entry 1239:\n",
      "ID: 1239\n",
      "Bibcode: 2020RAA....20..159S\n",
      "Missions: {'Hubble': {'mission': 'Hubble', 'class': 'z_notmatch'}, 'Webb Telescope': {'mission': 'Webb Telescope', 'class': 'z_notmatch'}, 'Transiting Exoplanet Survey Satellite': {'mission': 'Transiting Exoplanet Survey Satellite', 'class': 'z_notmatch'}, 'Kepler': {'mission': 'Kepler', 'class': 'z_notmatch'}, 'Pan-STARRS': {'mission': 'Pan-STARRS', 'class': 'MENTION'}, 'Galaxy Evolution Explorer': {'mission': 'Galaxy Evolution Explorer', 'class': 'z_notmatch'}, 'K2': {'mission': 'K2', 'class': 'z_notmatch'}, 'Hubble Legacy Archive': {'mission': 'Hubble Legacy Archive', 'class': 'z_notmatch'}}\n",
      "Start of text:\n",
      "1 Introduction What the Milky Way looks like has long been a mystery. There are three main reasons why this problem has been unsolved for so long. One is that most of the visible stars lie in the Galactic thin disk. Our solar system lies nearly in the mid-plane of that disk, far from the center of the Milky Way, and from our vantage point we cannot distinguish structures in the Milky Way because of projection effects. The difficult situation that astronomers face is best illustrated by a famous \n",
      "-\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For use of real papers from test dataset to test on\n",
    "if (do_real_testdata):\n",
    "    #Load information for processed bibcodes reserved for testing\n",
    "    dict_TVTinfo = np.load(os.path.join(dir_info, \"dict_TVTinfo.npy\"), allow_pickle=True).item()\n",
    "    list_test_bibcodes = [key for key in dict_TVTinfo if (dict_TVTinfo[key][\"folder_TVT\"] == folder_test)]\n",
    "    \n",
    "    #Load the original data\n",
    "    with open(filepath_json, 'r') as openfile:\n",
    "        dataset = json.load(openfile)\n",
    "    #\n",
    "    \n",
    "    #Extract text information for the bibcodes reserved for testing\n",
    "    list_test_indanddata_raw = [(ii, dataset[ii]) for ii in range(0, len(dataset))\n",
    "                                if (dataset[ii][\"bibcode\"] in list_test_bibcodes)] #Data for test set\n",
    "    #\n",
    "    \n",
    "    #Shuffle, if requested\n",
    "    if do_shuffle:\n",
    "        np.random.shuffle(list_test_indanddata_raw)\n",
    "    #\n",
    "    \n",
    "    #Extract target number of test papers from the test bibcodes\n",
    "    if (max_tests is not None): #Fetch subset of tests\n",
    "        list_test_indanddata = list_test_indanddata_raw[0:max_tests]\n",
    "    else: #Use all tests\n",
    "        list_test_indanddata = list_test_indanddata_raw\n",
    "    #\n",
    "    \n",
    "    #Process the text input into dictionary format for inputting into the codebase\n",
    "    dict_texts = {} #To hold formatted text entries\n",
    "    for ii in range(0, len(list_test_indanddata)):\n",
    "        curr_ind = list_test_indanddata[ii][0]\n",
    "        curr_data = list_test_indanddata[ii][1]\n",
    "        #\n",
    "        #Convert this data entry into dictionary with: key:text,id,bibcode,mission structure\n",
    "        curr_info = {\"text\":curr_data[\"body\"], \"id\":str(curr_ind), \"bibcode\":curr_data[\"bibcode\"],\n",
    "                    \"missions\":{}}\n",
    "        for curr_mission in curr_data[\"class_missions\"]: #Iterate through missions for this paper\n",
    "            for curr_kobj in all_kobjs: #Iterate through declared Keyword objects\n",
    "                curr_name = curr_kobj.get_name()\n",
    "                #Store mission data under keyword name, if applicable\n",
    "                if (curr_kobj.is_keyword(curr_mission)):\n",
    "                    curr_info[\"missions\"][curr_name] = {\"mission\":curr_name,\n",
    "                                                    \"class\":curr_data[\"class_missions\"][curr_mission][\"papertype\"]}\n",
    "                #\n",
    "                #Otherwise, store that this mission was not detected for this text\n",
    "                else:\n",
    "                    curr_info[\"missions\"][curr_name] = {\"mission\":curr_name, \"class\":config.verdict_rejection}                    \n",
    "            #\n",
    "        #\n",
    "        #Store this data entry\n",
    "        dict_texts[str(curr_ind)] = curr_info\n",
    "    #\n",
    "    \n",
    "    #Print some notes about the testing data\n",
    "    print(\"Number of texts in text set: {0}\".format(len(dict_texts)))\n",
    "    print(\"\")\n",
    "    for key in dict_texts:\n",
    "        print(\"Entry {0}:\".format(key))\n",
    "        print(\"ID: {0}\".format(dict_texts[key][\"id\"]))\n",
    "        print(\"Bibcode: {0}\".format(dict_texts[key][\"bibcode\"]))\n",
    "        print(\"Missions: {0}\".format(dict_texts[key][\"missions\"]))\n",
    "        print(\"Start of text:\\n{0}\".format(dict_texts[key][\"text\"][0:500]))\n",
    "        print(\"-\\n\")\n",
    "    #\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2194a016-51fc-47fc-a756-7540e5674774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For use of fake, made-up data entries to test on\n",
    "if (not do_real_testdata):\n",
    "    print(\"Using fake test data for testing.\")\n",
    "    #Make some fake data\n",
    "    dict_texts_raw = {\"science\":[\"We present HST observations in Figure 4.\",\n",
    "                        \"The HST stars are listed in Table 3b.\",\n",
    "                        \"Despite our efforts to smooth the data, there are still rings in the HST images.\",\n",
    "                        \"See Section 8c for more discussion of the Hubble images.\",\n",
    "                        \"The supernovae detected with HST tend to be brighter than initially predicted.\",\n",
    "                        \"Our spectra from HST fit well to the standard trend first published in Someone et al. 1990.\",\n",
    "                        \"We use the Hubble Space Telescope to build an ultraviolet database of the target stars.\",\n",
    "                        \"The blue points (HST) exhibit more scatter than the red points (JWST).\",\n",
    "                        \"The benefit, then, is the far higher S/N we achieved in our HST observations.\",\n",
    "                        \"Here we employ the Hubble Telescope to observe the edge of the photon-dominated region.\",\n",
    "                        \"The black line shows that the region targeted with Hubble has an extreme UV signature.\"],\n",
    "                 \"datainfluenced\":[\"The simulated Hubble data is plotted in Figure 4.\",\n",
    "                       \"Compared to the HST observations in Someone et al., our JWST follow-up reached higher S/N.\",\n",
    "                       \"We were able to reproduce the luminosities from Hubble using our latest models.\",\n",
    "                       \"We overplot Hubble-observed stars from Someone et al. in Figure 3b.\",\n",
    "                       \"We built the spectral templates using UV data in the Hubble archive.\",\n",
    "                       \"We simulate what our future HST observations will look like to predict the S/N.\",\n",
    "                       \"Our work here with JWST is inspired by our earlier HST study published in 2010.\",\n",
    "                       \"We therefore use the Hubble statistics from Author et al. to guide our stellar predictions.\",\n",
    "                       \"The stars in Figure 3 were plotted based on the HST-fitted trend line in Person et al.\",\n",
    "                       \"The final step is to use the HST exposure tool to put our modeled images in context.\"],\n",
    "                 \"mention\":[\"Person et al. used HST to measure the Hubble constant.\",\n",
    "                        \"We will present new HST observations in a future work.\",\n",
    "                        \"HST is a fantastic instrument that has revolutionized our view of space.\",\n",
    "                        \"The Hubble Space Telescope (HST) has its mission center at the STScI.\",\n",
    "                        \"We can use HST to power a variety of science in the ultraviolet regime.\",\n",
    "                        \"It is not clear when the star will be observable with HST.\",\n",
    "                        \"More data can be found and downloaded from the Hubble archive.\",\n",
    "                        \"We note that HST can be used to observe the stars as well, at higher S/N.\",\n",
    "                        \"However, we ended up using the JWST rather than HST observations in this work.\",\n",
    "                        \"We push the analysis of the Hubble component of the dataset to a future study.\",\n",
    "                        \"We expect the HST observations to be released in the fall.\",\n",
    "                        \"We look forward to any follow-up studies with, e.g., the Hubble Telescope.\"]}\n",
    "    #\n",
    "    #Convert into dictionary with: key:text,class,id,mission structure\n",
    "    i_track = 0\n",
    "    dict_texts = {}\n",
    "    #Store subheadings by mission, to avoid duplicating and processing the same text across different missions\n",
    "    mission = operator_1._fetch_keyword_object(lookup=\"HST\")._get_info(\"name\")\n",
    "    for key in dict_texts_raw:\n",
    "        curr_set = dict_texts_raw[key]\n",
    "        for ii in range(0, len(curr_set)):\n",
    "            dict_texts[str(i_track)] = {\"text\":curr_set[ii], \"id\":\"{0}_{1}\".format(key, ii), \"bibcode\":str(i_track),\n",
    "                                        \"missions\":{mission:{\"mission\":mission, \"class\":key}}}\n",
    "            i_track += 1\n",
    "    #\n",
    "    print(\"Mission: {0}\".format(mission))\n",
    "    print(\"Number of texts in text set: {0}\".format(len(dict_texts)))\n",
    "    print(\"\")\n",
    "    for key in dict_texts:\n",
    "        print(dict_texts[key])\n",
    "        print(\"-\")\n",
    "    #\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eacfa22-ba0d-48e2-b878-e6e665b61e3b",
   "metadata": {},
   "source": [
    "Next, let's prepare some additional information for each of these classifiers.  We'll need to set, for example, the uncertainty thresholds for accepting or rejecting each classifier's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52317109-f682-4555-a6fe-187424b69116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store texts for each operator and its internal classifier\n",
    "#For operator 1\n",
    "dict_texts_1 = dict_texts #Dictionary of texts to classify\n",
    "\n",
    "#For operator 2\n",
    "dict_texts_2 = dict_texts #Dictionary of texts to classify\n",
    "\n",
    "#Gather into list\n",
    "list_dict_texts = [dict_texts_1, dict_texts_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc781e0-10f6-4eee-a431-23727b1ef0e2",
   "metadata": {},
   "source": [
    "Now, let's evaluate the performance of these classifiers in different ways.  We will consider these performance tests:\n",
    "* Basic: We generate confusion matrices for the set of Operators (containing the different classifiers).\n",
    "* Uncertainty: We plot performance as a function of uncertainty level for the set of Operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09831c4e-c557-4f2d-87fe-134a12329bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an instance of the Performance class\n",
    "performer = bibcat.Performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf1be08",
   "metadata": {},
   "source": [
    "The Basic evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c73bc293-bb66-4d66-bb0e-6643a1e15ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Running evaluate_performance_basic()!\n",
      "Generating evaluation for the given operators...\n",
      "\n",
      "> Running _generate_evaluation()!\n",
      "Iterating through Operators to classify each set of text...\n",
      "Classifying with Operator #0...\n",
      "\n",
      "> Running classify_set()!\n",
      "~: Hubble\n",
      "~: Webb Telescope\n",
      "~: Transiting Exoplanet Survey Satellite\n",
      "~: Kepler\n",
      "~: Pan-STARRS\n",
      "~: Galaxy Evolution Explorer\n",
      "~: K2\n",
      "~: Hubble Legacy Archive\n",
      "Classification for text #1 of 10 complete...\n",
      "~: Hubble\n",
      "~: Webb Telescope\n",
      "~: Transiting Exoplanet Survey Satellite\n",
      "~: Kepler\n",
      "~: Pan-STARRS\n",
      "~: Galaxy Evolution Explorer\n",
      "~: K2\n",
      "~: Hubble Legacy Archive\n",
      "Classification for text #2 of 10 complete...\n",
      "~: Hubble\n",
      "~: Webb Telescope\n",
      "~: Transiting Exoplanet Survey Satellite\n",
      "~: Kepler\n",
      "~: Pan-STARRS\n",
      "~: Galaxy Evolution Explorer\n",
      "~: K2\n",
      "~: Hubble Legacy Archive\n",
      "Classification for text #3 of 10 complete...\n",
      "~: Hubble\n",
      "~: Webb Telescope\n",
      "~: Transiting Exoplanet Survey Satellite\n",
      "~: Kepler\n",
      "~: Pan-STARRS\n",
      "~: Galaxy Evolution Explorer\n",
      "~: K2\n",
      "~: Hubble Legacy Archive\n",
      "Classification for text #4 of 10 complete...\n",
      "~: Hubble\n",
      "~: Webb Telescope\n",
      "~: Transiting Exoplanet Survey Satellite\n",
      "~: Kepler\n",
      "~: Pan-STARRS\n",
      "~: Galaxy Evolution Explorer\n",
      "~: K2\n",
      "~: Hubble Legacy Archive\n",
      "Classification for text #5 of 10 complete...\n",
      "~: Hubble\n",
      "~: Webb Telescope\n",
      "~: Transiting Exoplanet Survey Satellite\n",
      "~: Kepler\n",
      "~: Pan-STARRS\n",
      "~: Galaxy Evolution Explorer\n",
      "~: K2\n",
      "~: Hubble Legacy Archive\n",
      "Classification for text #6 of 10 complete...\n",
      "~: Hubble\n",
      "~: Webb Telescope\n",
      "~: Transiting Exoplanet Survey Satellite\n",
      "~: Kepler\n",
      "~: Pan-STARRS\n",
      "~: Galaxy Evolution Explorer\n",
      "~: K2\n",
      "~: Hubble Legacy Archive\n",
      "Classification for text #7 of 10 complete...\n",
      "~: Hubble\n",
      "~: Webb Telescope\n",
      "~: Transiting Exoplanet Survey Satellite\n",
      "~: Kepler\n",
      "~: Pan-STARRS\n",
      "~: Galaxy Evolution Explorer\n",
      "~: K2\n",
      "~: Hubble Legacy Archive\n",
      "Classification for text #8 of 10 complete...\n",
      "~: Hubble\n",
      "~: Webb Telescope\n",
      "~: Transiting Exoplanet Survey Satellite\n",
      "~: Kepler\n",
      "~: Pan-STARRS\n",
      "~: Galaxy Evolution Explorer\n",
      "~: K2\n",
      "~: Hubble Legacy Archive\n",
      "Classification for text #9 of 10 complete...\n",
      "~: Hubble\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "ValueError('Err: Unrecognized ambig. phrase:\\nHubble sequence\\nTaken from this text snippet:\\nOnly with accurate information of Galactic bar/bulge and spiral arms can we pinpoint the exact location of the Milky Way in the Hubble sequence of spiral galaxies.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "~: Webb Telescope\n",
      "~: Transiting Exoplanet Survey Satellite\n",
      "~: Kepler\n",
      "~: Pan-STARRS\n",
      "~: Galaxy Evolution Explorer\n",
      "~: K2\n",
      "~: Hubble Legacy Archive\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "ValueError('Err: Unrecognized ambig. phrase:\\nHubble sequence\\nTaken from this text snippet:\\nOnly with accurate information of Galactic bar/bulge and spiral arms can we pinpoint the exact location of the Milky Way in the Hubble sequence of spiral galaxies.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #10 of 10 complete...\n",
      "\n",
      "Run of classify_set() complete!\n",
      "\n",
      "Classification complete for Operator #0.\n",
      "Generating the performance counter...\n",
      "\n",
      "> Running _generate_performance_counter()!\n",
      "Accumulating performance over 10 texts.\n",
      "Actual class names: ['datainfluenced', 'mention', 'science', 'other', 'znotmatch']\n",
      "Measured class names: ['datainfluenced', 'mention', 'science', 'other', 'zerror', 'zlowprob', 'znotmatch']\n",
      "\n",
      "-\n",
      "Performance counter generated:\n",
      "Actual datainfluenced total: 0\n",
      "Actual datainfluenced vs Measured datainfluenced: 0\n",
      "Actual datainfluenced vs Measured mention: 0\n",
      "Actual datainfluenced vs Measured science: 0\n",
      "Actual datainfluenced vs Measured other: 0\n",
      "Actual datainfluenced vs Measured zerror: 0\n",
      "Actual datainfluenced vs Measured zlowprob: 0\n",
      "Actual datainfluenced vs Measured znotmatch: 0\n",
      "Actual datainfluenced vs Measured _total: 0\n",
      "Actual mention total: 6\n",
      "Actual mention vs Measured datainfluenced: 0\n",
      "Actual mention vs Measured mention: 0\n",
      "Actual mention vs Measured science: 0\n",
      "Actual mention vs Measured other: 0\n",
      "Actual mention vs Measured zerror: 0\n",
      "Actual mention vs Measured zlowprob: 6\n",
      "Actual mention vs Measured znotmatch: 0\n",
      "Actual mention vs Measured _total: 6\n",
      "Actual science total: 3\n",
      "Actual science vs Measured datainfluenced: 0\n",
      "Actual science vs Measured mention: 0\n",
      "Actual science vs Measured science: 0\n",
      "Actual science vs Measured other: 0\n",
      "Actual science vs Measured zerror: 0\n",
      "Actual science vs Measured zlowprob: 3\n",
      "Actual science vs Measured znotmatch: 0\n",
      "Actual science vs Measured _total: 3\n",
      "Actual other total: 0\n",
      "Actual other vs Measured datainfluenced: 0\n",
      "Actual other vs Measured mention: 0\n",
      "Actual other vs Measured science: 0\n",
      "Actual other vs Measured other: 0\n",
      "Actual other vs Measured zerror: 0\n",
      "Actual other vs Measured zlowprob: 0\n",
      "Actual other vs Measured znotmatch: 0\n",
      "Actual other vs Measured _total: 0\n",
      "Actual znotmatch total: 71\n",
      "Actual znotmatch vs Measured datainfluenced: 0\n",
      "Actual znotmatch vs Measured mention: 2\n",
      "Actual znotmatch vs Measured science: 0\n",
      "Actual znotmatch vs Measured other: 0\n",
      "Actual znotmatch vs Measured zerror: 2\n",
      "Actual znotmatch vs Measured zlowprob: 8\n",
      "Actual znotmatch vs Measured znotmatch: 59\n",
      "Actual znotmatch vs Measured _total: 71\n",
      "\n",
      "-\n",
      "\n",
      "Run of _generate_performance_counter() complete!\n",
      "Performance counter complete.\n",
      "Saving misclassifications...\n",
      "\n",
      "Misclassifications saved at: /Users/jamila.pegues/Documents/STScI_Fellowship/Functional/Library/BibTracking/repo_stsci/bibcat/output/test_misclassif_basic_Operator_ML.txt\n",
      "All work complete for Operator #0.\n",
      "Classifying with Operator #1...\n",
      "\n",
      "> Running classify_set()!\n",
      "~: Hubble\n",
      "~: Webb Telescope\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamila.pegues/Documents/STScI_Fellowship/Functional/Library/BibTracking/repo_stsci/bibcat/src/bibcat_classes.py:5314: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  (np.abs(tmp_unnorm - curr_scores[other_key])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~: Transiting Exoplanet Survey Satellite\n",
      "~: Kepler\n",
      "~: Pan-STARRS\n",
      "~: Galaxy Evolution Explorer\n",
      "~: K2\n",
      "~: Hubble Legacy Archive\n",
      "Classification for text #1 of 10 complete...\n",
      "~: Hubble\n",
      "~: Webb Telescope\n",
      "~: Transiting Exoplanet Survey Satellite\n",
      "~: Kepler\n",
      "~: Pan-STARRS\n",
      "~: Galaxy Evolution Explorer\n",
      "~: K2\n",
      "~: Hubble Legacy Archive\n",
      "Classification for text #2 of 10 complete...\n",
      "~: Hubble\n",
      "~: Webb Telescope\n",
      "~: Transiting Exoplanet Survey Satellite\n",
      "~: Kepler\n",
      "~: Pan-STARRS\n",
      "~: Galaxy Evolution Explorer\n",
      "~: K2\n",
      "~: Hubble Legacy Archive\n",
      "Classification for text #3 of 10 complete...\n",
      "~: Hubble\n",
      "~: Webb Telescope\n",
      "~: Transiting Exoplanet Survey Satellite\n",
      "~: Kepler\n",
      "~: Pan-STARRS\n",
      "~: Galaxy Evolution Explorer\n",
      "~: K2\n",
      "~: Hubble Legacy Archive\n",
      "Classification for text #4 of 10 complete...\n",
      "~: Hubble\n",
      "~: Webb Telescope\n",
      "~: Transiting Exoplanet Survey Satellite\n",
      "~: Kepler\n",
      "~: Pan-STARRS\n",
      "~: Galaxy Evolution Explorer\n",
      "~: K2\n",
      "~: Hubble Legacy Archive\n",
      "Classification for text #5 of 10 complete...\n",
      "~: Hubble\n",
      "~: Webb Telescope\n",
      "~: Transiting Exoplanet Survey Satellite\n",
      "~: Kepler\n",
      "~: Pan-STARRS\n",
      "~: Galaxy Evolution Explorer\n",
      "~: K2\n",
      "~: Hubble Legacy Archive\n",
      "Classification for text #6 of 10 complete...\n",
      "~: Hubble\n",
      "~: Webb Telescope\n",
      "~: Transiting Exoplanet Survey Satellite\n",
      "~: Kepler\n",
      "~: Pan-STARRS\n",
      "~: Galaxy Evolution Explorer\n",
      "~: K2\n",
      "~: Hubble Legacy Archive\n",
      "Classification for text #7 of 10 complete...\n",
      "~: Hubble\n",
      "~: Webb Telescope\n",
      "~: Transiting Exoplanet Survey Satellite\n",
      "~: Kepler\n",
      "~: Pan-STARRS\n",
      "~: Galaxy Evolution Explorer\n",
      "~: K2\n",
      "~: Hubble Legacy Archive\n",
      "Classification for text #8 of 10 complete...\n",
      "~: Hubble\n",
      "~: Webb Telescope\n",
      "~: Transiting Exoplanet Survey Satellite\n",
      "~: Kepler\n",
      "~: Pan-STARRS\n",
      "~: Galaxy Evolution Explorer\n",
      "~: K2\n",
      "~: Hubble Legacy Archive\n",
      "Classification for text #9 of 10 complete...\n",
      "~: Hubble\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "ValueError('Err: Unrecognized ambig. phrase:\\nHubble sequence\\nTaken from this text snippet:\\nOnly with accurate information of Galactic bar/bulge and spiral arms can we pinpoint the exact location of the Milky Way in the Hubble sequence of spiral galaxies.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "~: Webb Telescope\n",
      "~: Transiting Exoplanet Survey Satellite\n",
      "~: Kepler\n",
      "~: Pan-STARRS\n",
      "~: Galaxy Evolution Explorer\n",
      "~: K2\n",
      "~: Hubble Legacy Archive\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "ValueError('Err: Unrecognized ambig. phrase:\\nHubble sequence\\nTaken from this text snippet:\\nOnly with accurate information of Galactic bar/bulge and spiral arms can we pinpoint the exact location of the Milky Way in the Hubble sequence of spiral galaxies.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #10 of 10 complete...\n",
      "\n",
      "Run of classify_set() complete!\n",
      "\n",
      "Classification complete for Operator #1.\n",
      "Generating the performance counter...\n",
      "\n",
      "> Running _generate_performance_counter()!\n",
      "Accumulating performance over 10 texts.\n",
      "Actual class names: ['datainfluenced', 'mention', 'science', 'other', 'znotmatch']\n",
      "Measured class names: ['datainfluenced', 'mention', 'science', 'other', 'zerror', 'zlowprob', 'znotmatch']\n",
      "\n",
      "-\n",
      "Performance counter generated:\n",
      "Actual datainfluenced total: 0\n",
      "Actual datainfluenced vs Measured datainfluenced: 0\n",
      "Actual datainfluenced vs Measured mention: 0\n",
      "Actual datainfluenced vs Measured science: 0\n",
      "Actual datainfluenced vs Measured other: 0\n",
      "Actual datainfluenced vs Measured zerror: 0\n",
      "Actual datainfluenced vs Measured zlowprob: 0\n",
      "Actual datainfluenced vs Measured znotmatch: 0\n",
      "Actual datainfluenced vs Measured _total: 0\n",
      "Actual mention total: 6\n",
      "Actual mention vs Measured datainfluenced: 0\n",
      "Actual mention vs Measured mention: 4\n",
      "Actual mention vs Measured science: 0\n",
      "Actual mention vs Measured other: 0\n",
      "Actual mention vs Measured zerror: 0\n",
      "Actual mention vs Measured zlowprob: 2\n",
      "Actual mention vs Measured znotmatch: 0\n",
      "Actual mention vs Measured _total: 6\n",
      "Actual science total: 3\n",
      "Actual science vs Measured datainfluenced: 0\n",
      "Actual science vs Measured mention: 0\n",
      "Actual science vs Measured science: 1\n",
      "Actual science vs Measured other: 0\n",
      "Actual science vs Measured zerror: 0\n",
      "Actual science vs Measured zlowprob: 2\n",
      "Actual science vs Measured znotmatch: 0\n",
      "Actual science vs Measured _total: 3\n",
      "Actual other total: 0\n",
      "Actual other vs Measured datainfluenced: 0\n",
      "Actual other vs Measured mention: 0\n",
      "Actual other vs Measured science: 0\n",
      "Actual other vs Measured other: 0\n",
      "Actual other vs Measured zerror: 0\n",
      "Actual other vs Measured zlowprob: 0\n",
      "Actual other vs Measured znotmatch: 0\n",
      "Actual other vs Measured _total: 0\n",
      "Actual znotmatch total: 71\n",
      "Actual znotmatch vs Measured datainfluenced: 0\n",
      "Actual znotmatch vs Measured mention: 5\n",
      "Actual znotmatch vs Measured science: 0\n",
      "Actual znotmatch vs Measured other: 0\n",
      "Actual znotmatch vs Measured zerror: 4\n",
      "Actual znotmatch vs Measured zlowprob: 3\n",
      "Actual znotmatch vs Measured znotmatch: 59\n",
      "Actual znotmatch vs Measured _total: 71\n",
      "\n",
      "-\n",
      "\n",
      "Run of _generate_performance_counter() complete!\n",
      "Performance counter complete.\n",
      "Saving misclassifications...\n",
      "\n",
      "Misclassifications saved at: /Users/jamila.pegues/Documents/STScI_Fellowship/Functional/Library/BibTracking/repo_stsci/bibcat/output/test_misclassif_basic_Operator_RB.txt\n",
      "All work complete for Operator #1.\n",
      "!\n",
      "\n",
      "Evaluation saved at: /Users/jamila.pegues/Documents/STScI_Fellowship/Functional/Library/BibTracking/repo_stsci/bibcat/output/test_eval_basic.npy\n",
      "\n",
      "Run of _generate_evaluation() complete!\n",
      "\n",
      "Evaluations generated.\n",
      "Plotting confusion matrices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamila.pegues/Documents/STScI_Fellowship/Functional/Library/BibTracking/repo_stsci/bibcat/src/bibcat_classes.py:7129: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  confmatr_norm[yy,xx] = (confmatr_abs[yy,xx] / curr_total)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrices have been plotted at:\n",
      "/Users/jamila.pegues/Documents/STScI_Fellowship/Functional/Library/BibTracking/repo_stsci/bibcat/output\n",
      "\n",
      "Run of evaluate_performance_basic() complete!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'woo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-57aca2617cbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                      \u001b[0mfileroot_evaluation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfileroot_evaluation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileroot_misclassif\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfileroot_misclassif\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                      print_freq=1, do_verbose=True, do_verbose_deep=False, figsize=figsize)\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwoo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'woo' is not defined"
     ]
    }
   ],
   "source": [
    "#Parameters for this evaluation\n",
    "fileroot_evaluation = \"test_eval_basic\" #Root name of the file within which to store the performance evaluation output\n",
    "fileroot_misclassif = \"test_misclassif_basic\" #Root name of the file within which to store misclassified text information\n",
    "figsize = (20, 12)\n",
    "\n",
    "#Run the pipeline for a basic evaluation of model performance\n",
    "performer.evaluate_performance_basic(operators=list_operators, dicts_texts=list_dict_texts, mappers=list_mappers,\n",
    "                                     thresholds=list_thresholds, buffers=list_buffers, is_text_processed=False,\n",
    "                                     do_verify_truematch=do_verify_truematch, do_raise_innererror=do_raise_innererror,\n",
    "                                     do_save_evaluation=True, do_save_misclassif=True, filepath_output=filepath_output,\n",
    "                                     fileroot_evaluation=fileroot_evaluation, fileroot_misclassif=fileroot_misclassif,\n",
    "                                     print_freq=1, do_verbose=True, do_verbose_deep=False, figsize=figsize)\n",
    "print(woo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f12f0d3",
   "metadata": {},
   "source": [
    "The Uncertainty evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68ae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters for this evaluation\n",
    "fileroot_evaluation = \"test_eval_uncertainty\" #Root name of the file within which to store the performance evaluation output\n",
    "fileroot_misclassif = \"test_misclassif_uncertainty\" #Root name of the file within which to store misclassified text information\n",
    "figsize = (40, 12)\n",
    "\n",
    "#Run the pipeline for an evaluation of model performance as a function of uncertainty\n",
    "performer.evaluate_performance_uncertainty(operators=list_operators, dicts_texts=list_dict_texts, mappers=list_mappers,\n",
    "                                     threshold_arrays=list_threshold_arrays, buffers=list_buffers,\n",
    "                                     is_text_processed=False,\n",
    "                                     do_verify_truematch=do_verify_truematch, do_raise_innererror=do_raise_innererror,\n",
    "                                     do_save_evaluation=True, do_save_misclassif=True, filepath_output=filepath_output,\n",
    "                                     fileroot_evaluation=fileroot_evaluation, fileroot_misclassif=fileroot_misclassif,\n",
    "                                     print_freq=25, do_verbose=True, do_verbose_deep=False, figsize=figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3ceb74-7087-4256-8044-59f4cb97db51",
   "metadata": {},
   "source": [
    "And with that, you should have new confusion matrices summarizing the basic performance for these classifiers saved in your requested directory!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee10749-9dc1-4460-a34c-18ecb413f450",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c8f912-089e-462c-b345-9710f35a03f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set end marker for this tutorial.\n",
    "print(\"This tutorial completed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
