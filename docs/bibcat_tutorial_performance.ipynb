{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e71ff86",
   "metadata": {},
   "source": [
    "# Bibliography Categorization: 'BibCat'\n",
    "## Tutorial: Estimating performance of classifiers in bibcat.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3ab7e4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d234a479",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction.\n",
    "\n",
    "In this tutorial, we will use bibcat to estimate the performance of classifiers on sets of texts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f050727",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86289680",
   "metadata": {},
   "source": [
    "## User Workflow: Training a machine learning (ML) model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af236d7a",
   "metadata": {},
   "source": [
    "The `Performance` class contains user-friendly methods for estimating the performance of given classifiers and outputting that performance as, e.g., confusion matrices.  We overview how this method can be run in the code blocks below.\n",
    "\n",
    "For this tutorial, we assume that the user has already run the trainML tutorial, and so has generated and saved a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fdea077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import external packages\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "272dbb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: /Users/jamila.pegues/Documents/STScI_Fellowship/Functional/Library/BibTracking/repo_stsci/bibcat/docs\n",
      "Source directory: /Users/jamila.pegues/Documents/STScI_Fellowship/Functional/Library/BibTracking/repo_stsci/bibcat/src\n"
     ]
    }
   ],
   "source": [
    "# Set up for fetching necessary bibcat modules for the tutorial\n",
    "# Check work directories: src/ is where all source python scripts are available. \n",
    "current_dir= os.path.dirname(os.path.abspath('__file__'))\n",
    "_parent = os.path.dirname(current_dir)\n",
    "src_dir = os.path.join(_parent, \"src\")\n",
    "\n",
    "print(f'Current Directory: {current_dir}')\n",
    "print(f'Source directory: {src_dir}')\n",
    "\n",
    "# move to the ../src/ directory to import necessary modules. \n",
    "os.chdir(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d040df1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root directory =/Users/jamila.pegues/Documents/STScI_Fellowship/Functional/Library/BibTracking/repo_stsci/bibcat/src, parent directory=/Users/jamila.pegues/Documents/STScI_Fellowship/Functional/Library/BibTracking/repo_stsci/bibcat\n",
      "/Users/jamila.pegues/Documents/STScI_Fellowship/Functional/Library/BibTracking/repo_stsci/bibcat/src/models folder already exists.\n",
      "/Users/jamila.pegues/Documents/STScI_Fellowship/Functional/Library/BibTracking/repo_stsci/bibcat/output folder already exists.\n"
     ]
    }
   ],
   "source": [
    "#Import bibcat packages\n",
    "import bibcat_classes as bibcat\n",
    "import bibcat_config as config\n",
    "import bibcat_parameters as params #Temporary file until contents moved elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef0edceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set parameters for each operator and its internal classifier\n",
    "#Global parameters\n",
    "do_verify_truematch = True #A very important parameter - discuss with J.P. first!!!  Set it to either True or False.\n",
    "do_raise_innererror = False #If True, will stop if exception encountered; if False, will print error and continue\n",
    "do_reuse_run = True\n",
    "#\n",
    "do_include_trainML_unused_bibcodes_in_testset = False #If True, will include the bibcodes from the trainML tutorial that were skipped because e.g. not target missions\n",
    "#\n",
    "list_threshold_arrays = [np.arange(0.35, 0.95+0.05, 0.05)]*2 #For uncertainty test\n",
    "class_mapper = params.map_papertypes #Mapper for class types; None for no mapper\n",
    "fileroot_evaluation = \"test_eval\" #Root name of the file within which to store the performance evaluation output\n",
    "threshold = 0.7 #0.9\n",
    "\n",
    "#For operator 1\n",
    "mapper_1 = class_mapper #Mapper to mask classifications; None if no masking\n",
    "threshold_1 = threshold #Uncertainty threshold for this classifier\n",
    "buffer_1 = 0\n",
    "\n",
    "#For operator 2\n",
    "mapper_2 = class_mapper #Mapper to mask classifications; None if no masking\n",
    "threshold_2 = threshold #Uncertainty threshold for this classifier\n",
    "buffer_2 = 0\n",
    "\n",
    "#Gather parameters into lists\n",
    "list_mappers = [mapper_1, mapper_2]\n",
    "list_thresholds = [threshold_1, threshold_2]\n",
    "list_buffers = [buffer_1, buffer_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9e0a06e-61fc-438a-b642-3669910f9b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set some overarching global variables\n",
    "seed_test = 20 #Random seed for shuffling text dataset\n",
    "np.random.seed(seed_test)\n",
    "do_shuffle = True #Whether or not to shuffle the text dataset\n",
    "do_real_testdata = True #If True, will use real papers to test performance; if False, will use fake texts below\n",
    "#\n",
    "max_tests = 500 #None #100 #Number of text entries to test the performance for; None for all tests available\n",
    "mode_modif = \"none\" #\"skim_anon\" #\"skim_trim_anon\" #None #We are using preprocessed data in this tutorial, so we do not need a processing mode at all\n",
    "target_classifs_basic = [\"science\", \"mention\", \"datainfluenced\"]\n",
    "target_classifs_uncertainty = [\"science\", \"mention\", \"datainfluenced\", \"other\", \"zlowprob\"]\n",
    "minmax_exclude_classifs = ([item.lower().replace(\"_\",\"\") for item in config.list_other_verdicts] + [\"other\"])\n",
    "\n",
    "#\n",
    "#Prepare some Keyword objects\n",
    "all_kobjs = params.all_kobjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "710913d3-0a11-4cda-8971-1b845d542fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output will be saved to: /Users/jamila.pegues/Documents/STScI_Fellowship/Functional/Library/BibTracking/repo_stsci/bibcat/src/models/test_run_rule/output\n"
     ]
    }
   ],
   "source": [
    "#Fetch filepaths for model and data\n",
    "name_model = config.name_model\n",
    "filepath_json = config.path_json\n",
    "dir_model = os.path.join(config.dir_allmodels, name_model)\n",
    "#\n",
    "#Set filepath for unused bibcodes from trainML, if so requested\n",
    "if do_include_trainML_unused_bibcodes_in_testset:\n",
    "    filesave_unused_bibcodes = os.path.join(dir_model,\n",
    "                              \"{0}_bibcodes_unused_during_trainML.npy\".format(name_model)) #Where to save processing errors\n",
    "#\n",
    "#Set and create (as needed) directories for storing performance output\n",
    "filepath_output = os.path.join(dir_model, \"output\") #Where to store performance output, such as confusion matrices\n",
    "if (not os.path.exists(filepath_output)):\n",
    "    os.makedirs(filepath_output)\n",
    "    print(\"Output folder created at: {0}\".format(filepath_output))\n",
    "print(\"Output will be saved to: {0}\".format(filepath_output))\n",
    "#\n",
    "#Set directories for fetching text\n",
    "dir_info = dir_model\n",
    "folder_test = config.folders_TVT[\"test\"]\n",
    "dir_test = os.path.join(dir_model, folder_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0188dbd8-388d-4f8e-95e9-ebede99435c2",
   "metadata": {},
   "source": [
    "Let's build a set of classifiers for which we'd like to test the performance.  We'll then feed each of those classifiers into an instance of the Operator class to handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "116fd35a-994f-452c-87dc-233733ab8749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of classifiers\n",
    "#This can be modified to use whatever classifiers you'd like.\n",
    "#Load a previously trained ML model\n",
    "filepath_model = os.path.join(dir_model, (name_model+\".npy\"))\n",
    "fileloc_ML = os.path.join(dir_model, (config.tfoutput_prefix+name_model))\n",
    "# !!! classifier_ML = bibcat.Classifier_ML(filepath_model=filepath_model, fileloc_ML=fileloc_ML, do_verbose=True)\n",
    "#\n",
    "\n",
    "#Load a rule-based classifier\n",
    "classifier_rules = bibcat.Classifier_Rules()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e4a36a1-e8cc-4576-8aab-904f61813988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance of Operator successfully initialized!\n",
      "Keyword objects:\n",
      "0: Keyword Object:\n",
      "Name: Hubble\n",
      "Keywords: ['Hubble Space Telescope', 'Hubble Telescope', 'Hubble']\n",
      "Acronyms: ['HST', 'HT']\n",
      "Banned Overlap: ['Hubble Legacy Archive']\n",
      "\n",
      "1: Keyword Object:\n",
      "Name: Webb Telescope\n",
      "Keywords: ['James Webb Space Telescope', 'Webb Space Telescope', 'James Webb Telescope', 'Webb Telescope']\n",
      "Acronyms: ['JWST', 'JST', 'JT']\n",
      "Banned Overlap: []\n",
      "\n",
      "2: Keyword Object:\n",
      "Name: Transiting Exoplanet Survey Satellite\n",
      "Keywords: ['Transiting Exoplanet Survey Satellite']\n",
      "Acronyms: ['TESS']\n",
      "Banned Overlap: []\n",
      "\n",
      "3: Keyword Object:\n",
      "Name: Kepler\n",
      "Keywords: ['Kepler']\n",
      "Acronyms: []\n",
      "Banned Overlap: []\n",
      "\n",
      "4: Keyword Object:\n",
      "Name: Pan-STARRS\n",
      "Keywords: ['Panoramic Survey Telescope and Rapid Response System', 'Pan-STARRS1', 'Pan-STARRS']\n",
      "Acronyms: ['PanSTARRS1', 'PanSTARRS', 'PS1']\n",
      "Banned Overlap: []\n",
      "\n",
      "5: Keyword Object:\n",
      "Name: Galaxy Evolution Explorer\n",
      "Keywords: ['Galaxy Evolution Explorer']\n",
      "Acronyms: ['GALEX']\n",
      "Banned Overlap: []\n",
      "\n",
      "6: Keyword Object:\n",
      "Name: K2\n",
      "Keywords: ['K2']\n",
      "Acronyms: []\n",
      "Banned Overlap: []\n",
      "\n",
      "7: Keyword Object:\n",
      "Name: Hubble Legacy Archive\n",
      "Keywords: ['Hubble Legacy Archive']\n",
      "Acronyms: ['HLA']\n",
      "Banned Overlap: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load models into instances of the Operator class\n",
    "# !!! operator_1 = bibcat.Operator(classifier=classifier_ML, mode=mode_modif, keyword_objs=all_kobjs,\n",
    "#                            name=\"Operator_ML\", do_verbose=True, load_check_truematch=True, do_verbose_deep=False)\n",
    "operator_2 = bibcat.Operator(classifier=classifier_rules,\n",
    "                            name=\"Operator_RB\", mode=mode_modif, keyword_objs=all_kobjs,\n",
    "                            do_verbose=True, do_verbose_deep=False)\n",
    "list_operators = [operator_2] #[operator_1, operator_2] #Feel free to add more/less operators here.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82951251-fc59-4e33-a978-bc8fa16915dd",
   "metadata": {},
   "source": [
    "Now, let's fetch some text for our classifiers to classify. For this tutorial, we'll load previously processed texts from the directory containing the test set for the ML classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8075c1f-bc7b-422e-89cc-82fac058bb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts in text set: 500\n"
     ]
    }
   ],
   "source": [
    "#For use of real papers from test dataset to test on\n",
    "if (do_real_testdata and ((not do_reuse_run) or (not os.path.exists(os.path.join(filepath_output, (fileroot_evaluation+\".npy\")))))):\n",
    "    #Load information for processed bibcodes reserved for testing\n",
    "    dict_TVTinfo = np.load(os.path.join(dir_info, \"dict_TVTinfo.npy\"), allow_pickle=True).item()\n",
    "    list_test_bibcodes = [key for key in dict_TVTinfo if (dict_TVTinfo[key][\"folder_TVT\"] == folder_test)]\n",
    "    \n",
    "    #Load the original data\n",
    "    with open(filepath_json, 'r') as openfile:\n",
    "        dataset = json.load(openfile)\n",
    "    #\n",
    "    \n",
    "    #Extract text information for the bibcodes reserved for testing\n",
    "    list_test_indanddata_raw = [(ii, dataset[ii]) for ii in range(0, len(dataset))\n",
    "                                if (dataset[ii][\"bibcode\"] in list_test_bibcodes)] #Data for test set\n",
    "    #\n",
    "    #Add in unused bibcodes from trainML tutorial, if so requested\n",
    "    if do_include_trainML_unused_bibcodes_in_testset:\n",
    "        tmp_dict = np.load(filesave_unused_bibcodes, allow_pickle=True).item()\n",
    "        list_test_indanddata_raw += [(tmp_dict[key], dataset[tmp_dict[key]]) for key in tmp_dict]\n",
    "    #\n",
    "    \n",
    "    #Shuffle, if requested\n",
    "    if do_shuffle:\n",
    "        np.random.shuffle(list_test_indanddata_raw)\n",
    "    #\n",
    "    \n",
    "    #Extract target number of test papers from the test bibcodes\n",
    "    if (max_tests is not None): #Fetch subset of tests\n",
    "        list_test_indanddata = list_test_indanddata_raw[0:max_tests]\n",
    "    else: #Use all tests\n",
    "        list_test_indanddata = list_test_indanddata_raw\n",
    "    #\n",
    "    \n",
    "    #Process the text input into dictionary format for inputting into the codebase\n",
    "    dict_texts = {} #To hold formatted text entries\n",
    "    for ii in range(0, len(list_test_indanddata)):\n",
    "        curr_ind = list_test_indanddata[ii][0]\n",
    "        curr_data = list_test_indanddata[ii][1]\n",
    "        #\n",
    "        #Convert this data entry into dictionary with: key:text,id,bibcode,mission structure\n",
    "        curr_info = {\"text\":curr_data[\"body\"], \"id\":str(curr_ind), \"bibcode\":curr_data[\"bibcode\"],\n",
    "                    \"missions\":{}}\n",
    "        \n",
    "        #Initialize all mission entries as non-matches\n",
    "        for curr_kobj in all_kobjs: #Iterate through declared Keyword objects\n",
    "            curr_name = curr_kobj.get_name()\n",
    "            curr_info[\"missions\"][curr_name] = {\"mission\":curr_name, \"class\":config.verdict_rejection}                    \n",
    "            \n",
    "        #If using unused bibcodes and no class_missions, store as is\n",
    "        if (do_include_trainML_unused_bibcodes_in_testset and (\"class_missions\" not in curr_data)):\n",
    "            #Store this data entry and skip ahead\n",
    "            dict_texts[str(curr_ind)] = curr_info\n",
    "            continue\n",
    "        \n",
    "        #Iterate through missions\n",
    "        for curr_mission in curr_data[\"class_missions\"]: #Iterate through missions for this paper\n",
    "            for curr_kobj in all_kobjs: #Iterate through declared Keyword objects\n",
    "                curr_name = curr_kobj.get_name()\n",
    "                #Store mission data under keyword name, if applicable\n",
    "                if (curr_kobj.identify_keyword(curr_mission)[\"bool\"]):\n",
    "                    curr_info[\"missions\"][curr_name] = {\"mission\":curr_name,\n",
    "                                                    \"class\":curr_data[\"class_missions\"][curr_mission][\"papertype\"]}\n",
    "                #\n",
    "                #Otherwise, store that this mission was not detected for this text\n",
    "                #else:\n",
    "                #    curr_info[\"missions\"][curr_name] = {\"mission\":curr_name, \"class\":config.verdict_rejection}                    \n",
    "            #\n",
    "        #\n",
    "        #Store this data entry\n",
    "        dict_texts[str(curr_ind)] = curr_info\n",
    "    #\n",
    "    \n",
    "    #Print some notes about the testing data\n",
    "    print(\"Number of texts in text set: {0}\".format(len(dict_texts)))\n",
    "    \"\"\"\n",
    "    print(\"\")\n",
    "    for key in dict_texts:\n",
    "        print(\"Entry {0}:\".format(key))\n",
    "        print(\"ID: {0}\".format(dict_texts[key][\"id\"]))\n",
    "        print(\"Bibcode: {0}\".format(dict_texts[key][\"bibcode\"]))\n",
    "        print(\"Missions: {0}\".format(dict_texts[key][\"missions\"]))\n",
    "        print(\"Start of text:\\n{0}\".format(dict_texts[key][\"text\"][0:500]))\n",
    "        print(\"-\\n\")\n",
    "    #\"\"\"\n",
    "#\n",
    "else:\n",
    "    dict_texts = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2194a016-51fc-47fc-a756-7540e5674774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For use of fake, made-up data entries to test on\n",
    "if (not do_real_testdata):\n",
    "    print(\"Using fake test data for testing.\")\n",
    "    #Make some fake data\n",
    "    dict_texts_raw = {\"science\":[\"We present HST observations in Figure 4.\",\n",
    "                        \"The HST stars are listed in Table 3b.\",\n",
    "                        \"Despite our efforts to smooth the data, there are still rings in the HST images.\",\n",
    "                        \"See Section 8c for more discussion of the Hubble images.\",\n",
    "                        \"The supernovae detected with HST tend to be brighter than initially predicted.\",\n",
    "                        \"Our spectra from HST fit well to the standard trend first published in Someone et al. 1990.\",\n",
    "                        \"We use the Hubble Space Telescope to build an ultraviolet database of the target stars.\",\n",
    "                        \"The blue points (HST) exhibit more scatter than the red points (JWST).\",\n",
    "                        \"The benefit, then, is the far higher S/N we achieved in our HST observations.\",\n",
    "                        \"Here we employ the Hubble Telescope to observe the edge of the photon-dominated region.\",\n",
    "                        \"The black line shows that the region targeted with Hubble has an extreme UV signature.\"],\n",
    "                 \"datainfluenced\":[\"The simulated Hubble data is plotted in Figure 4.\",\n",
    "                       \"Compared to the HST observations in Someone et al., our JWST follow-up reached higher S/N.\",\n",
    "                       \"We were able to reproduce the luminosities from Hubble using our latest models.\",\n",
    "                       \"We overplot Hubble-observed stars from Someone et al. in Figure 3b.\",\n",
    "                       \"We built the spectral templates using UV data in the Hubble archive.\",\n",
    "                       \"We simulate what our future HST observations will look like to predict the S/N.\",\n",
    "                       \"Our work here with JWST is inspired by our earlier HST study published in 2010.\",\n",
    "                       \"We therefore use the Hubble statistics from Author et al. to guide our stellar predictions.\",\n",
    "                       \"The stars in Figure 3 were plotted based on the HST-fitted trend line in Person et al.\",\n",
    "                       \"The final step is to use the HST exposure tool to put our modeled images in context.\"],\n",
    "                 \"mention\":[\"Person et al. used HST to measure the Hubble constant.\",\n",
    "                        \"We will present new HST observations in a future work.\",\n",
    "                        \"HST is a fantastic instrument that has revolutionized our view of space.\",\n",
    "                        \"The Hubble Space Telescope (HST) has its mission center at the STScI.\",\n",
    "                        \"We can use HST to power a variety of science in the ultraviolet regime.\",\n",
    "                        \"It is not clear when the star will be observable with HST.\",\n",
    "                        \"More data can be found and downloaded from the Hubble archive.\",\n",
    "                        \"We note that HST can be used to observe the stars as well, at higher S/N.\",\n",
    "                        \"However, we ended up using the JWST rather than HST observations in this work.\",\n",
    "                        \"We push the analysis of the Hubble component of the dataset to a future study.\",\n",
    "                        \"We expect the HST observations to be released in the fall.\",\n",
    "                        \"We look forward to any follow-up studies with, e.g., the Hubble Telescope.\"]}\n",
    "    #\n",
    "    #Convert into dictionary with: key:text,class,id,mission structure\n",
    "    i_track = 0\n",
    "    dict_texts = {}\n",
    "    #Store subheadings by mission, to avoid duplicating and processing the same text across different missions\n",
    "    mission = operator_1._fetch_keyword_object(lookup=\"HST\")._get_info(\"name\")\n",
    "    for key in dict_texts_raw:\n",
    "        curr_set = dict_texts_raw[key]\n",
    "        for ii in range(0, len(curr_set)):\n",
    "            dict_texts[str(i_track)] = {\"text\":curr_set[ii], \"id\":\"{0}_{1}\".format(key, ii), \"bibcode\":str(i_track),\n",
    "                                        \"missions\":{mission:{\"mission\":mission, \"class\":key}}}\n",
    "            i_track += 1\n",
    "    #\n",
    "    print(\"Mission: {0}\".format(mission))\n",
    "    print(\"Number of texts in text set: {0}\".format(len(dict_texts)))\n",
    "    print(\"\")\n",
    "    for key in dict_texts:\n",
    "        print(dict_texts[key])\n",
    "        print(\"-\")\n",
    "    #\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eacfa22-ba0d-48e2-b878-e6e665b61e3b",
   "metadata": {},
   "source": [
    "Next, let's prepare some additional information for each of these classifiers.  We'll need to set, for example, the uncertainty thresholds for accepting or rejecting each classifier's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52317109-f682-4555-a6fe-187424b69116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store texts for each operator and its internal classifier\n",
    "#For operator 1\n",
    "dict_texts_1 = dict_texts #Dictionary of texts to classify\n",
    "\n",
    "#For operator 2\n",
    "dict_texts_2 = dict_texts #Dictionary of texts to classify\n",
    "\n",
    "#Gather into list\n",
    "list_dict_texts = [dict_texts_1, dict_texts_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc781e0-10f6-4eee-a431-23727b1ef0e2",
   "metadata": {},
   "source": [
    "Now, let's evaluate the performance of these classifiers in different ways.  We will consider these performance tests:\n",
    "* Basic: We generate confusion matrices for the set of Operators (containing the different classifiers).\n",
    "* Uncertainty: We plot performance as a function of uncertainty level for the set of Operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09831c4e-c557-4f2d-87fe-134a12329bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an instance of the Performance class\n",
    "performer = bibcat.Performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf1be08",
   "metadata": {},
   "source": [
    "The Basic evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c73bc293-bb66-4d66-bb0e-6643a1e15ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Running evaluate_performance_basic()!\n",
      "Generating classifications for the given operators...\n",
      "\n",
      "> Running _generate_classifications()!\n",
      "Iterating through Operators to classify each set of text...\n",
      "Classifying with Operator #0...\n",
      "\n",
      "> Running classify_set()!\n",
      "Classification for text #1 of 500 complete...\n",
      "Classification for text #2 of 500 complete...\n",
      "Classification for text #3 of 500 complete...\n",
      "Classification for text #4 of 500 complete...\n",
      "Classification for text #5 of 500 complete...\n",
      "Classification for text #6 of 500 complete...\n",
      "Classification for text #7 of 500 complete...\n",
      "Classification for text #8 of 500 complete...\n",
      "Classification for text #9 of 500 complete...\n",
      "Classification for text #10 of 500 complete...\n",
      "Classification for text #11 of 500 complete...\n",
      "Classification for text #12 of 500 complete...\n",
      "Classification for text #13 of 500 complete...\n",
      "Classification for text #14 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nKepler PSF\\nTaken from this text snippet:\\nSince the PSF of TESS is substantially larger than the Kepler PSF and the duration of a typical light curve is much shorter than Kepler ’s four years, the centroid method (Section 000.000 is far less efficient.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #15 of 500 complete...\n",
      "Classification for text #16 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nsimple Kepler solver\\nTaken from this text snippet:\\nThe latter can be a different code, for example, a simple Kepler solver or some high-order symplectic N -body solver.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #17 of 500 complete...\n",
      "Classification for text #18 of 500 complete...\n",
      "Classification for text #19 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nmany Kepler rapid rotators\\nTaken from this text snippet:\\nIf the star is actually an unresolved binary, as could be the case for many Kepler rapid rotators, it would likely be tidally locked, decoupling P rot from age, causing the predictions of gyrochronology models to fail.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #20 of 500 complete...\n",
      "Classification for text #21 of 500 complete...\n",
      "Classification for text #22 of 500 complete...\n",
      "Classification for text #23 of 500 complete...\n",
      "Classification for text #24 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nsignificant Hubble tension\\nTaken from this text snippet:\\nIn particular, we emphasize that the statistically significant Hubble tension does not appear in this model but does exist in the standard ΛCDM model, independently showing ΛCDM to be invalid.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #25 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nPHANGS - HST\\nTaken from this text snippet:\\nLarge imaging surveys using the Hubble Space Telescope (HST) have made significant progress in cataloging and characterizing star cluster populations in nearby 000–000 Mpc) galaxies (e.g, LEGUS, PHANGS-HST; Adamoetal 000; Leeetal 000.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #26 of 500 complete...\n",
      "Classification for text #27 of 500 complete...\n",
      "Classification for text #28 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHubble users\\nTaken from this text snippet:\\nSome are relatively “standard” and familiar to Hubble users, but offered with unprecedented sensitivity and wavelength coverage: e.g. imaging, long-slit spectroscopy, Lyot coronagraphy with occulting spots – while other capabilities are being offered for the first time in a space facility at these wavelengths: multi-object spectroscopy with a programmable shutter array, integral field spectroscopy, and high-contrast imaging through the use of aperture masking interferometry (NIRISS) or 000-quadrant phase masks (4QPM, MIRI).')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #29 of 500 complete...\n",
      "Classification for text #30 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHubble flow\\nTaken from this text snippet:\\nHowever, as shown by deviations of galaxy recession velocities from the Hubble flow and via direct galaxy catalogs, the local universe is lumpy 000% fluctuations or more) on length scales as large as 000 Mpc. 000 000 This is not at all surprising given the 000 Mpc Baryon Acoustic Oscillations (BAO) length scale.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #31 of 500 complete...\n",
      "Classification for text #32 of 500 complete...\n",
      "Classification for text #33 of 500 complete...\n",
      "Classification for text #34 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHubble type\\nTaken from this text snippet:\\nThis is in contrast to results based on CALIFA data, which did not find any correlation between the metallicity gradient and Hubble type (Sánchezetal 000; Sánchez-Menguianoetal 000.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #35 of 500 complete...\n",
      "Classification for text #36 of 500 complete...\n",
      "Classification for text #37 of 500 complete...\n",
      "Classification for text #38 of 500 complete...\n",
      "Classification for text #39 of 500 complete...\n",
      "Classification for text #40 of 500 complete...\n",
      "Classification for text #41 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHubble time\\nTaken from this text snippet:\\nIf t iso is greater than the Hubble time, then we substitute N env, the number of ISO-spawning regions that have ever existed in the Milky Way, for R env t iso.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #42 of 500 complete...\n",
      "Classification for text #43 of 500 complete...\n",
      "Classification for text #44 of 500 complete...\n",
      "Classification for text #45 of 500 complete...\n",
      "Classification for text #46 of 500 complete...\n",
      "Classification for text #47 of 500 complete...\n",
      "Classification for text #48 of 500 complete...\n",
      "Classification for text #49 of 500 complete...\n",
      "Classification for text #50 of 500 complete...\n",
      "Classification for text #51 of 500 complete...\n",
      "Classification for text #52 of 500 complete...\n",
      "Classification for text #53 of 500 complete...\n",
      "Classification for text #54 of 500 complete...\n",
      "Classification for text #55 of 500 complete...\n",
      "Classification for text #56 of 500 complete...\n",
      "Classification for text #57 of 500 complete...\n",
      "Classification for text #58 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nK2 We\\nTaken from this text snippet:\\nOne of these flares is found to have the largest amplitude relative to the photospheric level and also the largest energy among all the L dwarf flares monitored by the Kepler / K 000 mission. 000.000 Sample of L dwarfs observed by K2 We analysed the light curves of 000 L dwarfs for which we obtained K 000 photometry despite being very faint objects.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #59 of 500 complete...\n",
      "Classification for text #60 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nextensive Kepler dataset\\nTaken from this text snippet:\\nAn extensive Kepler dataset showed HAT-P-000 b to have an approximately polar and eccentric orbit, evidencing a dynamically disturbed history for the system 000, 000.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nK2 - K4V\\nTaken from this text snippet:\\nWe know that HAT-P-000 is an active, K2-K4V (effective temperature T eff ≈ 000 K), high-metallicity ([Fe/H] = 000.000 star 000.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #61 of 500 complete...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification for text #62 of 500 complete...\n",
      "Classification for text #63 of 500 complete...\n",
      "Classification for text #64 of 500 complete...\n",
      "Classification for text #65 of 500 complete...\n",
      "Classification for text #66 of 500 complete...\n",
      "Classification for text #67 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nKepler detector\\nTaken from this text snippet:\\nThe ability of the Kepler detector to resolve multi-star systems is limited due to it having a relatively large pixel size (approximately 000′′ on sky. 000 000 Characteristics of the Kepler space telescope: websitewebsite.)')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #68 of 500 complete...\n",
      "Classification for text #69 of 500 complete...\n",
      "Classification for text #70 of 500 complete...\n",
      "Classification for text #71 of 500 complete...\n",
      "Classification for text #72 of 500 complete...\n",
      "Classification for text #73 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHST - STIS\\nTaken from this text snippet:\\nThe current goal of the University of Colorado ultraviolet rocket program is to develop the technical capabilities to enable a future, highly multiplexed ultraviolet spectrograph (with both high-resolution and imaging spectroscopy modes), e.g, an analog to the successful Hubble Space Telescope-Space Telescope Imaging Spectrograph (HST-STIS) instrument, with an order-of-magnitude higher efficiency.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #74 of 500 complete...\n",
      "Classification for text #75 of 500 complete...\n",
      "Classification for text #76 of 500 complete...\n",
      "Classification for text #77 of 500 complete...\n",
      "Classification for text #78 of 500 complete...\n",
      "Classification for text #79 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nK2 V\\nTaken from this text snippet:\\nThe P rot ∼ 000 day K dwarfs (see Tables 000 and 000 for stellar parameter references): comparing the similar planet-hosting stars HD000 (K0 V, T eff = 000 K, P rot = 000.000 days), Eri (K2 V, T eff = 000 K, P rot = 000.000 days), and HD000 (K3 V, T eff = 000 K, P rot = 000 days) with the non-planet-hosting K dwarf HR000 (K1 V, T eff = 000 K, P rot = 000.000 days), we find the average F Si iv / F bolom value for the planet-hosting stars is 000.000 (±000.000 × 000 −000, while HR000 displays the identical 000.000 (±000.000 × 000 −000. 000.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #80 of 500 complete...\n",
      "Classification for text #81 of 500 complete...\n",
      "Classification for text #82 of 500 complete...\n",
      "Classification for text #83 of 500 complete...\n",
      "Classification for text #84 of 500 complete...\n",
      "Classification for text #85 of 500 complete...\n",
      "Classification for text #86 of 500 complete...\n",
      "Classification for text #87 of 500 complete...\n",
      "Classification for text #88 of 500 complete...\n",
      "Classification for text #89 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nKepler ’s SN remnant\\nTaken from this text snippet:\\nAuthorsetal suggest that Fe clumps may also be responsible for the protrusions or ‘ears’ seen in Kepler ’s SN remnant (SNR) and SNR G1.000 + 000.000.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #90 of 500 complete...\n",
      "Classification for text #91 of 500 complete...\n",
      "Classification for text #92 of 500 complete...\n",
      "Classification for text #93 of 500 complete...\n",
      "Classification for text #94 of 500 complete...\n",
      "Classification for text #95 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nlocal Kepler time\\nTaken from this text snippet:\\nThe viscous spreading timescale 000 000 The viscous evolution timescale is t ν = (α Ω K) −000 × (h / r) −000, where α is the Shakura-Sunyaev viscosity parameter, Ω K is the local Kepler time, and (h / r) is the scale height-to-radius ratio. from 000 au is t ∼ 000 000 yr, assuming the viscosity parameter is α = 000 −000.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #96 of 500 complete...\n",
      "Classification for text #97 of 500 complete...\n",
      "Classification for text #98 of 500 complete...\n",
      "Classification for text #99 of 500 complete...\n",
      "Classification for text #100 of 500 complete...\n",
      "Classification for text #101 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nFull Kepler Dataset\\nTaken from this text snippet:\\nCharbonneau, The Occurrence of Potentially Habitable Planets Orbiting M Dwarfs Estimated from the Full Kepler Dataset and an Empirical Measurement of the Detection Sensitivity, Astrophys.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #102 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHubble sequence\\nTaken from this text snippet:\\n000: Morphological type in the Hubble sequence, which is taken from Authorsetal.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #103 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nKepler ’s third law\\nTaken from this text snippet:\\nThe prior on the scaled semi-major axis, a / R *, is obtained using Kepler’s third law with values of the planetary period and the stellar density (Table A.000.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #104 of 500 complete...\n",
      "Classification for text #105 of 500 complete...\n",
      "Classification for text #106 of 500 complete...\n",
      "Classification for text #107 of 500 complete...\n",
      "Classification for text #108 of 500 complete...\n",
      "Classification for text #109 of 500 complete...\n",
      "Classification for text #110 of 500 complete...\n",
      "Classification for text #111 of 500 complete...\n",
      "Classification for text #112 of 500 complete...\n",
      "Classification for text #113 of 500 complete...\n",
      "Classification for text #114 of 500 complete...\n",
      "Classification for text #115 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nKepler ’s Third Law\\nTaken from this text snippet:\\nWe first calculated the semimajor axis of the binary system from Kepler’s Third Law, based on the orbital period found by Authorsetal and assuming both components are stars).')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #116 of 500 complete...\n",
      "Classification for text #117 of 500 complete...\n",
      "Classification for text #118 of 500 complete...\n",
      "Classification for text #119 of 500 complete...\n",
      "Classification for text #120 of 500 complete...\n",
      "Classification for text #121 of 500 complete...\n",
      "Classification for text #122 of 500 complete...\n",
      "Classification for text #123 of 500 complete...\n",
      "Classification for text #124 of 500 complete...\n",
      "Classification for text #125 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nKepler Center\\nTaken from this text snippet:\\nWerner1 000 Institute for Astronomy and Astrophysics, Kepler Center for Astro and Particle Physics, Eberhard Karls University, Sand 000, 000 Tübingen, Germany 000 Department of Astronomy & Astrophysics, Eberly College of Science, The Pennsylvania State University, 000 Davey Lab, University Park, PA000, USA 000 Physique Atomique et Astrophysique, Université de Mons – UMONS, 000 Mons, Belgium 000 IPNAS, Université de Liège, Sart Tilman, 000 Liège, Belgium 000 NASA Goddard Space Flight Center, Greenbelt, MD000, USA Accepted 000 November 000.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #126 of 500 complete...\n",
      "Classification for text #127 of 500 complete...\n",
      "Classification for text #128 of 500 complete...\n",
      "Classification for text #129 of 500 complete...\n",
      "Classification for text #130 of 500 complete...\n",
      "Classification for text #131 of 500 complete...\n",
      "Classification for text #132 of 500 complete...\n",
      "Classification for text #133 of 500 complete...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification for text #134 of 500 complete...\n",
      "Classification for text #135 of 500 complete...\n",
      "Classification for text #136 of 500 complete...\n",
      "Classification for text #137 of 500 complete...\n",
      "Classification for text #138 of 500 complete...\n",
      "Classification for text #139 of 500 complete...\n",
      "Classification for text #140 of 500 complete...\n",
      "Classification for text #141 of 500 complete...\n",
      "Classification for text #142 of 500 complete...\n",
      "Classification for text #143 of 500 complete...\n",
      "Classification for text #144 of 500 complete...\n",
      "Classification for text #145 of 500 complete...\n",
      "Classification for text #146 of 500 complete...\n",
      "Classification for text #147 of 500 complete...\n",
      "Classification for text #148 of 500 complete...\n",
      "Classification for text #149 of 500 complete...\n",
      "Classification for text #150 of 500 complete...\n",
      "Classification for text #151 of 500 complete...\n",
      "Classification for text #152 of 500 complete...\n",
      "Classification for text #153 of 500 complete...\n",
      "Classification for text #154 of 500 complete...\n",
      "Classification for text #155 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHubble types\\nTaken from this text snippet:\\nSurveying an area of 000 deg 000, these authors found a faint-end slope of α = −000.000 when including galaxies of all Hubble types, and as steep as α ∼ −000.000 when the sample was restricted to just early types (regular and dwarf ellipticals).')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #156 of 500 complete...\n",
      "Classification for text #157 of 500 complete...\n",
      "Classification for text #158 of 500 complete...\n",
      "Classification for text #159 of 500 complete...\n",
      "Classification for text #160 of 500 complete...\n",
      "Classification for text #161 of 500 complete...\n",
      "Classification for text #162 of 500 complete...\n",
      "Classification for text #163 of 500 complete...\n",
      "Classification for text #164 of 500 complete...\n",
      "Classification for text #165 of 500 complete...\n",
      "Classification for text #166 of 500 complete...\n",
      "Classification for text #167 of 500 complete...\n",
      "Classification for text #168 of 500 complete...\n",
      "Classification for text #169 of 500 complete...\n",
      "Classification for text #170 of 500 complete...\n",
      "Classification for text #171 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHubble time\\nTaken from this text snippet:\\nFor galaxies with masses M * ≥ 000 × 000 000 M ⊙, a discrepancy between the GSMF in the absence of feedback (solid grey line) and expectation values from the CDM model (dotted line) starts to appear because gas cooling times in host (sub)haloes harbouring such massive galaxies become comparable to the Hubble time when the haloes assemble, so not all the baryons enclosed have yet been able to cool and form stars.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #172 of 500 complete...\n",
      "Classification for text #173 of 500 complete...\n",
      "Classification for text #174 of 500 complete...\n",
      "Classification for text #175 of 500 complete...\n",
      "Classification for text #176 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nKepler ’s third law\\nTaken from this text snippet:\\nThe semimajor axis a of the system in AU is calculated from Kepler’s third law: This is projected onto the sky using the Thiele-Innes elements: At a given time (t), mean anomaly (M), and eccentric anomaly (E), the projected separations (in AU) of the companion from the primary star in the x direction, y direction, or radially are given by Following a similar approach as Authorsetal, the tangential velocity of the companion at time t is given by Projecting onto the sky to obtain separations and velocities in the right ascension (RA) and declination (Dec) directions then provides the following companion positions and tangential velocities relative to the primary star: To convert onto the on-sky projection requires a distance measurement, we included a fit to the Gaia DR2 distance in our likelihood function to help pin the distance of the system to an appropriate value.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #177 of 500 complete...\n",
      "Classification for text #178 of 500 complete...\n",
      "Classification for text #179 of 500 complete...\n",
      "Classification for text #180 of 500 complete...\n",
      "Classification for text #181 of 500 complete...\n",
      "Classification for text #182 of 500 complete...\n",
      "Classification for text #183 of 500 complete...\n",
      "Classification for text #184 of 500 complete...\n",
      "Classification for text #185 of 500 complete...\n",
      "Classification for text #186 of 500 complete...\n",
      "Classification for text #187 of 500 complete...\n",
      "Classification for text #188 of 500 complete...\n",
      "Classification for text #189 of 500 complete...\n",
      "Classification for text #190 of 500 complete...\n",
      "Classification for text #191 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHubble time\\nTaken from this text snippet:\\nThroughout this work, we use Planck cosmology: H 000 = 000.000 ± 000.000 km s −000 Mpc −000, matter density parameter Ω m = 000.000 ± 000.000, and vacuum energy density Ω Λ = 000.000 ± 000.000, resulting in a Hubble time of 000.000 Gyr.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #192 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nKepler -based rotation periods\\nTaken from this text snippet:\\nWe compiled Kepler -based rotation periods, Gaia photometry, and Gaia parallaxes for members of the NGC000 cluster.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #193 of 500 complete...\n",
      "Classification for text #194 of 500 complete...\n",
      "Classification for text #195 of 500 complete...\n",
      "Classification for text #196 of 500 complete...\n",
      "Classification for text #197 of 500 complete...\n",
      "Classification for text #198 of 500 complete...\n",
      "Classification for text #199 of 500 complete...\n",
      "Classification for text #200 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nredshift - binned Hubble diagram\\nTaken from this text snippet:\\nUsing the Bayesian Estimation Applied to Multiple Species (BEAMS) framework and its extension BBC (‘BEAMS with Bias Correction’), we produce a redshift-binned Hubble diagram marginalised over contamination and corrected for selection effects and we use it to constrain the dark energy equation-of-state, w.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #201 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nrepurposed K2\\nTaken from this text snippet:\\nThough a broken reaction wheel ended the prime Kepler mission, the repurposed K2 switched between fields along the ecliptic every quarter-year and was able to observe far more clusters and young stars.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #202 of 500 complete...\n",
      "Classification for text #203 of 500 complete...\n",
      "Classification for text #204 of 500 complete...\n",
      "Classification for text #205 of 500 complete...\n",
      "Classification for text #206 of 500 complete...\n",
      "Classification for text #207 of 500 complete...\n",
      "Classification for text #208 of 500 complete...\n",
      "Classification for text #209 of 500 complete...\n",
      "Classification for text #210 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\ncomet C/000 K2 PanSTARRS\\nTaken from this text snippet:\\nSimilarly, prediscovery observations of comet C/000 K2 PanSTARRS indicate that it was already active in 000, at a distance of 000.000 au, but studies of the development and evolution of its coma suggest it could have been active from as early as 000 au.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #211 of 500 complete...\n",
      "Classification for text #212 of 500 complete...\n",
      "Classification for text #213 of 500 complete...\n",
      "Classification for text #214 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHubble time\\nTaken from this text snippet:\\nWe do not overplot the King parameters of the classical Milky Way dwarf galaxies, because their relaxation times are approximately a Hubble time.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification for text #215 of 500 complete...\n",
      "Classification for text #216 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHubble flow\\nTaken from this text snippet:\\n000 λsrc The source is assumed to be at rest with respect to the Hubble flow—the coordinate frame moving away from the observer with the recession speed c da(t) v= a0 dt Zz dz ′, H(z ′) 000 000 which is ≈ H0 D for small z, where D is distance (in Mpc) in the expanding Universe; a(t)/a0 is the normalised scale factor; and H(z ′) = 000 + ΩM [000 + z ′)000 − 000])−000/000.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #217 of 500 complete...\n",
      "Classification for text #218 of 500 complete...\n",
      "Classification for text #219 of 500 complete...\n",
      "Classification for text #220 of 500 complete...\n",
      "Classification for text #221 of 500 complete...\n",
      "Classification for text #222 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nKepler ’s third law\\nTaken from this text snippet:\\nAfter transforming a to P orb, using Kepler’s third law, the ellipsoidal model becomes where and the α e coefficients are where u and τ are the primary’s linear limb and gravity darkening coefficients, respectively. 000.000 Reflection We turn now to the reflection of the primary light by the secondary surface.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #223 of 500 complete...\n",
      "Classification for text #224 of 500 complete...\n",
      "Classification for text #225 of 500 complete...\n",
      "Classification for text #226 of 500 complete...\n",
      "Classification for text #227 of 500 complete...\n",
      "Classification for text #228 of 500 complete...\n",
      "Classification for text #229 of 500 complete...\n",
      "Classification for text #230 of 500 complete...\n",
      "Classification for text #231 of 500 complete...\n",
      "Classification for text #232 of 500 complete...\n",
      "Classification for text #233 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nKepler-000\\nTaken from this text snippet:\\nThe high-quality long-duration light curves of the Kepler space telescope finally allowed the first detection of TTVs by Authorsetal with the famous case of Kepler-000.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #234 of 500 complete...\n",
      "Classification for text #235 of 500 complete...\n",
      "Classification for text #236 of 500 complete...\n",
      "Classification for text #237 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nK2 diagram close\\nTaken from this text snippet:\\nTo conclude, the planet falls in the K1–K2 diagram close to HR000 and WISE000, two objects with early T spectral types and red colors.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #238 of 500 complete...\n",
      "Classification for text #239 of 500 complete...\n",
      "Classification for text #240 of 500 complete...\n",
      "Classification for text #241 of 500 complete...\n",
      "Classification for text #242 of 500 complete...\n",
      "Classification for text #243 of 500 complete...\n",
      "Classification for text #244 of 500 complete...\n",
      "Classification for text #245 of 500 complete...\n",
      "Classification for text #246 of 500 complete...\n",
      "Classification for text #247 of 500 complete...\n",
      "Classification for text #248 of 500 complete...\n",
      "Classification for text #249 of 500 complete...\n",
      "Classification for text #250 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nkepler-000\\nTaken from this text snippet:\\nProtoplanetary Disk Model We utilize a simple two-population dust evolution model as implemented in the publicly available twopoppy code 000 000 The original code is available at website-pop-py, and the modified version used in this paper is available at website-chachan/two-pop-py/tree/kepler-000. to determine which disks are most conducive for giant planet core formation and calculate the amount of solids that reaches the inner disk.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #251 of 500 complete...\n",
      "Classification for text #252 of 500 complete...\n",
      "Classification for text #253 of 500 complete...\n",
      "Classification for text #254 of 500 complete...\n",
      "Classification for text #255 of 500 complete...\n",
      "Classification for text #256 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nK2 time - series\\nTaken from this text snippet:\\nAs a result, the length of the K2 time-series might be insufficient to constrain spot lifetimes through the ACF.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #257 of 500 complete...\n",
      "Classification for text #258 of 500 complete...\n",
      "Classification for text #259 of 500 complete...\n",
      "Classification for text #260 of 500 complete...\n",
      "Classification for text #261 of 500 complete...\n",
      "Classification for text #262 of 500 complete...\n",
      "Classification for text #263 of 500 complete...\n",
      "Classification for text #264 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nKepler-7b\\nTaken from this text snippet:\\nOne of the more compelling observational indications of inhomogeneous cloud coverage is the westwards offset in the peak optical phase curve, first detected for Kepler-7b by Authorsetal.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #265 of 500 complete...\n",
      "Classification for text #266 of 500 complete...\n",
      "Classification for text #267 of 500 complete...\n",
      "Classification for text #268 of 500 complete...\n",
      "Classification for text #269 of 500 complete...\n",
      "Classification for text #270 of 500 complete...\n",
      "Classification for text #271 of 500 complete...\n",
      "Classification for text #272 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nK2.5V\\nTaken from this text snippet:\\nThe two stars have similar masses (and 000.000 ± 000.000 M ⊙) and close spectral types (G9 and K2.5V), allowing us to consider them as two evolutionary stages of the same star.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #273 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nK2 population\\nTaken from this text snippet:\\nThe Transiting Exoplanet Survey Satellite (TESS; Rickeretal 000 offers the opportunity to expand the K2 population on two fronts.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #274 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nKepler ’s launch\\nTaken from this text snippet:\\nPrior to Kepler’s launch, it was shown that the analysis of the dynamical interaction in multi-planet systems would be feasible offering an independent mass determination.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #275 of 500 complete...\n",
      "Classification for text #276 of 500 complete...\n",
      "Classification for text #277 of 500 complete...\n",
      "Classification for text #278 of 500 complete...\n",
      "Classification for text #279 of 500 complete...\n",
      "Classification for text #280 of 500 complete...\n",
      "Classification for text #281 of 500 complete...\n",
      "Classification for text #282 of 500 complete...\n",
      "Classification for text #283 of 500 complete...\n",
      "Classification for text #284 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHubble types T ∈\\nTaken from this text snippet:\\nSample and data Our sample of 000 galaxies was selected from the extragalactic database HyperLeda 000 and met the following criteria: They host prominent bars, according to the visual classification from ancillary optical images; They probe both star-forming and quiescent bars, based on the perusal of archival H α or mid-IR imaging; They have morphological types spanning the range S0/a-Sc (i.e, Hubble types T ∈ [000, 000]); They are nearby, with recessional velocities 000 km s −000; They have low disk inclinations (i 000°), enabling the study of surface densities (of SF and gas masses) and minimising the effect of dust absorption in optical and near-IR wavelengths; They have galactic declinations δ> −000°, avoiding high air masses during IRAM-000 m observations; They have D000> 000′, where D000 is the length of the projected major axis of a galaxy at the isophotal level 000 mag arcsec −000 in the B -band, ensuring good spatial resolution.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification for text #285 of 500 complete...\n",
      "Classification for text #286 of 500 complete...\n",
      "Classification for text #287 of 500 complete...\n",
      "Classification for text #288 of 500 complete...\n",
      "Classification for text #289 of 500 complete...\n",
      "Classification for text #290 of 500 complete...\n",
      "Classification for text #291 of 500 complete...\n",
      "Classification for text #292 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nK2 eclipse\\nTaken from this text snippet:\\nTo check for possible period changes, we fitted for a set of eclipse times over 000 yr segments of the ASAS and ASAS-SN light curves, using the K2 eclipse as a template.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #293 of 500 complete...\n",
      "Classification for text #294 of 500 complete...\n",
      "Classification for text #295 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHubble Collaboration\\nTaken from this text snippet:\\n(Picture credits: NASA, ESA, and the Hubble Heritage Team (STScI/AURA)–ESA/Hubble Collaboration.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #296 of 500 complete...\n",
      "Classification for text #297 of 500 complete...\n",
      "Classification for text #298 of 500 complete...\n",
      "Classification for text #299 of 500 complete...\n",
      "Classification for text #300 of 500 complete...\n",
      "Classification for text #301 of 500 complete...\n",
      "Classification for text #302 of 500 complete...\n",
      "Classification for text #303 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nWD+K2\\nTaken from this text snippet:\\nThe other two classical binaries lie on the cluster main-sequence: one is a known WD+F6 binary (HR000; HD000) and the other one is the known eclipsing binary of Algol type (WD+K2) V000 Tau (Figure 000.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #304 of 500 complete...\n",
      "Classification for text #305 of 500 complete...\n",
      "Classification for text #306 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nK2 index\\nTaken from this text snippet:\\nAuthorsetal developed a technique to determine metallicities of M dwarfs from low-resolution (R ∼ 000 spectra in the K band 000.000 μ m), using the equivalent widths (EWs) of the Na i doublet lines 000.000 and 000.000 μ m), Ca i triplet lines 000.000–000.000 μ m), and the H 000 O–K2 index.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #307 of 500 complete...\n",
      "Classification for text #308 of 500 complete...\n",
      "Classification for text #309 of 500 complete...\n",
      "Classification for text #310 of 500 complete...\n",
      "Classification for text #311 of 500 complete...\n",
      "Classification for text #312 of 500 complete...\n",
      "Classification for text #313 of 500 complete...\n",
      "Classification for text #314 of 500 complete...\n",
      "Classification for text #315 of 500 complete...\n",
      "Classification for text #316 of 500 complete...\n",
      "Classification for text #317 of 500 complete...\n",
      "Classification for text #318 of 500 complete...\n",
      "Classification for text #319 of 500 complete...\n",
      "Classification for text #320 of 500 complete...\n",
      "Classification for text #321 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nK2 - C1\\nTaken from this text snippet:\\nRight panel: and distribution of the 000 RAVE targets in K2-C1 possessing seismic parameters.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #322 of 500 complete...\n",
      "Classification for text #323 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHubble parameter\\nTaken from this text snippet:\\nThroughout the paper, we assume a flat lambda cold dark matter (ΛCDM) cosmology with Ω m = 000.000, and Hubble parameter, where we have assumed h = 000.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #324 of 500 complete...\n",
      "Classification for text #325 of 500 complete...\n",
      "Classification for text #326 of 500 complete...\n",
      "Classification for text #327 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHubble diagram\\nTaken from this text snippet:\\nIn our work, for the first time, we use our new set of high-spectral resolution observations of high- z HII galaxies (HIIG), obtained with VLT-KMOS (González-Moránetal 000 along with available HIIG data (Terlevichetal 000; González-Moránetal 000 and combine them with the SNIa data from the Pantheon sample in order to reconstruct the Hubble diagram and thus to place constraints on the main cosmokinetic parameters (deceleration and jerk), as well as to check for deviations from the predictions of the ΛCDM model.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #328 of 500 complete...\n",
      "Classification for text #329 of 500 complete...\n",
      "Classification for text #330 of 500 complete...\n",
      "Classification for text #331 of 500 complete...\n",
      "Classification for text #332 of 500 complete...\n",
      "Classification for text #333 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHubble flow\\nTaken from this text snippet:\\nFollowing the lineage of the SPT-SZ,000 SPTpol,000 and SPT-3G cameras,000 which each demonstrated multiple early-stage technologies, SPT3G+ provides an ideal platform for technology development, focusing specifically on KIDs for CMB observations and mm-wave LIM. 000.000 Kinematic Sunyaev-Zeldovich Effect The kSZ effect is the anisotropy induced by CMB photons scattering off electrons with bulk peculiar velocities relative to the Hubble flow, and its correlation with the cosmic velocity field and ionization history can be used to constrain cosmological parameters.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #334 of 500 complete...\n",
      "Classification for text #335 of 500 complete...\n",
      "Classification for text #336 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nshort Kepler short - cadence\\nTaken from this text snippet:\\nWhile the CoRoT and K2 Cepheids’ light curves are too short Kepler short-cadence (SC) RR Lyrae data are promising for searching the effect.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #337 of 500 complete...\n",
      "Classification for text #338 of 500 complete...\n",
      "Classification for text #339 of 500 complete...\n",
      "Classification for text #340 of 500 complete...\n",
      "Classification for text #341 of 500 complete...\n",
      "Classification for text #342 of 500 complete...\n",
      "Classification for text #343 of 500 complete...\n",
      "Classification for text #344 of 500 complete...\n",
      "Classification for text #345 of 500 complete...\n",
      "Classification for text #346 of 500 complete...\n",
      "Classification for text #347 of 500 complete...\n",
      "Classification for text #348 of 500 complete...\n",
      "Classification for text #349 of 500 complete...\n",
      "Classification for text #350 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHubble tension\\nTaken from this text snippet:\\nHowever, several recent cosmological tensions—namely the “Hubble tension,” concerning the present-day expansion rate of the universe, H 000, and the “ σ 000 tension,” concerning the amplitude of matter clustering on quasi-linear scales—potentially point to new physics beyond ΛCDM (see Verdeetal 000 for a review).')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #351 of 500 complete...\n",
      "Classification for text #352 of 500 complete...\n",
      "Classification for text #353 of 500 complete...\n",
      "Classification for text #354 of 500 complete...\n",
      "Classification for text #355 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nspace - based mission Kepler\\nTaken from this text snippet:\\nThe space-based mission Kepler used transit photometry to detect and characterise exoplanets and one of its key objectives is the determination of the frequency of terrestrial planets in the habitable zones of stars.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification for text #356 of 500 complete...\n",
      "Classification for text #357 of 500 complete...\n",
      "Classification for text #358 of 500 complete...\n",
      "Classification for text #359 of 500 complete...\n",
      "Classification for text #360 of 500 complete...\n",
      "Classification for text #361 of 500 complete...\n",
      "Classification for text #362 of 500 complete...\n",
      "Classification for text #363 of 500 complete...\n",
      "Classification for text #364 of 500 complete...\n",
      "Classification for text #365 of 500 complete...\n",
      "Classification for text #366 of 500 complete...\n",
      "Classification for text #367 of 500 complete...\n",
      "Classification for text #368 of 500 complete...\n",
      "Classification for text #369 of 500 complete...\n",
      "Classification for text #370 of 500 complete...\n",
      "Classification for text #371 of 500 complete...\n",
      "Classification for text #372 of 500 complete...\n",
      "Classification for text #373 of 500 complete...\n",
      "Classification for text #374 of 500 complete...\n",
      "Classification for text #375 of 500 complete...\n",
      "Classification for text #376 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nKepler ’s third law\\nTaken from this text snippet:\\nThe periods of the sinusoids were calculated from the semi-major axes of the planets predicted by the dynamic simulations using Kepler’s third law and assuming circular orbits.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #377 of 500 complete...\n",
      "Classification for text #378 of 500 complete...\n",
      "Classification for text #379 of 500 complete...\n",
      "Classification for text #380 of 500 complete...\n",
      "Classification for text #381 of 500 complete...\n",
      "Classification for text #382 of 500 complete...\n",
      "Classification for text #383 of 500 complete...\n",
      "Classification for text #384 of 500 complete...\n",
      "Classification for text #385 of 500 complete...\n",
      "Classification for text #386 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHubble types\\nTaken from this text snippet:\\nX-shaped magnetic fields in the thick disc/halo were also detected for eight edge-on galaxies spanning a range of Hubble types and SFRs 000.6M yr 000 SFR 000.3M yr 000.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #387 of 500 complete...\n",
      "Classification for text #388 of 500 complete...\n",
      "Classification for text #389 of 500 complete...\n",
      "Classification for text #390 of 500 complete...\n",
      "Classification for text #391 of 500 complete...\n",
      "Classification for text #392 of 500 complete...\n",
      "Classification for text #393 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHubble distance\\nTaken from this text snippet:\\nWe begin with the definition of the comoving volume element,where D H = c / H 000 is the Hubble distance, in our assumed cosmology, and D l is the angular diameter distance to the lens.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #394 of 500 complete...\n",
      "Classification for text #395 of 500 complete...\n",
      "Classification for text #396 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nKepler ’s third law\\nTaken from this text snippet:\\nWe note that, by using the transit duration and depth along with stellar mass and radius, we can estimate the period through Kepler’s third law in the assumption of planar and circular orbit, as shown in Sect. 000.000 of Seager Mallén-Authorsetal.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #397 of 500 complete...\n",
      "Classification for text #398 of 500 complete...\n",
      "Classification for text #399 of 500 complete...\n",
      "Classification for text #400 of 500 complete...\n",
      "Classification for text #401 of 500 complete...\n",
      "Classification for text #402 of 500 complete...\n",
      "Classification for text #403 of 500 complete...\n",
      "Classification for text #404 of 500 complete...\n",
      "Classification for text #405 of 500 complete...\n",
      "Classification for text #406 of 500 complete...\n",
      "Classification for text #407 of 500 complete...\n",
      "Classification for text #408 of 500 complete...\n",
      "Classification for text #409 of 500 complete...\n",
      "Classification for text #410 of 500 complete...\n",
      "Classification for text #411 of 500 complete...\n",
      "Classification for text #412 of 500 complete...\n",
      "Classification for text #413 of 500 complete...\n",
      "Classification for text #414 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHubble time\\nTaken from this text snippet:\\nAt, the Hubble time) corresponds to ≲000 e-folding times, assuming Eddington-limited black hole accretion and a fixed radiative efficiency η r.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #415 of 500 complete...\n",
      "Classification for text #416 of 500 complete...\n",
      "Classification for text #417 of 500 complete...\n",
      "Classification for text #418 of 500 complete...\n",
      "Classification for text #419 of 500 complete...\n",
      "Classification for text #420 of 500 complete...\n",
      "Classification for text #421 of 500 complete...\n",
      "Classification for text #422 of 500 complete...\n",
      "Classification for text #423 of 500 complete...\n",
      "Classification for text #424 of 500 complete...\n",
      "Classification for text #425 of 500 complete...\n",
      "Classification for text #426 of 500 complete...\n",
      "Classification for text #427 of 500 complete...\n",
      "Classification for text #428 of 500 complete...\n",
      "Classification for text #429 of 500 complete...\n",
      "Classification for text #430 of 500 complete...\n",
      "Classification for text #431 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHubble Flow\\nTaken from this text snippet:\\nH i line fluxes (column 000 are calculated from fits to the spatially integrated line spectrum, Distances (column 000 are calculated using the ALFALFA flow model, which is simply Hubble Flow at km s −000; for sources in this velocity range (∼000–000 km s −000 distance uncertainties due to proper motions are ≲000%.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #432 of 500 complete...\n",
      "Classification for text #433 of 500 complete...\n",
      "Classification for text #434 of 500 complete...\n",
      "Classification for text #435 of 500 complete...\n",
      "Classification for text #436 of 500 complete...\n",
      "Classification for text #437 of 500 complete...\n",
      "Classification for text #438 of 500 complete...\n",
      "Classification for text #439 of 500 complete...\n",
      "Classification for text #440 of 500 complete...\n",
      "Classification for text #441 of 500 complete...\n",
      "Classification for text #442 of 500 complete...\n",
      "Classification for text #443 of 500 complete...\n",
      "Classification for text #444 of 500 complete...\n",
      "Classification for text #445 of 500 complete...\n",
      "Classification for text #446 of 500 complete...\n",
      "Classification for text #447 of 500 complete...\n",
      "Classification for text #448 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\noriginal Hubble - Sandage stars\\nTaken from this text snippet:\\nThey also note that the star J000.000 + 000.000, classified as Ofpe/WN9 by Authorsetal, is actually Var 000, one of the original Hubble-Sandage stars, now called LBVs.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nK2 I\\nTaken from this text snippet:\\nThe star 2MASS J000–000 ([M000] SMC000 may be a similarly case, as Authorsetal called it a K2 I while Authorsetal classified it as M2 Ia-Iab.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #449 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nsuper - Hubble scales\\nTaken from this text snippet:\\nHowever, since the comoving curvature perturbation on super-Hubble scales is conserved if there is only a single adiabatic mode [000,000], there is no growth of the curvature perturbation on super-Hubble scales in such a case.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #450 of 500 complete...\n",
      "Classification for text #451 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHubble time\\nTaken from this text snippet:\\nFor example, the H/He envelopes on a 000 M ⊕ planet can be easily stripped in 000 Myr at 000.000 au around a G-type star, but the mass loss timescale quickly shoots up to more than a Hubble time for planetary cores with>000–000 M ⊕ depending on the insolation the planet receives.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nKepler USPs\\nTaken from this text snippet:\\nThe histograms are the metallicity distribution of all Kepler USPs (blue) and hot Jupiters (orange).')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #452 of 500 complete...\n",
      "Classification for text #453 of 500 complete...\n",
      "Classification for text #454 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nplanet Kepler-7b\\nTaken from this text snippet:\\nInterestingly, for the planet Kepler-7b, similar to HAT-P-000 b in terms of surface gravity and equilibrium temperature, an albedo A g ~ 000.000 was derived in the Kepler band and interpreted as reflection on a silicate cloud deck.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #455 of 500 complete...\n",
      "Classification for text #456 of 500 complete...\n",
      "Classification for text #457 of 500 complete...\n",
      "Classification for text #458 of 500 complete...\n",
      "Classification for text #459 of 500 complete...\n",
      "Classification for text #460 of 500 complete...\n",
      "Classification for text #461 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nKepler problem\\nTaken from this text snippet:\\nSystem Description The motion of a single planet orbiting a single central star is described by the solution to the Kepler problem.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #462 of 500 complete...\n",
      "Classification for text #463 of 500 complete...\n",
      "Classification for text #464 of 500 complete...\n",
      "Classification for text #465 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHubble types\\nTaken from this text snippet:\\nHubble types from CALIFA DR3 are indicated in the legend for the five selected galaxies.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #466 of 500 complete...\n",
      "Classification for text #467 of 500 complete...\n",
      "Classification for text #468 of 500 complete...\n",
      "Classification for text #469 of 500 complete...\n",
      "Classification for text #470 of 500 complete...\n",
      "Classification for text #471 of 500 complete...\n",
      "Classification for text #472 of 500 complete...\n",
      "Classification for text #473 of 500 complete...\n",
      "Classification for text #474 of 500 complete...\n",
      "Classification for text #475 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHubble WFC3\\nTaken from this text snippet:\\nThe green points indicate the Hubble WFC3 and Spitzer photometric observations.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #476 of 500 complete...\n",
      "Classification for text #477 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHST WFC3\\nTaken from this text snippet:\\nCharge-trapping: A major correlated error source on the Hubble Space Telescope’s Wide Field Camera 000 (HST WFC3) is the ramp effect.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #478 of 500 complete...\n",
      "Classification for text #479 of 500 complete...\n",
      "Classification for text #480 of 500 complete...\n",
      "Classification for text #481 of 500 complete...\n",
      "Classification for text #482 of 500 complete...\n",
      "Classification for text #483 of 500 complete...\n",
      "Classification for text #484 of 500 complete...\n",
      "Classification for text #485 of 500 complete...\n",
      "Classification for text #486 of 500 complete...\n",
      "Classification for text #487 of 500 complete...\n",
      "Classification for text #488 of 500 complete...\n",
      "Classification for text #489 of 500 complete...\n",
      "Classification for text #490 of 500 complete...\n",
      "Classification for text #491 of 500 complete...\n",
      "Classification for text #492 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHubble time\\nTaken from this text snippet:\\nNext, the SFR is assumed as where controls the star formation rate in unit of Hubble time.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #493 of 500 complete...\n",
      "Classification for text #494 of 500 complete...\n",
      "Classification for text #495 of 500 complete...\n",
      "Classification for text #496 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nKepler Kepler\\nTaken from this text snippet:\\nKepler Kepler observed the TRAPPIST-000 system in its short-cadence mode for one 000 day cycle, spanning 000 December–000 March; while these observations cover the same time range in which the Evryscope observed TRAPPIST-000, all K2 observations took place during the time of year when TRAPPIST-000 was not observable from CTIO.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nK2 flares\\nTaken from this text snippet:\\nWe fit this power law to the K2 flares observed in Authorsetal, after converting Kepler bandpass flare energies given therein to bolometric flare energies as described in Section 000.000, using the fraction of bolometric energy in the Kepler bandpass (f K2 = 000.000; Osten Wolk 000 rather than f g ′.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #497 of 500 complete...\n",
      "Classification for text #498 of 500 complete...\n",
      "Classification for text #499 of 500 complete...\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nHubble Sequence\\nTaken from this text snippet:\\nGALAXY FORMATION AND THE INTERGALACTIC MEDIUM000 000.000 The Peak era of galaxy assembly. 000 000.000.000 TMT and galaxy formation. 000 000.000.000 How does the distribution of dark matter relate to the luminous stars and gas we see? 000 website.000.000.REL000 PAGE V DETAILED SCIENCE CASE: 000 April 000, 000 000.000.000 The Growth of Stars: Star-Formation Histories, Dust, and Chemical 000 000.000.000 The formation of passive galaxies and the birth of the Hubble Sequence. 000 000.000.000 The Stellar Initial Mass Function, Early Black Holes and the Growth of Quasars 000 000.000.000 The Census of Baryons and the Baryon Cycle. 000 000.000.000 Spatial dissection of forming galaxies. 000 000.000 The Age of Maturity and Quiescence. 000 000.000.000 Morphological and Kinematic Growth of Galaxies. 000 000.000.000 Feedback and the Physics of Galaxy Quenching. 000 000.000.000 The Influence of Local and Large-Scale Environment. 000 000.000 The Intergalactic Medium. 000 000.000.000 Background 000 000.000.000 TMT and the IGM. 000 000.000.000 TMT and the CGM. 000 000.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nKepler ’s demonstration\\nTaken from this text snippet:\\nWith Kepler’s demonstration that small (numeric RE) planets are common, the next step in understanding the frequency of earthlike planets is to determine the density of a significant number of these planets, especially those at large semi-major axes.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "-\n",
      "The following err. was encountered in operate:\n",
      "NotImplementedError('Err: Unrecognized ambig. phrase:\\nK2 systems\\nTaken from this text snippet:\\nMost Kepler and K2 systems are too faint and the planets too small to have detectable Doppler radial velocity signals (c.f.')\n",
      "Error was noted. Returning error as verdict.\n",
      "-\n",
      "Classification for text #500 of 500 complete...\n",
      "\n",
      "Run of classify_set() complete!\n",
      "\n",
      "Classification complete for Operator #0.\n",
      "Generating the performance counter...\n",
      "All work complete for Operator #0.\n",
      "!\n",
      "\n",
      "Evaluation saved at: /Users/jamila.pegues/Documents/STScI_Fellowship/Functional/Library/BibTracking/repo_stsci/bibcat/src/models/test_run_rule/output/test_eval.npy\n",
      "\n",
      "Run of _generate_classifications() complete!\n",
      "\n",
      "Classifications generated.\n",
      "Evaluating classifications...\n",
      "\n",
      "> Running _generate_performance_counter() for: Operator_RB\n",
      "Accumulating performance over 500 texts.\n",
      "Actual class names: ['datainfluenced', 'mention', 'science', 'other', 'znotmatch']\n",
      "Measured class names: ['datainfluenced', 'mention', 'science', 'other', 'zerror', 'zlowprob', 'znotmatch']\n",
      "Saving misclassifications...\n",
      "\n",
      "Misclassifications for Operator_RB saved at: /Users/jamila.pegues/Documents/STScI_Fellowship/Functional/Library/BibTracking/repo_stsci/bibcat/src/models/test_run_rule/output/test_misclassif_basic_Operator_RB.txt\n",
      "\n",
      "-\n",
      "Performance counter generated:\n",
      "Actual datainfluenced total: 8\n",
      "Actual datainfluenced vs Measured datainfluenced: 1\n",
      "Actual datainfluenced vs Measured mention: 0\n",
      "Actual datainfluenced vs Measured science: 2\n",
      "Actual datainfluenced vs Measured other: 0\n",
      "Actual datainfluenced vs Measured zerror: 3\n",
      "Actual datainfluenced vs Measured zlowprob: 2\n",
      "Actual datainfluenced vs Measured znotmatch: 0\n",
      "Actual datainfluenced vs Measured _total: 8\n",
      "Actual mention total: 457\n",
      "Actual mention vs Measured datainfluenced: 3\n",
      "Actual mention vs Measured mention: 242\n",
      "Actual mention vs Measured science: 19\n",
      "Actual mention vs Measured other: 0\n",
      "Actual mention vs Measured zerror: 44\n",
      "Actual mention vs Measured zlowprob: 140\n",
      "Actual mention vs Measured znotmatch: 9\n",
      "Actual mention vs Measured _total: 457\n",
      "Actual science total: 237\n",
      "Actual science vs Measured datainfluenced: 2\n",
      "Actual science vs Measured mention: 12\n",
      "Actual science vs Measured science: 92\n",
      "Actual science vs Measured other: 0\n",
      "Actual science vs Measured zerror: 27\n",
      "Actual science vs Measured zlowprob: 88\n",
      "Actual science vs Measured znotmatch: 16\n",
      "Actual science vs Measured _total: 237\n",
      "Actual other total: 1\n",
      "Actual other vs Measured datainfluenced: 0\n",
      "Actual other vs Measured mention: 1\n",
      "Actual other vs Measured science: 0\n",
      "Actual other vs Measured other: 0\n",
      "Actual other vs Measured zerror: 0\n",
      "Actual other vs Measured zlowprob: 0\n",
      "Actual other vs Measured znotmatch: 0\n",
      "Actual other vs Measured _total: 1\n",
      "Actual znotmatch total: 3297\n",
      "Actual znotmatch vs Measured datainfluenced: 1\n",
      "Actual znotmatch vs Measured mention: 39\n",
      "Actual znotmatch vs Measured science: 9\n",
      "Actual znotmatch vs Measured other: 0\n",
      "Actual znotmatch vs Measured zerror: 49\n",
      "Actual znotmatch vs Measured zlowprob: 29\n",
      "Actual znotmatch vs Measured znotmatch: 3170\n",
      "Actual znotmatch vs Measured _total: 3297\n",
      "\n",
      "-\n",
      "\n",
      "Run of _generate_performance_counter() complete!\n",
      "\n",
      "Evaluations generated.\n",
      "Plotting confusion matrices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Running _combine_performance_across_evaluations()!\n",
      "Combining evaluations across these operators: ['Operator_RB']\n",
      "All possible operator combinations: []\n",
      "Run of _combine_performance_across_evaluations() complete!\n",
      "Confusion matrices have been plotted at:\n",
      "/Users/jamila.pegues/Documents/STScI_Fellowship/Functional/Library/BibTracking/repo_stsci/bibcat/src/models/test_run_rule/output\n",
      "\n",
      "Run of evaluate_performance_basic() complete!\n"
     ]
    }
   ],
   "source": [
    "#Parameters for this evaluation\n",
    "filename_root = \"performance_confmatr_basic_{0}\".format(name_model)\n",
    "for ii in range(0, len(list_operators)):\n",
    "    if (list_thresholds[ii] is not None):\n",
    "        filename_root += \"_unc{0}of{1:.2f}\".format((ii+1), list_thresholds[ii]).replace(\".\",\"p\")\n",
    "fileroot_misclassif = \"test_misclassif_basic\" #Root name of the file within which to store misclassified text information\n",
    "figsize = (20, 12)\n",
    "\n",
    "#Run the pipeline for a basic evaluation of model performance\n",
    "performer.evaluate_performance_basic(operators=list_operators, dicts_texts=list_dict_texts, mappers=list_mappers,\n",
    "                                     thresholds=list_thresholds, buffers=list_buffers, is_text_processed=False,\n",
    "                                     do_reuse_run=do_reuse_run, filename_root=filename_root,\n",
    "                                     do_verify_truematch=do_verify_truematch, do_raise_innererror=do_raise_innererror,\n",
    "                                     do_save_evaluation=True, do_save_misclassif=True, filepath_output=filepath_output,\n",
    "                                     fileroot_evaluation=fileroot_evaluation, fileroot_misclassif=fileroot_misclassif,\n",
    "                                     print_freq=1, do_verbose=True, do_verbose_deep=False, figsize=figsize,\n",
    "                                     target_classifs=target_classifs_basic,\n",
    "                                     minmax_exclude_classifs=minmax_exclude_classifs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f12f0d3",
   "metadata": {},
   "source": [
    "The Uncertainty evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f68ae90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Running evaluate_performance_uncertainty()!\n",
      "Generating classifications for operators...\n",
      "\n",
      "> Running _generate_classifications()!\n",
      "Iterating through Operators to classify each set of text...\n",
      "Previous evaluation exists at /Users/jamila.pegues/Documents/STScI_Fellowship/Functional/Library/BibTracking/repo_stsci/bibcat/src/models/test_run_rule/output/test_eval.npy\n",
      "Loading that eval...\n",
      "\n",
      "Classifications generated.\n",
      "Evaluating classifications...\n",
      "Threshold #1 of 13:\n",
      "\n",
      "> Running _generate_performance_counter() for: Operator_RB\n",
      "Accumulating performance over 500 texts.\n",
      "Actual class names: ['datainfluenced', 'mention', 'science', 'other', 'znotmatch']\n",
      "Measured class names: ['datainfluenced', 'mention', 'science', 'other', 'zerror', 'zlowprob', 'znotmatch']\n",
      "\n",
      "-\n",
      "Performance counter generated:\n",
      "Actual datainfluenced total: 8\n",
      "Actual datainfluenced vs Measured datainfluenced: 1\n",
      "Actual datainfluenced vs Measured mention: 1\n",
      "Actual datainfluenced vs Measured science: 3\n",
      "Actual datainfluenced vs Measured other: 0\n",
      "Actual datainfluenced vs Measured zerror: 3\n",
      "Actual datainfluenced vs Measured zlowprob: 0\n",
      "Actual datainfluenced vs Measured znotmatch: 0\n",
      "Actual datainfluenced vs Measured _total: 8\n",
      "Actual mention total: 457\n",
      "Actual mention vs Measured datainfluenced: 9\n",
      "Actual mention vs Measured mention: 314\n",
      "Actual mention vs Measured science: 34\n",
      "Actual mention vs Measured other: 0\n",
      "Actual mention vs Measured zerror: 44\n",
      "Actual mention vs Measured zlowprob: 47\n",
      "Actual mention vs Measured znotmatch: 9\n",
      "Actual mention vs Measured _total: 457\n",
      "Actual science total: 237\n",
      "Actual science vs Measured datainfluenced: 6\n",
      "Actual science vs Measured mention: 64\n",
      "Actual science vs Measured science: 118\n",
      "Actual science vs Measured other: 0\n",
      "Actual science vs Measured zerror: 27\n",
      "Actual science vs Measured zlowprob: 6\n",
      "Actual science vs Measured znotmatch: 16\n",
      "Actual science vs Measured _total: 237\n",
      "Actual other total: 1\n",
      "Actual other vs Measured datainfluenced: 0\n",
      "Actual other vs Measured mention: 1\n",
      "Actual other vs Measured science: 0\n",
      "Actual other vs Measured other: 0\n",
      "Actual other vs Measured zerror: 0\n",
      "Actual other vs Measured zlowprob: 0\n",
      "Actual other vs Measured znotmatch: 0\n",
      "Actual other vs Measured _total: 1\n",
      "Actual znotmatch total: 3297\n",
      "Actual znotmatch vs Measured datainfluenced: 1\n",
      "Actual znotmatch vs Measured mention: 49\n",
      "Actual znotmatch vs Measured science: 15\n",
      "Actual znotmatch vs Measured other: 0\n",
      "Actual znotmatch vs Measured zerror: 49\n",
      "Actual znotmatch vs Measured zlowprob: 13\n",
      "Actual znotmatch vs Measured znotmatch: 3170\n",
      "Actual znotmatch vs Measured _total: 3297\n",
      "\n",
      "-\n",
      "\n",
      "Run of _generate_performance_counter() complete!\n",
      "Threshold #2 of 13:\n",
      "\n",
      "> Running _generate_performance_counter() for: Operator_RB\n",
      "Accumulating performance over 500 texts.\n",
      "Actual class names: ['datainfluenced', 'mention', 'science', 'other', 'znotmatch']\n",
      "Measured class names: ['datainfluenced', 'mention', 'science', 'other', 'zerror', 'zlowprob', 'znotmatch']\n",
      "\n",
      "-\n",
      "Performance counter generated:\n",
      "Actual datainfluenced total: 8\n",
      "Actual datainfluenced vs Measured datainfluenced: 1\n",
      "Actual datainfluenced vs Measured mention: 1\n",
      "Actual datainfluenced vs Measured science: 2\n",
      "Actual datainfluenced vs Measured other: 0\n",
      "Actual datainfluenced vs Measured zerror: 3\n",
      "Actual datainfluenced vs Measured zlowprob: 1\n",
      "Actual datainfluenced vs Measured znotmatch: 0\n",
      "Actual datainfluenced vs Measured _total: 8\n",
      "Actual mention total: 457\n",
      "Actual mention vs Measured datainfluenced: 9\n",
      "Actual mention vs Measured mention: 314\n",
      "Actual mention vs Measured science: 33\n",
      "Actual mention vs Measured other: 0\n",
      "Actual mention vs Measured zerror: 44\n",
      "Actual mention vs Measured zlowprob: 48\n",
      "Actual mention vs Measured znotmatch: 9\n",
      "Actual mention vs Measured _total: 457\n",
      "Actual science total: 237\n",
      "Actual science vs Measured datainfluenced: 6\n",
      "Actual science vs Measured mention: 62\n",
      "Actual science vs Measured science: 115\n",
      "Actual science vs Measured other: 0\n",
      "Actual science vs Measured zerror: 27\n",
      "Actual science vs Measured zlowprob: 11\n",
      "Actual science vs Measured znotmatch: 16\n",
      "Actual science vs Measured _total: 237\n",
      "Actual other total: 1\n",
      "Actual other vs Measured datainfluenced: 0\n",
      "Actual other vs Measured mention: 1\n",
      "Actual other vs Measured science: 0\n",
      "Actual other vs Measured other: 0\n",
      "Actual other vs Measured zerror: 0\n",
      "Actual other vs Measured zlowprob: 0\n",
      "Actual other vs Measured znotmatch: 0\n",
      "Actual other vs Measured _total: 1\n",
      "Actual znotmatch total: 3297\n",
      "Actual znotmatch vs Measured datainfluenced: 1\n",
      "Actual znotmatch vs Measured mention: 49\n",
      "Actual znotmatch vs Measured science: 14\n",
      "Actual znotmatch vs Measured other: 0\n",
      "Actual znotmatch vs Measured zerror: 49\n",
      "Actual znotmatch vs Measured zlowprob: 14\n",
      "Actual znotmatch vs Measured znotmatch: 3170\n",
      "Actual znotmatch vs Measured _total: 3297\n",
      "\n",
      "-\n",
      "\n",
      "Run of _generate_performance_counter() complete!\n",
      "Threshold #3 of 13:\n",
      "\n",
      "> Running _generate_performance_counter() for: Operator_RB\n",
      "Accumulating performance over 500 texts.\n",
      "Actual class names: ['datainfluenced', 'mention', 'science', 'other', 'znotmatch']\n",
      "Measured class names: ['datainfluenced', 'mention', 'science', 'other', 'zerror', 'zlowprob', 'znotmatch']\n",
      "\n",
      "-\n",
      "Performance counter generated:\n",
      "Actual datainfluenced total: 8\n",
      "Actual datainfluenced vs Measured datainfluenced: 1\n",
      "Actual datainfluenced vs Measured mention: 1\n",
      "Actual datainfluenced vs Measured science: 2\n",
      "Actual datainfluenced vs Measured other: 0\n",
      "Actual datainfluenced vs Measured zerror: 3\n",
      "Actual datainfluenced vs Measured zlowprob: 1\n",
      "Actual datainfluenced vs Measured znotmatch: 0\n",
      "Actual datainfluenced vs Measured _total: 8\n",
      "Actual mention total: 457\n",
      "Actual mention vs Measured datainfluenced: 9\n",
      "Actual mention vs Measured mention: 312\n",
      "Actual mention vs Measured science: 33\n",
      "Actual mention vs Measured other: 0\n",
      "Actual mention vs Measured zerror: 44\n",
      "Actual mention vs Measured zlowprob: 50\n",
      "Actual mention vs Measured znotmatch: 9\n",
      "Actual mention vs Measured _total: 457\n",
      "Actual science total: 237\n",
      "Actual science vs Measured datainfluenced: 6\n",
      "Actual science vs Measured mention: 59\n",
      "Actual science vs Measured science: 110\n",
      "Actual science vs Measured other: 0\n",
      "Actual science vs Measured zerror: 27\n",
      "Actual science vs Measured zlowprob: 19\n",
      "Actual science vs Measured znotmatch: 16\n",
      "Actual science vs Measured _total: 237\n",
      "Actual other total: 1\n",
      "Actual other vs Measured datainfluenced: 0\n",
      "Actual other vs Measured mention: 1\n",
      "Actual other vs Measured science: 0\n",
      "Actual other vs Measured other: 0\n",
      "Actual other vs Measured zerror: 0\n",
      "Actual other vs Measured zlowprob: 0\n",
      "Actual other vs Measured znotmatch: 0\n",
      "Actual other vs Measured _total: 1\n",
      "Actual znotmatch total: 3297\n",
      "Actual znotmatch vs Measured datainfluenced: 1\n",
      "Actual znotmatch vs Measured mention: 49\n",
      "Actual znotmatch vs Measured science: 14\n",
      "Actual znotmatch vs Measured other: 0\n",
      "Actual znotmatch vs Measured zerror: 49\n",
      "Actual znotmatch vs Measured zlowprob: 14\n",
      "Actual znotmatch vs Measured znotmatch: 3170\n",
      "Actual znotmatch vs Measured _total: 3297\n",
      "\n",
      "-\n",
      "\n",
      "Run of _generate_performance_counter() complete!\n",
      "Threshold #4 of 13:\n",
      "\n",
      "> Running _generate_performance_counter() for: Operator_RB\n",
      "Accumulating performance over 500 texts.\n",
      "Actual class names: ['datainfluenced', 'mention', 'science', 'other', 'znotmatch']\n",
      "Measured class names: ['datainfluenced', 'mention', 'science', 'other', 'zerror', 'zlowprob', 'znotmatch']\n",
      "\n",
      "-\n",
      "Performance counter generated:\n",
      "Actual datainfluenced total: 8\n",
      "Actual datainfluenced vs Measured datainfluenced: 1\n",
      "Actual datainfluenced vs Measured mention: 0\n",
      "Actual datainfluenced vs Measured science: 2\n",
      "Actual datainfluenced vs Measured other: 0\n",
      "Actual datainfluenced vs Measured zerror: 3\n",
      "Actual datainfluenced vs Measured zlowprob: 2\n",
      "Actual datainfluenced vs Measured znotmatch: 0\n",
      "Actual datainfluenced vs Measured _total: 8\n",
      "Actual mention total: 457\n",
      "Actual mention vs Measured datainfluenced: 7\n",
      "Actual mention vs Measured mention: 304\n",
      "Actual mention vs Measured science: 25\n",
      "Actual mention vs Measured other: 0\n",
      "Actual mention vs Measured zerror: 44\n",
      "Actual mention vs Measured zlowprob: 68\n",
      "Actual mention vs Measured znotmatch: 9\n",
      "Actual mention vs Measured _total: 457\n",
      "Actual science total: 237\n",
      "Actual science vs Measured datainfluenced: 4\n",
      "Actual science vs Measured mention: 47\n",
      "Actual science vs Measured science: 104\n",
      "Actual science vs Measured other: 0\n",
      "Actual science vs Measured zerror: 27\n",
      "Actual science vs Measured zlowprob: 39\n",
      "Actual science vs Measured znotmatch: 16\n",
      "Actual science vs Measured _total: 237\n",
      "Actual other total: 1\n",
      "Actual other vs Measured datainfluenced: 0\n",
      "Actual other vs Measured mention: 1\n",
      "Actual other vs Measured science: 0\n",
      "Actual other vs Measured other: 0\n",
      "Actual other vs Measured zerror: 0\n",
      "Actual other vs Measured zlowprob: 0\n",
      "Actual other vs Measured znotmatch: 0\n",
      "Actual other vs Measured _total: 1\n",
      "Actual znotmatch total: 3297\n",
      "Actual znotmatch vs Measured datainfluenced: 1\n",
      "Actual znotmatch vs Measured mention: 46\n",
      "Actual znotmatch vs Measured science: 14\n",
      "Actual znotmatch vs Measured other: 0\n",
      "Actual znotmatch vs Measured zerror: 49\n",
      "Actual znotmatch vs Measured zlowprob: 17\n",
      "Actual znotmatch vs Measured znotmatch: 3170\n",
      "Actual znotmatch vs Measured _total: 3297\n",
      "\n",
      "-\n",
      "\n",
      "Run of _generate_performance_counter() complete!\n",
      "Threshold #5 of 13:\n",
      "\n",
      "> Running _generate_performance_counter() for: Operator_RB\n",
      "Accumulating performance over 500 texts.\n",
      "Actual class names: ['datainfluenced', 'mention', 'science', 'other', 'znotmatch']\n",
      "Measured class names: ['datainfluenced', 'mention', 'science', 'other', 'zerror', 'zlowprob', 'znotmatch']\n",
      "\n",
      "-\n",
      "Performance counter generated:\n",
      "Actual datainfluenced total: 8\n",
      "Actual datainfluenced vs Measured datainfluenced: 1\n",
      "Actual datainfluenced vs Measured mention: 0\n",
      "Actual datainfluenced vs Measured science: 2\n",
      "Actual datainfluenced vs Measured other: 0\n",
      "Actual datainfluenced vs Measured zerror: 3\n",
      "Actual datainfluenced vs Measured zlowprob: 2\n",
      "Actual datainfluenced vs Measured znotmatch: 0\n",
      "Actual datainfluenced vs Measured _total: 8\n",
      "Actual mention total: 457\n",
      "Actual mention vs Measured datainfluenced: 6\n",
      "Actual mention vs Measured mention: 291\n",
      "Actual mention vs Measured science: 22\n",
      "Actual mention vs Measured other: 0\n",
      "Actual mention vs Measured zerror: 44\n",
      "Actual mention vs Measured zlowprob: 85\n",
      "Actual mention vs Measured znotmatch: 9\n",
      "Actual mention vs Measured _total: 457\n",
      "Actual science total: 237\n",
      "Actual science vs Measured datainfluenced: 3\n",
      "Actual science vs Measured mention: 38\n",
      "Actual science vs Measured science: 99\n",
      "Actual science vs Measured other: 0\n",
      "Actual science vs Measured zerror: 27\n",
      "Actual science vs Measured zlowprob: 54\n",
      "Actual science vs Measured znotmatch: 16\n",
      "Actual science vs Measured _total: 237\n",
      "Actual other total: 1\n",
      "Actual other vs Measured datainfluenced: 0\n",
      "Actual other vs Measured mention: 1\n",
      "Actual other vs Measured science: 0\n",
      "Actual other vs Measured other: 0\n",
      "Actual other vs Measured zerror: 0\n",
      "Actual other vs Measured zlowprob: 0\n",
      "Actual other vs Measured znotmatch: 0\n",
      "Actual other vs Measured _total: 1\n",
      "Actual znotmatch total: 3297\n",
      "Actual znotmatch vs Measured datainfluenced: 1\n",
      "Actual znotmatch vs Measured mention: 44\n",
      "Actual znotmatch vs Measured science: 10\n",
      "Actual znotmatch vs Measured other: 0\n",
      "Actual znotmatch vs Measured zerror: 49\n",
      "Actual znotmatch vs Measured zlowprob: 23\n",
      "Actual znotmatch vs Measured znotmatch: 3170\n",
      "Actual znotmatch vs Measured _total: 3297\n",
      "\n",
      "-\n",
      "\n",
      "Run of _generate_performance_counter() complete!\n",
      "Threshold #6 of 13:\n",
      "\n",
      "> Running _generate_performance_counter() for: Operator_RB\n",
      "Accumulating performance over 500 texts.\n",
      "Actual class names: ['datainfluenced', 'mention', 'science', 'other', 'znotmatch']\n",
      "Measured class names: ['datainfluenced', 'mention', 'science', 'other', 'zerror', 'zlowprob', 'znotmatch']\n",
      "\n",
      "-\n",
      "Performance counter generated:\n",
      "Actual datainfluenced total: 8\n",
      "Actual datainfluenced vs Measured datainfluenced: 1\n",
      "Actual datainfluenced vs Measured mention: 0\n",
      "Actual datainfluenced vs Measured science: 2\n",
      "Actual datainfluenced vs Measured other: 0\n",
      "Actual datainfluenced vs Measured zerror: 3\n",
      "Actual datainfluenced vs Measured zlowprob: 2\n",
      "Actual datainfluenced vs Measured znotmatch: 0\n",
      "Actual datainfluenced vs Measured _total: 8\n",
      "Actual mention total: 457\n",
      "Actual mention vs Measured datainfluenced: 6\n",
      "Actual mention vs Measured mention: 273\n",
      "Actual mention vs Measured science: 20\n",
      "Actual mention vs Measured other: 0\n",
      "Actual mention vs Measured zerror: 44\n",
      "Actual mention vs Measured zlowprob: 105\n",
      "Actual mention vs Measured znotmatch: 9\n",
      "Actual mention vs Measured _total: 457\n",
      "Actual science total: 237\n",
      "Actual science vs Measured datainfluenced: 2\n",
      "Actual science vs Measured mention: 25\n",
      "Actual science vs Measured science: 97\n",
      "Actual science vs Measured other: 0\n",
      "Actual science vs Measured zerror: 27\n",
      "Actual science vs Measured zlowprob: 70\n",
      "Actual science vs Measured znotmatch: 16\n",
      "Actual science vs Measured _total: 237\n",
      "Actual other total: 1\n",
      "Actual other vs Measured datainfluenced: 0\n",
      "Actual other vs Measured mention: 1\n",
      "Actual other vs Measured science: 0\n",
      "Actual other vs Measured other: 0\n",
      "Actual other vs Measured zerror: 0\n",
      "Actual other vs Measured zlowprob: 0\n",
      "Actual other vs Measured znotmatch: 0\n",
      "Actual other vs Measured _total: 1\n",
      "Actual znotmatch total: 3297\n",
      "Actual znotmatch vs Measured datainfluenced: 1\n",
      "Actual znotmatch vs Measured mention: 43\n",
      "Actual znotmatch vs Measured science: 9\n",
      "Actual znotmatch vs Measured other: 0\n",
      "Actual znotmatch vs Measured zerror: 49\n",
      "Actual znotmatch vs Measured zlowprob: 25\n",
      "Actual znotmatch vs Measured znotmatch: 3170\n",
      "Actual znotmatch vs Measured _total: 3297\n",
      "\n",
      "-\n",
      "\n",
      "Run of _generate_performance_counter() complete!\n",
      "Threshold #7 of 13:\n",
      "\n",
      "> Running _generate_performance_counter() for: Operator_RB\n",
      "Accumulating performance over 500 texts.\n",
      "Actual class names: ['datainfluenced', 'mention', 'science', 'other', 'znotmatch']\n",
      "Measured class names: ['datainfluenced', 'mention', 'science', 'other', 'zerror', 'zlowprob', 'znotmatch']\n",
      "\n",
      "-\n",
      "Performance counter generated:\n",
      "Actual datainfluenced total: 8\n",
      "Actual datainfluenced vs Measured datainfluenced: 1\n",
      "Actual datainfluenced vs Measured mention: 0\n",
      "Actual datainfluenced vs Measured science: 2\n",
      "Actual datainfluenced vs Measured other: 0\n",
      "Actual datainfluenced vs Measured zerror: 3\n",
      "Actual datainfluenced vs Measured zlowprob: 2\n",
      "Actual datainfluenced vs Measured znotmatch: 0\n",
      "Actual datainfluenced vs Measured _total: 8\n",
      "Actual mention total: 457\n",
      "Actual mention vs Measured datainfluenced: 3\n",
      "Actual mention vs Measured mention: 254\n",
      "Actual mention vs Measured science: 20\n",
      "Actual mention vs Measured other: 0\n",
      "Actual mention vs Measured zerror: 44\n",
      "Actual mention vs Measured zlowprob: 127\n",
      "Actual mention vs Measured znotmatch: 9\n",
      "Actual mention vs Measured _total: 457\n",
      "Actual science total: 237\n",
      "Actual science vs Measured datainfluenced: 2\n",
      "Actual science vs Measured mention: 21\n",
      "Actual science vs Measured science: 95\n",
      "Actual science vs Measured other: 0\n",
      "Actual science vs Measured zerror: 27\n",
      "Actual science vs Measured zlowprob: 76\n",
      "Actual science vs Measured znotmatch: 16\n",
      "Actual science vs Measured _total: 237\n",
      "Actual other total: 1\n",
      "Actual other vs Measured datainfluenced: 0\n",
      "Actual other vs Measured mention: 1\n",
      "Actual other vs Measured science: 0\n",
      "Actual other vs Measured other: 0\n",
      "Actual other vs Measured zerror: 0\n",
      "Actual other vs Measured zlowprob: 0\n",
      "Actual other vs Measured znotmatch: 0\n",
      "Actual other vs Measured _total: 1\n",
      "Actual znotmatch total: 3297\n",
      "Actual znotmatch vs Measured datainfluenced: 1\n",
      "Actual znotmatch vs Measured mention: 40\n",
      "Actual znotmatch vs Measured science: 9\n",
      "Actual znotmatch vs Measured other: 0\n",
      "Actual znotmatch vs Measured zerror: 49\n",
      "Actual znotmatch vs Measured zlowprob: 28\n",
      "Actual znotmatch vs Measured znotmatch: 3170\n",
      "Actual znotmatch vs Measured _total: 3297\n",
      "\n",
      "-\n",
      "\n",
      "Run of _generate_performance_counter() complete!\n",
      "Threshold #8 of 13:\n",
      "\n",
      "> Running _generate_performance_counter() for: Operator_RB\n",
      "Accumulating performance over 500 texts.\n",
      "Actual class names: ['datainfluenced', 'mention', 'science', 'other', 'znotmatch']\n",
      "Measured class names: ['datainfluenced', 'mention', 'science', 'other', 'zerror', 'zlowprob', 'znotmatch']\n",
      "\n",
      "-\n",
      "Performance counter generated:\n",
      "Actual datainfluenced total: 8\n",
      "Actual datainfluenced vs Measured datainfluenced: 1\n",
      "Actual datainfluenced vs Measured mention: 0\n",
      "Actual datainfluenced vs Measured science: 2\n",
      "Actual datainfluenced vs Measured other: 0\n",
      "Actual datainfluenced vs Measured zerror: 3\n",
      "Actual datainfluenced vs Measured zlowprob: 2\n",
      "Actual datainfluenced vs Measured znotmatch: 0\n",
      "Actual datainfluenced vs Measured _total: 8\n",
      "Actual mention total: 457\n",
      "Actual mention vs Measured datainfluenced: 3\n",
      "Actual mention vs Measured mention: 242\n",
      "Actual mention vs Measured science: 19\n",
      "Actual mention vs Measured other: 0\n",
      "Actual mention vs Measured zerror: 44\n",
      "Actual mention vs Measured zlowprob: 140\n",
      "Actual mention vs Measured znotmatch: 9\n",
      "Actual mention vs Measured _total: 457\n",
      "Actual science total: 237\n",
      "Actual science vs Measured datainfluenced: 2\n",
      "Actual science vs Measured mention: 12\n",
      "Actual science vs Measured science: 92\n",
      "Actual science vs Measured other: 0\n",
      "Actual science vs Measured zerror: 27\n",
      "Actual science vs Measured zlowprob: 88\n",
      "Actual science vs Measured znotmatch: 16\n",
      "Actual science vs Measured _total: 237\n",
      "Actual other total: 1\n",
      "Actual other vs Measured datainfluenced: 0\n",
      "Actual other vs Measured mention: 1\n",
      "Actual other vs Measured science: 0\n",
      "Actual other vs Measured other: 0\n",
      "Actual other vs Measured zerror: 0\n",
      "Actual other vs Measured zlowprob: 0\n",
      "Actual other vs Measured znotmatch: 0\n",
      "Actual other vs Measured _total: 1\n",
      "Actual znotmatch total: 3297\n",
      "Actual znotmatch vs Measured datainfluenced: 1\n",
      "Actual znotmatch vs Measured mention: 39\n",
      "Actual znotmatch vs Measured science: 9\n",
      "Actual znotmatch vs Measured other: 0\n",
      "Actual znotmatch vs Measured zerror: 49\n",
      "Actual znotmatch vs Measured zlowprob: 29\n",
      "Actual znotmatch vs Measured znotmatch: 3170\n",
      "Actual znotmatch vs Measured _total: 3297\n",
      "\n",
      "-\n",
      "\n",
      "Run of _generate_performance_counter() complete!\n",
      "Threshold #9 of 13:\n",
      "\n",
      "> Running _generate_performance_counter() for: Operator_RB\n",
      "Accumulating performance over 500 texts.\n",
      "Actual class names: ['datainfluenced', 'mention', 'science', 'other', 'znotmatch']\n",
      "Measured class names: ['datainfluenced', 'mention', 'science', 'other', 'zerror', 'zlowprob', 'znotmatch']\n",
      "\n",
      "-\n",
      "Performance counter generated:\n",
      "Actual datainfluenced total: 8\n",
      "Actual datainfluenced vs Measured datainfluenced: 1\n",
      "Actual datainfluenced vs Measured mention: 0\n",
      "Actual datainfluenced vs Measured science: 2\n",
      "Actual datainfluenced vs Measured other: 0\n",
      "Actual datainfluenced vs Measured zerror: 3\n",
      "Actual datainfluenced vs Measured zlowprob: 2\n",
      "Actual datainfluenced vs Measured znotmatch: 0\n",
      "Actual datainfluenced vs Measured _total: 8\n",
      "Actual mention total: 457\n",
      "Actual mention vs Measured datainfluenced: 3\n",
      "Actual mention vs Measured mention: 235\n",
      "Actual mention vs Measured science: 19\n",
      "Actual mention vs Measured other: 0\n",
      "Actual mention vs Measured zerror: 44\n",
      "Actual mention vs Measured zlowprob: 147\n",
      "Actual mention vs Measured znotmatch: 9\n",
      "Actual mention vs Measured _total: 457\n",
      "Actual science total: 237\n",
      "Actual science vs Measured datainfluenced: 2\n",
      "Actual science vs Measured mention: 12\n",
      "Actual science vs Measured science: 91\n",
      "Actual science vs Measured other: 0\n",
      "Actual science vs Measured zerror: 27\n",
      "Actual science vs Measured zlowprob: 89\n",
      "Actual science vs Measured znotmatch: 16\n",
      "Actual science vs Measured _total: 237\n",
      "Actual other total: 1\n",
      "Actual other vs Measured datainfluenced: 0\n",
      "Actual other vs Measured mention: 0\n",
      "Actual other vs Measured science: 0\n",
      "Actual other vs Measured other: 0\n",
      "Actual other vs Measured zerror: 0\n",
      "Actual other vs Measured zlowprob: 1\n",
      "Actual other vs Measured znotmatch: 0\n",
      "Actual other vs Measured _total: 1\n",
      "Actual znotmatch total: 3297\n",
      "Actual znotmatch vs Measured datainfluenced: 1\n",
      "Actual znotmatch vs Measured mention: 37\n",
      "Actual znotmatch vs Measured science: 9\n",
      "Actual znotmatch vs Measured other: 0\n",
      "Actual znotmatch vs Measured zerror: 49\n",
      "Actual znotmatch vs Measured zlowprob: 31\n",
      "Actual znotmatch vs Measured znotmatch: 3170\n",
      "Actual znotmatch vs Measured _total: 3297\n",
      "\n",
      "-\n",
      "\n",
      "Run of _generate_performance_counter() complete!\n",
      "Threshold #10 of 13:\n",
      "\n",
      "> Running _generate_performance_counter() for: Operator_RB\n",
      "Accumulating performance over 500 texts.\n",
      "Actual class names: ['datainfluenced', 'mention', 'science', 'other', 'znotmatch']\n",
      "Measured class names: ['datainfluenced', 'mention', 'science', 'other', 'zerror', 'zlowprob', 'znotmatch']\n",
      "\n",
      "-\n",
      "Performance counter generated:\n",
      "Actual datainfluenced total: 8\n",
      "Actual datainfluenced vs Measured datainfluenced: 1\n",
      "Actual datainfluenced vs Measured mention: 0\n",
      "Actual datainfluenced vs Measured science: 2\n",
      "Actual datainfluenced vs Measured other: 0\n",
      "Actual datainfluenced vs Measured zerror: 3\n",
      "Actual datainfluenced vs Measured zlowprob: 2\n",
      "Actual datainfluenced vs Measured znotmatch: 0\n",
      "Actual datainfluenced vs Measured _total: 8\n",
      "Actual mention total: 457\n",
      "Actual mention vs Measured datainfluenced: 3\n",
      "Actual mention vs Measured mention: 164\n",
      "Actual mention vs Measured science: 19\n",
      "Actual mention vs Measured other: 0\n",
      "Actual mention vs Measured zerror: 44\n",
      "Actual mention vs Measured zlowprob: 218\n",
      "Actual mention vs Measured znotmatch: 9\n",
      "Actual mention vs Measured _total: 457\n",
      "Actual science total: 237\n",
      "Actual science vs Measured datainfluenced: 2\n",
      "Actual science vs Measured mention: 8\n",
      "Actual science vs Measured science: 91\n",
      "Actual science vs Measured other: 0\n",
      "Actual science vs Measured zerror: 27\n",
      "Actual science vs Measured zlowprob: 93\n",
      "Actual science vs Measured znotmatch: 16\n",
      "Actual science vs Measured _total: 237\n",
      "Actual other total: 1\n",
      "Actual other vs Measured datainfluenced: 0\n",
      "Actual other vs Measured mention: 0\n",
      "Actual other vs Measured science: 0\n",
      "Actual other vs Measured other: 0\n",
      "Actual other vs Measured zerror: 0\n",
      "Actual other vs Measured zlowprob: 1\n",
      "Actual other vs Measured znotmatch: 0\n",
      "Actual other vs Measured _total: 1\n",
      "Actual znotmatch total: 3297\n",
      "Actual znotmatch vs Measured datainfluenced: 1\n",
      "Actual znotmatch vs Measured mention: 30\n",
      "Actual znotmatch vs Measured science: 9\n",
      "Actual znotmatch vs Measured other: 0\n",
      "Actual znotmatch vs Measured zerror: 49\n",
      "Actual znotmatch vs Measured zlowprob: 38\n",
      "Actual znotmatch vs Measured znotmatch: 3170\n",
      "Actual znotmatch vs Measured _total: 3297\n",
      "\n",
      "-\n",
      "\n",
      "Run of _generate_performance_counter() complete!\n",
      "Threshold #11 of 13:\n",
      "\n",
      "> Running _generate_performance_counter() for: Operator_RB\n",
      "Accumulating performance over 500 texts.\n",
      "Actual class names: ['datainfluenced', 'mention', 'science', 'other', 'znotmatch']\n",
      "Measured class names: ['datainfluenced', 'mention', 'science', 'other', 'zerror', 'zlowprob', 'znotmatch']\n",
      "\n",
      "-\n",
      "Performance counter generated:\n",
      "Actual datainfluenced total: 8\n",
      "Actual datainfluenced vs Measured datainfluenced: 0\n",
      "Actual datainfluenced vs Measured mention: 0\n",
      "Actual datainfluenced vs Measured science: 2\n",
      "Actual datainfluenced vs Measured other: 0\n",
      "Actual datainfluenced vs Measured zerror: 3\n",
      "Actual datainfluenced vs Measured zlowprob: 3\n",
      "Actual datainfluenced vs Measured znotmatch: 0\n",
      "Actual datainfluenced vs Measured _total: 8\n",
      "Actual mention total: 457\n",
      "Actual mention vs Measured datainfluenced: 0\n",
      "Actual mention vs Measured mention: 97\n",
      "Actual mention vs Measured science: 18\n",
      "Actual mention vs Measured other: 0\n",
      "Actual mention vs Measured zerror: 44\n",
      "Actual mention vs Measured zlowprob: 289\n",
      "Actual mention vs Measured znotmatch: 9\n",
      "Actual mention vs Measured _total: 457\n",
      "Actual science total: 237\n",
      "Actual science vs Measured datainfluenced: 0\n",
      "Actual science vs Measured mention: 2\n",
      "Actual science vs Measured science: 91\n",
      "Actual science vs Measured other: 0\n",
      "Actual science vs Measured zerror: 27\n",
      "Actual science vs Measured zlowprob: 101\n",
      "Actual science vs Measured znotmatch: 16\n",
      "Actual science vs Measured _total: 237\n",
      "Actual other total: 1\n",
      "Actual other vs Measured datainfluenced: 0\n",
      "Actual other vs Measured mention: 0\n",
      "Actual other vs Measured science: 0\n",
      "Actual other vs Measured other: 0\n",
      "Actual other vs Measured zerror: 0\n",
      "Actual other vs Measured zlowprob: 1\n",
      "Actual other vs Measured znotmatch: 0\n",
      "Actual other vs Measured _total: 1\n",
      "Actual znotmatch total: 3297\n",
      "Actual znotmatch vs Measured datainfluenced: 0\n",
      "Actual znotmatch vs Measured mention: 18\n",
      "Actual znotmatch vs Measured science: 9\n",
      "Actual znotmatch vs Measured other: 0\n",
      "Actual znotmatch vs Measured zerror: 49\n",
      "Actual znotmatch vs Measured zlowprob: 51\n",
      "Actual znotmatch vs Measured znotmatch: 3170\n",
      "Actual znotmatch vs Measured _total: 3297\n",
      "\n",
      "-\n",
      "\n",
      "Run of _generate_performance_counter() complete!\n",
      "Threshold #12 of 13:\n",
      "\n",
      "> Running _generate_performance_counter() for: Operator_RB\n",
      "Accumulating performance over 500 texts.\n",
      "Actual class names: ['datainfluenced', 'mention', 'science', 'other', 'znotmatch']\n",
      "Measured class names: ['datainfluenced', 'mention', 'science', 'other', 'zerror', 'zlowprob', 'znotmatch']\n",
      "\n",
      "-\n",
      "Performance counter generated:\n",
      "Actual datainfluenced total: 8\n",
      "Actual datainfluenced vs Measured datainfluenced: 0\n",
      "Actual datainfluenced vs Measured mention: 0\n",
      "Actual datainfluenced vs Measured science: 1\n",
      "Actual datainfluenced vs Measured other: 0\n",
      "Actual datainfluenced vs Measured zerror: 3\n",
      "Actual datainfluenced vs Measured zlowprob: 4\n",
      "Actual datainfluenced vs Measured znotmatch: 0\n",
      "Actual datainfluenced vs Measured _total: 8\n",
      "Actual mention total: 457\n",
      "Actual mention vs Measured datainfluenced: 0\n",
      "Actual mention vs Measured mention: 87\n",
      "Actual mention vs Measured science: 11\n",
      "Actual mention vs Measured other: 0\n",
      "Actual mention vs Measured zerror: 44\n",
      "Actual mention vs Measured zlowprob: 306\n",
      "Actual mention vs Measured znotmatch: 9\n",
      "Actual mention vs Measured _total: 457\n",
      "Actual science total: 237\n",
      "Actual science vs Measured datainfluenced: 0\n",
      "Actual science vs Measured mention: 0\n",
      "Actual science vs Measured science: 11\n",
      "Actual science vs Measured other: 0\n",
      "Actual science vs Measured zerror: 27\n",
      "Actual science vs Measured zlowprob: 183\n",
      "Actual science vs Measured znotmatch: 16\n",
      "Actual science vs Measured _total: 237\n",
      "Actual other total: 1\n",
      "Actual other vs Measured datainfluenced: 0\n",
      "Actual other vs Measured mention: 0\n",
      "Actual other vs Measured science: 0\n",
      "Actual other vs Measured other: 0\n",
      "Actual other vs Measured zerror: 0\n",
      "Actual other vs Measured zlowprob: 1\n",
      "Actual other vs Measured znotmatch: 0\n",
      "Actual other vs Measured _total: 1\n",
      "Actual znotmatch total: 3297\n",
      "Actual znotmatch vs Measured datainfluenced: 0\n",
      "Actual znotmatch vs Measured mention: 16\n",
      "Actual znotmatch vs Measured science: 6\n",
      "Actual znotmatch vs Measured other: 0\n",
      "Actual znotmatch vs Measured zerror: 49\n",
      "Actual znotmatch vs Measured zlowprob: 56\n",
      "Actual znotmatch vs Measured znotmatch: 3170\n",
      "Actual znotmatch vs Measured _total: 3297\n",
      "\n",
      "-\n",
      "\n",
      "Run of _generate_performance_counter() complete!\n",
      "Threshold #13 of 13:\n",
      "\n",
      "> Running _generate_performance_counter() for: Operator_RB\n",
      "Accumulating performance over 500 texts.\n",
      "Actual class names: ['datainfluenced', 'mention', 'science', 'other', 'znotmatch']\n",
      "Measured class names: ['datainfluenced', 'mention', 'science', 'other', 'zerror', 'zlowprob', 'znotmatch']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-\n",
      "Performance counter generated:\n",
      "Actual datainfluenced total: 8\n",
      "Actual datainfluenced vs Measured datainfluenced: 0\n",
      "Actual datainfluenced vs Measured mention: 0\n",
      "Actual datainfluenced vs Measured science: 1\n",
      "Actual datainfluenced vs Measured other: 0\n",
      "Actual datainfluenced vs Measured zerror: 3\n",
      "Actual datainfluenced vs Measured zlowprob: 4\n",
      "Actual datainfluenced vs Measured znotmatch: 0\n",
      "Actual datainfluenced vs Measured _total: 8\n",
      "Actual mention total: 457\n",
      "Actual mention vs Measured datainfluenced: 0\n",
      "Actual mention vs Measured mention: 68\n",
      "Actual mention vs Measured science: 5\n",
      "Actual mention vs Measured other: 0\n",
      "Actual mention vs Measured zerror: 44\n",
      "Actual mention vs Measured zlowprob: 331\n",
      "Actual mention vs Measured znotmatch: 9\n",
      "Actual mention vs Measured _total: 457\n",
      "Actual science total: 237\n",
      "Actual science vs Measured datainfluenced: 0\n",
      "Actual science vs Measured mention: 0\n",
      "Actual science vs Measured science: 8\n",
      "Actual science vs Measured other: 0\n",
      "Actual science vs Measured zerror: 27\n",
      "Actual science vs Measured zlowprob: 186\n",
      "Actual science vs Measured znotmatch: 16\n",
      "Actual science vs Measured _total: 237\n",
      "Actual other total: 1\n",
      "Actual other vs Measured datainfluenced: 0\n",
      "Actual other vs Measured mention: 0\n",
      "Actual other vs Measured science: 0\n",
      "Actual other vs Measured other: 0\n",
      "Actual other vs Measured zerror: 0\n",
      "Actual other vs Measured zlowprob: 1\n",
      "Actual other vs Measured znotmatch: 0\n",
      "Actual other vs Measured _total: 1\n",
      "Actual znotmatch total: 3297\n",
      "Actual znotmatch vs Measured datainfluenced: 0\n",
      "Actual znotmatch vs Measured mention: 15\n",
      "Actual znotmatch vs Measured science: 2\n",
      "Actual znotmatch vs Measured other: 0\n",
      "Actual znotmatch vs Measured zerror: 49\n",
      "Actual znotmatch vs Measured zlowprob: 61\n",
      "Actual znotmatch vs Measured znotmatch: 3170\n",
      "Actual znotmatch vs Measured _total: 3297\n",
      "\n",
      "-\n",
      "\n",
      "Run of _generate_performance_counter() complete!\n",
      "\n",
      "Evaluations generated.\n",
      "Plotting performance with respect to uncertainty...\n",
      "Results have been plotted at:\n",
      "/Users/jamila.pegues/Documents/STScI_Fellowship/Functional/Library/BibTracking/repo_stsci/bibcat/src/models/test_run_rule/output\n",
      "\n",
      "Run of evaluate_performance_uncertainty() complete!\n"
     ]
    }
   ],
   "source": [
    "#Parameters for this evaluation\n",
    "filename_root = \"performance_grid_uncertainty_{0}\".format(name_model)\n",
    "figsize = (40, 12)\n",
    "colors = [\"tomato\", \"dodgerblue\", \"silver\", \"purple\", \"dimgray\", \"darkgoldenrod\", \"darkgreen\", \"green\", \"cyan\"]\n",
    "linestyles = [\"-\", \"-\", \"--\", \"-\", \"--\", \"--\", \":\", \":\", \":\"]\n",
    "\n",
    "#Run the pipeline for an evaluation of model performance as a function of uncertainty\n",
    "performer.evaluate_performance_uncertainty(operators=list_operators, dicts_texts=list_dict_texts, mappers=list_mappers,\n",
    "                                     threshold_arrays=list_threshold_arrays, buffers=list_buffers,\n",
    "                                     is_text_processed=False, do_reuse_run=do_reuse_run,\n",
    "                                     do_verify_truematch=do_verify_truematch, do_raise_innererror=do_raise_innererror,\n",
    "                                     do_save_evaluation=True, filepath_output=filepath_output,\n",
    "                                     fileroot_evaluation=fileroot_evaluation,\n",
    "                                     filename_root=filename_root,\n",
    "                                     print_freq=25, do_verbose=True, do_verbose_deep=False, figsize=figsize,\n",
    "                                     target_classifs=target_classifs_uncertainty,\n",
    "                                     colors=colors, linestyles=linestyles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3ceb74-7087-4256-8044-59f4cb97db51",
   "metadata": {},
   "source": [
    "And with that, you should have new confusion matrices summarizing the basic performance for these classifiers saved in your requested directory!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee10749-9dc1-4460-a34c-18ecb413f450",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8c8f912-089e-462c-b345-9710f35a03f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This tutorial completed successfully.\n"
     ]
    }
   ],
   "source": [
    "#Set end marker for this tutorial.\n",
    "print(\"This tutorial completed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
