{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e71ff86",
   "metadata": {},
   "source": [
    "# Bibliography Categorization: 'BibCat'\n",
    "## Tutorial: Machine learning (ML) models in bibcat.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3ab7e4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d234a479",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction.\n",
    "\n",
    "In this tutorial, we will use bibcat to train a machine learning (ML) model on some raw input text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f050727",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86289680",
   "metadata": {},
   "source": [
    "## User Workflow: Training a machine learning (ML) model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af236d7a",
   "metadata": {},
   "source": [
    "The `Operator` class contains a user-friendly method `train_model_ML` that runs the full workflow for training an ML model, from the input raw text all the way to saving the output ML model.  We overview how this method can be run in the code blocks below.\n",
    "\n",
    "For this tutorial, we have two sets of data: either 1) some short, made-up text for a quick run of the code, or 2) an imported database of text from an external file of the user's choosing. The former case is useful for getting a quick sense of how the code works. The latter case is useful for building an actual model, but of course will take much longer on larger databases of text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e1149ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fdea077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import external packages\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f14b847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: /Users/jyoon/GitHub/bibcat/docs\n",
      "Source directory: /Users/jyoon/GitHub/bibcat/src\n"
     ]
    }
   ],
   "source": [
    "# Set up for fetching necessary bibcat modules for the tutorial\n",
    "# Check work directories: src/ is where all source python scripts are available. \n",
    "current_dir= os.path.dirname(os.path.abspath('__file__'))\n",
    "_parent = os.path.dirname(current_dir)\n",
    "src_dir = os.path.join(_parent, \"src\")\n",
    "\n",
    "print(f'Current Directory: {current_dir}')\n",
    "print(f'Source directory: {src_dir}')\n",
    "\n",
    "# move to the ../src/ directory to import necessary modules. \n",
    "os.chdir(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8643e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root directory =/Users/jyoon/GitHub/bibcat/src, parent directory=/Users/jyoon/GitHub/bibcat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jyoon/anaconda3/envs/bib_tensorflow_py310/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Import bibcat packages\n",
    "import bibcat_classes as bibcat\n",
    "import bibcat_config as config\n",
    "import bibcat_constants as preset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7ef4fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which data would you like to run the ML model on?  Choose from the booleans below.\n",
    "do_quick_run = True #This will train the ML model on short bits of text. Runs pretty quickly.\n",
    "do_real_run = False #This will train the ML model on external text. Will take longer for larger databases.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed0ced33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The rest of these parameters can be left as-is for a first run-through.\n",
    "#\n",
    "num_papers = 500 #500 #None, or an integer; if an integer, will truncate external .json text dataset to this size\n",
    "#Set num_papers=None to use all available papers in external dataset\n",
    "#Note: If set to integer, final paper count might be a little more than target num_papers given\n",
    "#\n",
    "allowed_classifications = config.allowed_classifications #For external data; classifications to include\n",
    "#\n",
    "\n",
    "#Fetch filepaths for model and data\n",
    "name_model = config.name_model\n",
    "filepath_json = config.path_json\n",
    "dir_model = os.path.join(config.dir_allmodels, name_model)\n",
    "#\n",
    "#Set values for generating ML model\n",
    "do_reuse_run = True #Whether or not to reuse any existing output from previous training+validation+testing runs\n",
    "do_shuffle = True #Whether or not to shuffle contents of training vs validation vs testing datasets\n",
    "fraction_TVT = [0.8, 0.1, 0.1] #Fractional breakdown of training vs validation vs testing datasets\n",
    "#\n",
    "mode_TVT = \"uniform\" # \"uniform\" #\"available\"\n",
    "#\"uniform\" = all training datasets will have the same number of entries\n",
    "#\"available\" = all training datasets will use full fraction (from fraction_TVT) of data available\n",
    "#\n",
    "seed_TVT = 10 #Random seed for generating training vs validation vs testing datasets\n",
    "seed_ML = 8 #Random seed for ML model\n",
    "mode_modif = \"skim_trim_anon\" #Mode to use for processing and generating modifs from input raw text\n",
    "#NOTE: See other modif modes in workflow tutorial\n",
    "buffer = 0\n",
    "#\n",
    "#Prepare some Keyword objects\n",
    "kobj_hubble = bibcat.Keyword(\n",
    "                keywords=[\"Hubble\", \"Hubble Telescope\",\n",
    "                          \"Hubble Space Telescope\"],\n",
    "                acronyms=[\"hst\", \"ht\"])\n",
    "all_kobjs = [kobj_hubble]\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97faa2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize an empty ML classifier\n",
    "classifier_ML = bibcat.Classifier_ML(filepath_model=None, fileloc_ML=None,\n",
    "                                    class_names=None, do_verbose=True)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd0f528d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance of Operator successfully initialized!\n",
      "Keyword objects:\n",
      "0: Keyword Object:\n",
      "Name: Hubble\n",
      "Keywords: ['Hubble Space Telescope', 'Hubble Telescope', 'Hubble']\n",
      "Acronyms: ['hst', 'ht']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Initialize an Operator\n",
    "tabby_ML = bibcat.Operator(classifier=classifier_ML, mode=mode_modif, keyword_objs=all_kobjs,\n",
    "                           do_verbose=True, load_check_truematch=False, do_verbose_deep=False)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dac2f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up data for the quick example case. But in reality, ML models should be trained on MUCH more data than this!!!\n",
    "if do_quick_run:\n",
    "    #Make some fake data\n",
    "    dict_texts_raw = {\"science\":[\"We present HST observations in Figure 4.\",\n",
    "                            \"The HST stars are listed in Table 3b.\",\n",
    "                            \"Despite our efforts to smooth the data, there are still rings in the HST images.\",\n",
    "                            \"See Section 8c for more discussion of the Hubble images.\",\n",
    "                            \"The supernovae detected with HST tend to be brighter than initially predicted.\",\n",
    "                            \"Our spectra from HST fit well to the standard trend first published in Someone et al. 1990.\",\n",
    "                            \"We use the Hubble Space Telescope to build an ultraviolet database of the target stars.\",\n",
    "                            \"The blue points (HST) exhibit more scatter than the red points (JWST).\",\n",
    "                            \"The benefit, then, is the far higher S/N we achieved in our HST observations.\",\n",
    "                            \"Here we employ the Hubble Telescope to observe the edge of the photon-dominated region.\",\n",
    "                            \"The black line shows that the region targeted with Hubble has an extreme UV signature.\"],\n",
    "                     \"datainfluenced\":[\"The simulated Hubble data is plotted in Figure 4.\",\n",
    "                           \"Compared to the HST observations in Someone et al., our JWST follow-up reached higher S/N.\",\n",
    "                           \"We were able to reproduce the luminosities from Hubble using our latest models.\",\n",
    "                           \"We overplot Hubble-observed stars from Someone et al. in Figure 3b.\",\n",
    "                           \"We built the spectral templates using UV data in the Hubble archive.\",\n",
    "                           \"We simulate what our future HST observations will look like to predict the S/N.\",\n",
    "                           \"Our work here with JWST is inspired by our earlier HST study published in 2010.\",\n",
    "                           \"We therefore use the Hubble statistics from Author et al. to guide our stellar predictions.\",\n",
    "                           \"The stars in Figure 3 were plotted based on the HST-fitted trend line in Person et al.\",\n",
    "                           \"The final step is to use the HST exposure tool to put our modeled images in context.\"],\n",
    "                     \"mention\":[\"Person et al. used HST to measure the Hubble constant.\",\n",
    "                            \"We will present new HST observations in a future work.\",\n",
    "                            \"HST is do_a fantastic instrument that has revolutionized our view of space.\",\n",
    "                            \"The Hubble Space Telescope (HST) has its mission center at the STScI.\",\n",
    "                            \"We can use HST to power a variety of science in the ultraviolet regime.\",\n",
    "                            \"It is not clear when the star will be observable with HST.\",\n",
    "                            \"More data can be found and downloaded from the Hubble archive.\",\n",
    "                            \"We note that HST can be used to observe the stars as well, at higher S/N.\",\n",
    "                            \"However, we ended up using the JWST rather than HST observations in this work.\",\n",
    "                            \"We push the analysis of the Hubble component of the dataset to a future study.\",\n",
    "                            \"We expect the HST observations to be released in the fall.\",\n",
    "                            \"We look forward to any follow-up studies with, e.g., the Hubble Telescope.\"]}\n",
    "    #\n",
    "    #Convert into dictionary with: key:text,class,id,mission structure\n",
    "    i_track = 0\n",
    "    dict_texts = {}\n",
    "    for key in dict_texts_raw:\n",
    "        curr_set = dict_texts_raw[key]\n",
    "        for ii in range(0, len(curr_set)):\n",
    "            dict_texts[str(i_track)] = {\"text\":curr_set[ii], \"class\":key, \"id\":\"{0}_{1}\".format(key, ii),\n",
    "                                       \"mission\":\"HST\"}\n",
    "            i_track += 1\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d25644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up data for the external data case.\n",
    "if do_real_run:\n",
    "    #Load the original data\n",
    "    with open(filepath_json, 'r') as openfile:\n",
    "        dataset = json.load(openfile)\n",
    "        len(dataset)\n",
    "    #\n",
    "    #Organize a new version of the data with: key:text,class,id,mission structure\n",
    "    i_track = 0 #Track number of papers kept from original dataset\n",
    "    dict_texts = {}\n",
    "    for ii in range(0, len(dataset)):\n",
    "        #Extract mission classifications for current text\n",
    "        curr_data = dataset[ii]\n",
    "        #\n",
    "        #Skip if no valid text at all for this text\n",
    "        if (\"body\" not in curr_data):\n",
    "            continue\n",
    "        #\n",
    "        #Skip if no valid missions at all for this text\n",
    "        if (\"class_missions\" not in curr_data):\n",
    "            continue\n",
    "        #\n",
    "        #Otherwise, extract the missions\n",
    "        curr_missions = curr_data[\"class_missions\"]\n",
    "        #\n",
    "        print(curr_missions)\n",
    "        #Iterate through missions for this text\n",
    "        i_mission = 0\n",
    "        for curr_key in curr_missions:\n",
    "            #If this is not an allowed mission, skip\n",
    "            if (curr_missions[curr_key][\"papertype\"] not in allowed_classifications):\n",
    "                continue\n",
    "            #\n",
    "            #Otherwise, check if this mission is a target mission\n",
    "            fetched_kobj = tabby_ML._fetch_keyword_object(lookup=curr_key,\n",
    "                                                          do_verbose=False, do_raise_emptyerror=False)\n",
    "            #Skip if not a target\n",
    "            if (fetched_kobj is None):\n",
    "                continue\n",
    "            #\n",
    "            #Otherwise, store classification info for this entry\n",
    "            curr_class = curr_missions[curr_key][\"papertype\"]\n",
    "            new_dict = {\"text\":curr_data[\"body\"], #Text for this paper\n",
    "                        \"class\":curr_class, #Classification for this mission\n",
    "                        \"mission\":curr_key, #The mission itself\n",
    "                        \"id\":(\"paper{0}_mission{1}_{2}_{3}\".format(ii, i_mission,\n",
    "                                                                   curr_key, curr_class)) #ID for this entry\n",
    "                       }\n",
    "            dict_texts[str(i_track)] = new_dict\n",
    "            #\n",
    "            #Increment counters\n",
    "            i_mission += 1 #Count of kept missions for this paper\n",
    "            i_track += 1 #Count of kept classifications overall\n",
    "        #\n",
    "\n",
    "        #Terminate early if requested number of papers reached\n",
    "        if ((num_papers is not None) and (i_track >= num_papers)):\n",
    "            break\n",
    "    #\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4af23be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Throw error if not enough text entries collected\n",
    "if do_real_run:\n",
    "    if ((num_papers is not None) and (len(dict_texts) < num_papers)):\n",
    "        raise ValueError(\"Err: Something went wrong during initial processing. Insufficient number of texts extracted.\"\n",
    "                        +\"\\nRequested number of texts: {0}\\nActual number of texts: {1}\"\n",
    "                        .format(num_papers, len(dict_texts)))\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d25b4cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text #0:\n",
      "Classification: science\n",
      "Mission: HST\n",
      "ID: science_0\n",
      "Text snippet:\n",
      "We present HST observations in Figure 4.\n",
      "---\n",
      "\n",
      "\n",
      "Text #1:\n",
      "Classification: science\n",
      "Mission: HST\n",
      "ID: science_1\n",
      "Text snippet:\n",
      "The HST stars are listed in Table 3b.\n",
      "---\n",
      "\n",
      "\n",
      "Text #2:\n",
      "Classification: science\n",
      "Mission: HST\n",
      "ID: science_2\n",
      "Text snippet:\n",
      "Despite our efforts to smooth the data, there are still rings in the HST images.\n",
      "---\n",
      "\n",
      "\n",
      "Text #3:\n",
      "Classification: science\n",
      "Mission: HST\n",
      "ID: science_3\n",
      "Text snippet:\n",
      "See Section 8c for more discussion of the Hubble images.\n",
      "---\n",
      "\n",
      "\n",
      "Text #4:\n",
      "Classification: science\n",
      "Mission: HST\n",
      "ID: science_4\n",
      "Text snippet:\n",
      "The supernovae detected with HST tend to be brighter than initially predicted.\n",
      "---\n",
      "\n",
      "\n",
      "Text #5:\n",
      "Classification: science\n",
      "Mission: HST\n",
      "ID: science_5\n",
      "Text snippet:\n",
      "Our spectra from HST fit well to the standard trend first published in Someone et al. 1990.\n",
      "---\n",
      "\n",
      "\n",
      "Text #6:\n",
      "Classification: science\n",
      "Mission: HST\n",
      "ID: science_6\n",
      "Text snippet:\n",
      "We use the Hubble Space Telescope to build an ultraviolet database of the target stars.\n",
      "---\n",
      "\n",
      "\n",
      "Text #7:\n",
      "Classification: science\n",
      "Mission: HST\n",
      "ID: science_7\n",
      "Text snippet:\n",
      "The blue points (HST) exhibit more scatter than the red points (JWST).\n",
      "---\n",
      "\n",
      "\n",
      "Text #8:\n",
      "Classification: science\n",
      "Mission: HST\n",
      "ID: science_8\n",
      "Text snippet:\n",
      "The benefit, then, is the far higher S/N we achieved in our HST observations.\n",
      "---\n",
      "\n",
      "\n",
      "Text #9:\n",
      "Classification: science\n",
      "Mission: HST\n",
      "ID: science_9\n",
      "Text snippet:\n",
      "Here we employ the Hubble Telescope to observe the edge of the photon-dominated region.\n",
      "---\n",
      "\n",
      "\n",
      "Text #10:\n",
      "Classification: science\n",
      "Mission: HST\n",
      "ID: science_10\n",
      "Text snippet:\n",
      "The black line shows that the region targeted with Hubble has an extreme UV signature.\n",
      "---\n",
      "\n",
      "\n",
      "Text #11:\n",
      "Classification: datainfluenced\n",
      "Mission: HST\n",
      "ID: datainfluenced_0\n",
      "Text snippet:\n",
      "The simulated Hubble data is plotted in Figure 4.\n",
      "---\n",
      "\n",
      "\n",
      "Text #12:\n",
      "Classification: datainfluenced\n",
      "Mission: HST\n",
      "ID: datainfluenced_1\n",
      "Text snippet:\n",
      "Compared to the HST observations in Someone et al., our JWST follow-up reached higher S/N.\n",
      "---\n",
      "\n",
      "\n",
      "Text #13:\n",
      "Classification: datainfluenced\n",
      "Mission: HST\n",
      "ID: datainfluenced_2\n",
      "Text snippet:\n",
      "We were able to reproduce the luminosities from Hubble using our latest models.\n",
      "---\n",
      "\n",
      "\n",
      "Text #14:\n",
      "Classification: datainfluenced\n",
      "Mission: HST\n",
      "ID: datainfluenced_3\n",
      "Text snippet:\n",
      "We overplot Hubble-observed stars from Someone et al. in Figure 3b.\n",
      "---\n",
      "\n",
      "\n",
      "Text #15:\n",
      "Classification: datainfluenced\n",
      "Mission: HST\n",
      "ID: datainfluenced_4\n",
      "Text snippet:\n",
      "We built the spectral templates using UV data in the Hubble archive.\n",
      "---\n",
      "\n",
      "\n",
      "Text #16:\n",
      "Classification: datainfluenced\n",
      "Mission: HST\n",
      "ID: datainfluenced_5\n",
      "Text snippet:\n",
      "We simulate what our future HST observations will look like to predict the S/N.\n",
      "---\n",
      "\n",
      "\n",
      "Text #17:\n",
      "Classification: datainfluenced\n",
      "Mission: HST\n",
      "ID: datainfluenced_6\n",
      "Text snippet:\n",
      "Our work here with JWST is inspired by our earlier HST study published in 2010.\n",
      "---\n",
      "\n",
      "\n",
      "Text #18:\n",
      "Classification: datainfluenced\n",
      "Mission: HST\n",
      "ID: datainfluenced_7\n",
      "Text snippet:\n",
      "We therefore use the Hubble statistics from Author et al. to guide our stellar predictions.\n",
      "---\n",
      "\n",
      "\n",
      "Text #19:\n",
      "Classification: datainfluenced\n",
      "Mission: HST\n",
      "ID: datainfluenced_8\n",
      "Text snippet:\n",
      "The stars in Figure 3 were plotted based on the HST-fitted trend line in Person et al.\n",
      "---\n",
      "\n",
      "\n",
      "Text #20:\n",
      "Classification: datainfluenced\n",
      "Mission: HST\n",
      "ID: datainfluenced_9\n",
      "Text snippet:\n",
      "The final step is to use the HST exposure tool to put our modeled images in context.\n",
      "---\n",
      "\n",
      "\n",
      "Text #21:\n",
      "Classification: mention\n",
      "Mission: HST\n",
      "ID: mention_0\n",
      "Text snippet:\n",
      "Person et al. used HST to measure the Hubble constant.\n",
      "---\n",
      "\n",
      "\n",
      "Text #22:\n",
      "Classification: mention\n",
      "Mission: HST\n",
      "ID: mention_1\n",
      "Text snippet:\n",
      "We will present new HST observations in a future work.\n",
      "---\n",
      "\n",
      "\n",
      "Text #23:\n",
      "Classification: mention\n",
      "Mission: HST\n",
      "ID: mention_2\n",
      "Text snippet:\n",
      "HST is do_a fantastic instrument that has revolutionized our view of space.\n",
      "---\n",
      "\n",
      "\n",
      "Text #24:\n",
      "Classification: mention\n",
      "Mission: HST\n",
      "ID: mention_3\n",
      "Text snippet:\n",
      "The Hubble Space Telescope (HST) has its mission center at the STScI.\n",
      "---\n",
      "\n",
      "\n",
      "Text #25:\n",
      "Classification: mention\n",
      "Mission: HST\n",
      "ID: mention_4\n",
      "Text snippet:\n",
      "We can use HST to power a variety of science in the ultraviolet regime.\n",
      "---\n",
      "\n",
      "\n",
      "Text #26:\n",
      "Classification: mention\n",
      "Mission: HST\n",
      "ID: mention_5\n",
      "Text snippet:\n",
      "It is not clear when the star will be observable with HST.\n",
      "---\n",
      "\n",
      "\n",
      "Text #27:\n",
      "Classification: mention\n",
      "Mission: HST\n",
      "ID: mention_6\n",
      "Text snippet:\n",
      "More data can be found and downloaded from the Hubble archive.\n",
      "---\n",
      "\n",
      "\n",
      "Text #28:\n",
      "Classification: mention\n",
      "Mission: HST\n",
      "ID: mention_7\n",
      "Text snippet:\n",
      "We note that HST can be used to observe the stars as well, at higher S/N.\n",
      "---\n",
      "\n",
      "\n",
      "Text #29:\n",
      "Classification: mention\n",
      "Mission: HST\n",
      "ID: mention_8\n",
      "Text snippet:\n",
      "However, we ended up using the JWST rather than HST observations in this work.\n",
      "---\n",
      "\n",
      "\n",
      "Text #30:\n",
      "Classification: mention\n",
      "Mission: HST\n",
      "ID: mention_9\n",
      "Text snippet:\n",
      "We push the analysis of the Hubble component of the dataset to a future study.\n",
      "---\n",
      "\n",
      "\n",
      "Text #31:\n",
      "Classification: mention\n",
      "Mission: HST\n",
      "ID: mention_10\n",
      "Text snippet:\n",
      "We expect the HST observations to be released in the fall.\n",
      "---\n",
      "\n",
      "\n",
      "Text #32:\n",
      "Classification: mention\n",
      "Mission: HST\n",
      "ID: mention_11\n",
      "Text snippet:\n",
      "We look forward to any follow-up studies with, e.g., the Hubble Telescope.\n",
      "---\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Uncomment the code below to print a snippet of each of the entries in the dataset.\n",
    "#\"\"\"\n",
    "for curr_key in dict_texts:\n",
    "    print(\"Text #{0}:\".format(curr_key))\n",
    "    print(\"Classification: {0}\".format(dict_texts[curr_key][\"class\"]))\n",
    "    print(\"Mission: {0}\".format(dict_texts[curr_key][\"mission\"]))\n",
    "    print(\"ID: {0}\".format(dict_texts[curr_key][\"id\"]))\n",
    "    print(\"Text snippet:\")\n",
    "    print(dict_texts[curr_key][\"text\"][0:500])\n",
    "    print(\"---\\n\\n\")\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6182daaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target missions:\n",
      "Keyword Object:\n",
      "Name: Hubble\n",
      "Keywords: ['Hubble Space Telescope', 'Hubble Telescope', 'Hubble']\n",
      "Acronyms: ['hst', 'ht']\n",
      "\n",
      "\n",
      "\n",
      "Number of valid text entries:\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "#Print number of texts that fell under given parameters\n",
    "print(\"Target missions:\")\n",
    "for curr_kobj in all_kobjs:\n",
    "    print(curr_kobj)\n",
    "    print(\"\")\n",
    "print(\"\")\n",
    "print(\"Number of valid text entries:\")\n",
    "print(len(dict_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42320d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Running train_model_ML()!\n",
      "Previous training/validation directories already exist.\n",
      "Reusing the existing training/validation data in /Users/jyoon/GitHub/bibcat/src/models/lamb_real_run.\n",
      "ML model already exists for lamb_real_run in /Users/jyoon/GitHub/bibcat/src/models/lamb_real_run.\n",
      "Reusing the existing ML model in /Users/jyoon/GitHub/bibcat/src/models/lamb_real_run.\n",
      "Run of train_model_ML() complete!\n",
      "\n",
      "Time to train the model with run = 0.0004050731658935547\n"
     ]
    }
   ],
   "source": [
    "#Use the Operator instance to train an ML model\n",
    "start=time.time()\n",
    "tabby_ML.train_model_ML(dir_model=dir_model, name_model=name_model, do_reuse_run=do_reuse_run,\n",
    "                        seed_ML=seed_ML, seed_TVT=seed_TVT, filename_json=None, dict_texts=dict_texts,\n",
    "                        buffer=buffer, fraction_TVT=fraction_TVT, mode_TVT=mode_TVT, do_shuffle=do_shuffle,\n",
    "                        do_verbose=True, do_verbose_deep=None)\n",
    "\n",
    "print(f'Time to train the model with run = {time.time()-start}')\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df664592",
   "metadata": {},
   "source": [
    "And with that, we're done training a new ML model!  If run successfully, the model will be saved in the `dir_model` directory.\n",
    "\n",
    "We can then use the brand new model to classify some new text, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a002238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 16:16:32.823085: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Max\n",
      "2023-08-28 16:16:32.823104: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 64.00 GB\n",
      "2023-08-28 16:16:32.823108: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 24.00 GB\n",
      "2023-08-28 16:16:32.823136: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-08-28 16:16:32.823151: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 16:16:35.228997: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance of Operator successfully initialized!\n",
      "Keyword objects:\n",
      "0: Keyword Object:\n",
      "Name: Hubble\n",
      "Keywords: ['Hubble Space Telescope', 'Hubble Telescope', 'Hubble']\n",
      "Acronyms: ['hst', 'ht']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Set path to the new model output\n",
    "filepath_model = os.path.join(dir_model, (name_model+\".npy\"))\n",
    "fileloc_ML = os.path.join(dir_model, (preset.tfoutput_prefix+name_model))\n",
    "#Load the new ML model into a new Classifier_ML instance\n",
    "classifier_ML = bibcat.Classifier_ML(filepath_model=filepath_model, fileloc_ML=fileloc_ML,\n",
    "                                    do_verbose=True)\n",
    "#\n",
    "#Load the instance into a new Operator\n",
    "tabby_ML = bibcat.Operator(classifier=classifier_ML, mode=mode_modif, keyword_objs=all_kobjs,\n",
    "                           do_verbose=True, load_check_truematch=True, do_verbose_deep=False)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8afdc5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running _fetch_keyword_object() for lookup term HST.\n",
      "Best matching keyword object (keyobj) for keyword HST:\n",
      "Keyword Object:\n",
      "Name: Hubble\n",
      "Keywords: ['Hubble Space Telescope', 'Hubble Telescope', 'Hubble']\n",
      "Acronyms: ['hst', 'ht']\n",
      "\n",
      "\n",
      "Preprocessing and extracting modifs from the text...\n",
      "\n",
      "Running Grammar on the text...\n",
      "Text has been processed into modifs.\n",
      "Text has been processed into modif.\n",
      "\n",
      "Running classify_text for ML classifier:\n",
      "Class names from model:\n",
      "['DATA_INFLUENCED', 'MENTION', 'SCIENCE']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 16:16:35.902020: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 617ms/step\n",
      "\n",
      "Method classify_text for ML classifier complete!\n",
      "Max verdict: SCIENCE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run the classifier for some sample text below\n",
    "lookup = \"HST\"\n",
    "text = \"In this study, we present our HST observations of stars in the star-forming region Taurus.\"\n",
    "threshold = 0.8\n",
    "#\n",
    "#Run the classifier\n",
    "result = tabby_ML.classify(text=text, lookup=lookup, buffer=0, threshold=threshold,\n",
    "                            do_raise_innererror=False, do_check_truematch=True)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c2ba8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modif: In this study, we present our OBJ observations of stars in the star - forming region Taurus.\n",
      "\n",
      "Classification: z_lowprob\n",
      "\n",
      "Uncertainties per class: {'DATA_INFLUENCED': 0.1383228, 'MENTION': 0.39837658, 'SCIENCE': 0.46330068}\n",
      "\n",
      "Full classification output:\n",
      "{'verdict': 'z_lowprob', 'scores_comb': None, 'scores_indiv': None, 'uncertainty': {'DATA_INFLUENCED': 0.1383228, 'MENTION': 0.39837658, 'SCIENCE': 0.46330068}, 'modif': 'In this study, we present our OBJ observations of stars in the star - forming region Taurus.'}\n"
     ]
    }
   ],
   "source": [
    "#Print the classifier results\n",
    "print(\"Modif: {2}\\n\\nClassification: {0}\\n\\nUncertainties per class: {1}\\n\"\n",
    "      .format(result[\"verdict\"], result[\"uncertainty\"], result[\"modif\"]))\n",
    "print(\"Full classification output:\\n{0}\".format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2813bea",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (bib_tensorflow_py310)",
   "language": "python",
   "name": "bib_tensorflow_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
